{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymongo\n",
      "import numpy as n\n",
      "import pandas as p\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Connection to Mongo DB\n",
      "try:\n",
      "    conn = pymongo.MongoClient()\n",
      "    print \"Connected successfully!!!\"\n",
      "except pymongo.errors.ConnectionFailure, e:\n",
      "   print \"Could not connect to MongoDB: %s\" % e \n",
      "conn"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skyscanner import Flights\n",
      "\n",
      "flights_service = Flights('<Your API Key>')\n",
      "flights_service"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from skyscanner import Flights\n",
      "\n",
      "flights_service = Flights('<Your API Key>')\n",
      "result = flights_service.get_result(\n",
      "    country='UK',\n",
      "    currency='GBP',\n",
      "    locale='en-GB',\n",
      "    originplace='SIN-sky',\n",
      "    destinationplace='KUL-sky',\n",
      "    outbounddate='2015-05-28',\n",
      "    inbounddate='2015-05-31',\n",
      "    adults=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "tr = ['$ 1.232','U$D 2.2321']\n",
      "print [re.sub(re.compile(r'\\$[\\s]*([\\d]+)'), '\\\\1', w.replace('.','')).strip() for w in tr]\n",
      "print [re.sub(re.compile(r'U\\$D (.*)'), '\\\\1', w.replace('.','')).strip() for w in tr]\n",
      "print [re.match(re.compile(r'(\\$)?(U\\$D)? (.*)'), w.replace('.','')).groups()[2] for w in tr]\n",
      "\n",
      "tre = [re.match(re.compile(r'(\\$)?(U\\$D)? (.*)'), w.replace('.','')).groups() for w in tr]\n",
      "df = p.DataFrame(tre).fillna(0)\n",
      "print [int(df.ix[i,0] == '$') * df.ix[i,2] for i in range(len(df.ix[:,2]))]\n",
      "print [int(df.ix[i,1] == 'U$D') * df.ix[i,2] for i in range(len(df.ix[:,2]))]\n",
      "print df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib.pylab import plot\n",
      "print plot.\n",
      "print dir(plot)\n",
      "\n",
      "#'latam.items.LatamItem'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = conn.bloomberg\n",
      "#db = conn['scrapy']\n",
      "db.companies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scrapy.selector import HtmlXPathSelector\n",
      "hxs = HtmlXPathSelector()\n",
      "df = {}\n",
      "df['profit'] = {\n",
      "    'xpath':  [1,2,3],\n",
      "    'format': \"res.replace(' profit', '').replace('$', '').replace(',', '')\"\n",
      "}\n",
      "df['ticker'] = {\n",
      "    'xpath': [4,5,6,7,8],\n",
      "}\n",
      "df = p.DataFrame.from_dict(df, orient='index').fillna('')\n",
      "print df\n",
      "print df['xpath']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dfa = {}\n",
      "dfa['li'] = [1,2,3,2,3,4,5,6,7]\n",
      "dfa['li2'] = [11,22,2,3]\n",
      "dfa['li3'] = [11,22,2,3,1,2,2,3,4,56,6,5,434]\n",
      "def makeItems(dfa2, itemClass):\n",
      "    dfa2 = p.DataFrame.from_dict(dfa2, orient='index').transpose().fillna('')\n",
      "    #print dfa2\n",
      "    #print dfa\n",
      "    #zz = zip(dfa['li'], dfa['li2'])\n",
      "    #print zz\n",
      "    items = []\n",
      "    for i in xrange(len(dfa2)):\n",
      "        ct = []\n",
      "        for j in xrange(len(dfa2.ix[i,:])):\n",
      "            k = list(dfa2.keys())[j]\n",
      "            ct.append(\"{0}='{1}'\".format(k, dfa2.ix[i,k]))\n",
      "        cmd = \"{0}({1})\".format(itemClass, \", \".join(ct))\n",
      "        #print cmd\n",
      "        items.append(cmd)\n",
      "        #exec(cmd)\n",
      "    return items\n",
      "        \n",
      "makeItems(dfa, 'ProfitlyTradesItem')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = conn.profitly\n",
      "# search for string\n",
      "li = []\n",
      "#for i in db.users.find({'user':re.compile(r'.*ykes.*')}):\n",
      "#for i in db.users.find({'user':re.compile(r'.*')}):\n",
      "    #print i\n",
      "#    li.append({'trader':i['href'].replace('/user/', ''), 'profit':i['profit'], 'url':i['href'].replace('/user/', 'http://profit.ly/user/')})\n",
      "#df = p.DataFrame(li).drop_duplicates().sort('profit', ascending=False)\n",
      "#plot(df.ix[:,'profit'])\n",
      "\n",
      "for i in db.brokers.find():\n",
      "    #print i\n",
      "    li.append(i)\n",
      "df = p.DataFrame(li).drop_duplicates()#.sort('profit', ascending=False)\n",
      "print df\n",
      "#plot(df.ix[:,'profit'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "db = conn.profitly\n",
      "# search for string\n",
      "li = []\n",
      "#for i in db.users.find({'user':re.compile(r'.*ykes.*')}):\n",
      "for i in db.users.find({'user':re.compile(r'.*')}):\n",
      "    #print i\n",
      "    li.append({'trader':i['href'].replace('/user/', ''), 'profit':i['profit'], 'url':i['href'].replace('/user/', 'http://profit.ly/user/')})\n",
      "df = p.DataFrame(li).drop_duplicates().sort('profit', ascending=False)\n",
      "plot(df.ix[:,'profit'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cs = p.DataFrame()\n",
      "i = 0\n",
      "for co in db.companies.find():    \n",
      "    cs = cs.combine_first(p.DataFrame(co, index=[i]))\n",
      "    #cs = cs.combine_first(p.DataFrame(co.ix[], index=[i]))\n",
      "    #cs = cs.combine_first(p.DataFrame([co['company'], co['country']], index=[i]))\n",
      "    i += 1\n",
      "    if i >= 100:\n",
      "        break\n",
      "\n",
      "#cs = p.DataFrame(n.array(cs))\n",
      "#cs = cs.drop_duplicates(0).set_index(0)\n",
      "print cs\n",
      "#print len(cs)\n",
      "#csd = cs.groupby(0).describe()\n",
      "#print csd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print db.collection_names()\n",
      "lns = []\n",
      "st = []\n",
      "for i in db.companies.find()[0:10]:\n",
      "    #print i\n",
      "    lns.append(len(i['company']))\n",
      "    print \"{1}\\t{0}\".format(i['ticker'], i['company'])\n",
      "    \n",
      "print \n",
      "print 'p'*max(lns)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "conn.database_names()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from tweepy import API\n",
      "lookup ='BigData'\n",
      "api = API(auth_handler='', cons)\n",
      "\n",
      "search = []\n",
      "page = 1\n",
      "maxPage = 10\n",
      "while(page<=maxPage):\n",
      "    tweets = api.search(lookup,page = page)\n",
      "    for tweet in tweets:\n",
      "        search.append(tweet)\n",
      "    page = page + 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tweepy\n",
      "import json\n",
      "\n",
      "# Authentication details. To  obtain these visit dev.twitter.com\n",
      "consumer_key = 'nWGEdfoaBt7d6wWhiAw5Tw'\n",
      "consumer_secret = 'qM4QfDPqG9JQp6n0fqTCMrj6LJjES6vu2IzqpZLc'\n",
      "access_token = '2284416938-JbD4F32m9xQPMxKoh6UikpCLoJm8F6xy8wDPS9P'\n",
      "access_token_secret = 'XvJZQWa6zz5vHcHkUcYBacQKZJE9pcxbpxUUgNo9rN4AG'\n",
      "\n",
      "# This is the listener, resposible for receiving data\n",
      "class StdOutListener(tweepy.StreamListener):\n",
      "    def on_data(self, data):\n",
      "        # Twitter returns data in JSON format - we need to decode it first\n",
      "        decoded = json.loads(data)\n",
      "\n",
      "        # Also, we convert UTF-8 to ASCII ignoring all bad characters sent by users\n",
      "        print '@%s: %s' % (decoded['user']['screen_name'], decoded['text'].encode('ascii', 'ignore'))\n",
      "        print 'test'\n",
      "        return True\n",
      "\n",
      "    def on_error(self, status):\n",
      "        print status\n",
      "\n",
      "#if __name__ == '__main__':\n",
      "l = StdOutListener()\n",
      "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
      "auth.set_access_token(access_token, access_token_secret)\n",
      "\n",
      "print \"Showing all new tweets for #programming:\"\n",
      "\n",
      "# There are different kinds of streams: public stream, user stream, multi-user streams\n",
      "# In this example follow #programming tag\n",
      "# For more details refer to https://dev.twitter.com/docs/streaming-apis\n",
      "stream = tweepy.Stream(auth, l)\n",
      "stream.filter(track=['programming'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scrapy import shell\n",
      "from scrapy.selector import HtmlXPathSelector\n",
      "from scrapy.contrib.spiders import CrawlSpider\n",
      "\n",
      "#class TestSpider(Spider):\n",
      "class TestSpider(CrawlSpider):\n",
      "    name = 'qwe'\n",
      "    \n",
      "    def set_crawler(self, crawler):\n",
      "        super(TestSpider, self).set_crawler(crawler)\n",
      "        crawler.settings.set('JOBDIR','seen')\n",
      "\n",
      "class Qwe(CrawlSpider):\n",
      "    name = 'qwe'\n",
      "\n",
      "from scrapy.crawler import Crawler\n",
      "\n",
      "#cr = TestSpider(cr)\n",
      "cr = Qwe()\n",
      "sc = shell.Shell(cr)\n",
      "response = scrapy.http.Response('http://google.com')\n",
      "#hxs = HtmlXPathSelector(response)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from twisted.internet import reactor\n",
      "from scrapy.crawler import Crawler\n",
      "from scrapy.settings import Settings\n",
      "from scrapy import log\n",
      "#from testspiders.spiders.followall import FollowAllSpider\n",
      "\n",
      "#spider = FollowAllSpider(domain='scrapinghub.com')\n",
      "crawler = Crawler(Settings())\n",
      "crawler.configure()\n",
      "crawler.crawl(spider)\n",
      "crawler.start()\n",
      "log.start()\n",
      "reactor.run() # the script will block here\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import sys\n",
      "try: sys.path.index('/ml.dev/bin')\n",
      "except: sys.path.append('/ml.dev/bin')\n",
      "\n",
      "import numpy as n\n",
      "import pandas as p\n",
      "#mport Quandl as q\n",
      "from Quandl import Quandl as q\n",
      "import datetime as dd\n",
      "from qoreliquid import *\n",
      "from matplotlib import pyplot as plt\n",
      "from pylab import rcParams\n",
      "rcParams['figure.figsize'] = 20, 5\n",
      "\n",
      "from IPython.display import display, clear_output\n",
      "import time\n",
      "import threading\n",
      "from multiprocessing.pool import ThreadPool\n",
      "from selenium.webdriver.common.action_chains import ActionChains"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b = Bloomberg()\n",
      "b.start()\n",
      "b.driver.get('http://www.bloomberg.com/billionaires')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.driver.quit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "li1 = []\n",
      "#for i in b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[2]/div/div[3]'):\n",
      "\"\"\"\n",
      "for i in b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[2]/div'):\n",
      "    #li1.append(i.text)\n",
      "    print p.DataFrame(i.text.split('\\n'))\n",
      "    clear_output()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def aadd(a, b):\n",
      "    amax = n.max([len(a), len(b)])\n",
      "    return n.array(apad(a, amax)) + n.array(apad(b, amax))\n",
      "\n",
      "#[pu, pr]\n",
      "n.concatenate((apad(pu, 9), apad(pr, 9)), 0)\n",
      "\n",
      "nw = 37.2\n",
      "pc = [35]\n",
      "pu = [63, 377, 8]\n",
      "pr = [496, 1]\n",
      "num = [1,2,3]\n",
      "#(nw/100*(100./(sum(pu)-length(pu).*num + sum(pr)-length(pr).*num).transpose()*[pu pr]))\n",
      "aadd(n.sum(pu)-len(pu)*num, n.sum(pr)-len(pr)*num).transpose()\n",
      "\n",
      "# octave \n",
      "# 13 (Jack Ma) AS OF MAY 27, 2015\n",
      "# nw = 37.2; pc = [35]; pu = [63 377 8]; pr = [496 1];\n",
      "# n = [0.5:0.5:10]; (nw/100*(100./(sum(pu)-length(pu).*n+sum(pr)-length(pr).*n)'*[pu pr]))\n",
      "\"\"\"\n",
      "ans =\n",
      "\n",
      "    2.486578   14.880000    0.315756   19.576870    0.039469\n",
      "    2.493191   14.919574    0.316596   19.628936    0.039574\n",
      "    2.499840   14.959360    0.317440   19.681280    0.039680\n",
      "    2.506524   14.999358    0.318289   19.733904    0.039786\n",
      "    2.513244   15.039571    0.319142   19.786810    0.039893\n",
      "    2.520000   15.080000    0.320000   19.840000    0.040000\n",
      "    2.526792   15.120647    0.320863   19.893477    0.040108\n",
      "    2.533622   15.161514    0.321730   19.947243    0.040216\n",
      "    2.540488   15.202602    0.322602   20.001301    0.040325\n",
      "    2.547391   15.243913    0.323478   20.055652    0.040435\n",
      "    2.554332   15.285450    0.324360   20.110300    0.040545\n",
      "    2.561311   15.327213    0.325246   20.165246    0.040656\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "xp = '//*[@id=\"billionaires\"]//div[@class=\"bubble\"]'\n",
      "for i in b.driver.find_elements_by_xpath(xp):\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#mdf = b.billionaires\n",
      "mdf\n",
      "#b.billionaires = mdf\n",
      "#b.getAllBillionaires()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter(mdf.ix[:,'YTD change'], mdf.ix[:,'age']); xlabel('YTD change'); ylabel('age');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scatter(mdf.ix[:,'YTD change'], mdf.ix[:,'networth'])\n",
      "#mdf.ix[:,'networth'].plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#b.getProfile(74)\n",
      "b.getPortfolio()\n",
      "#b.driver.quit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.driver.find_elements_by_xpath('//*[@id=\"menu\"]/ul/li[1]')[0].click() # click explore"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mvw(na):\n",
      "    for i in xrange(len(na)):\n",
      "        if na[i] == '?':\n",
      "            na[i] = 0\n",
      "    return n.array(na.fillna(0))\n",
      "a = mvw(cdf.ix[:,'price'])\n",
      "b = mvw(cdf.ix[:,'available_supply'])\n",
      "scatter(a, b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e[0:2,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = e[:,0]\n",
      "b = e[:,3]\n",
      "a = normalizeme(a)\n",
      "a = sigmoidme(a)\n",
      "b = normalizeme(b)\n",
      "b = sigmoidme(b)\n",
      "print n.corrcoef(a, b)\n",
      "scatter(a, b); show();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "sns.set(style=\"darkgrid\")\n",
      "#rs = np.random.RandomState(33)\n",
      "#d = rs.normal(size=(10, 10))\n",
      "#print len(e)\n",
      "#print e\n",
      "f, ax = plt.subplots(figsize=(9, 9))\n",
      "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
      "sns.corrplot(e, annot=True, sig_stars=True, diag_names=True, cmap=cmap, ax=ax); show();\n",
      "#f.tight_layout()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cdf = p.read_csv('/mldev/lib/crawlers/finance/dataPipeline.scrapy/cryptocoins_numbeo.csv2')\n",
      "print cdf\n",
      "e = cdf.ix[:,['percent_1hr','percent_24hr','percent_7days','price','marketcap']].fillna(0).get_values().transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"   12  3   \".strip()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def runp():\n",
      "    els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[2]/div')#[0].text\n",
      "    pool = ThreadPool(processes=1)\n",
      "    def testThr(els, i):\n",
      "        #print 't'+str(i)\n",
      "        resp = 0\n",
      "        #\"\"\"\n",
      "        while resp == 0:\n",
      "            try:\n",
      "                try:\n",
      "                    ret = els[i].text.split('\\n')\n",
      "                    resp = 1\n",
      "                except ResponseNotReady, e:\n",
      "                    resp = 0\n",
      "                    logging.debug(e)\n",
      "            except NameError, e:\n",
      "                logging.debug(e)\n",
      "            #time.sleep(1)\n",
      "            #print resp\n",
      "        return ret\n",
      "        #\"\"\"\n",
      "    \n",
      "    #els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[2]/div')#[0].text\n",
      "    df = p.DataFrame()\n",
      "    for i in xrange(200):\n",
      "        return_val = pool.apply_async(testThr, (els, i)).get()\n",
      "        df0 = p.DataFrame([return_val], index=[i+1])#.transpose()\n",
      "        df = df.combine_first(df0)\n",
      "        #break\n",
      "    return df\n",
      "    print ''\n",
      "\n",
      "dfs = list(xrange(7))\n",
      "mdf = p.DataFrame()\n",
      "\n",
      "els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[1]/form/div/select/option[1]') # net worth (by rank)\n",
      "tit = els[0].text; print tit\n",
      "els[0].click()\n",
      "dfs[1] = runp()\n",
      "mdf['n'] = dfs[1].ix[:,2]\n",
      "mdf[tit] = dfs[1].ix[:,1]\n",
      "\n",
      "els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[1]/form/div/select/option[2]') # $ change previous day (by rank)\n",
      "tit = els[0].text; print tit\n",
      "els[0].click()\n",
      "dfs[2] = runp()\n",
      "mdf[tit] = dfs[2].ix[:,1]\n",
      "\n",
      "els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[1]/form/div/select/option[3]') # $ change previous day\n",
      "tit = els[0].text; print tit\n",
      "els[0].click()\n",
      "dfs[3] = runp()\n",
      "mdf[tit] = dfs[3].ix[:,1]\n",
      "\n",
      "els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[1]/form/div/select/option[4]') # % change previous day\n",
      "tit = els[0].text; print tit\n",
      "els[0].click()\n",
      "dfs[4] = runp()\n",
      "mdf[tit] = dfs[4].ix[:,1]\n",
      "\n",
      "els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[1]/form/div/select/option[5]') # $ change YTD\n",
      "tit = els[0].text; print tit\n",
      "els[0].click()\n",
      "dfs[5] = runp()\n",
      "mdf[tit] = dfs[5].ix[:,1]\n",
      "\n",
      "els = b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[1]/form/div/select/option[6]') # % change YTD\n",
      "tit = els[0].text; print tit\n",
      "els[0].click()\n",
      "dfs[6] = runp()\n",
      "mdf[tit] = dfs[6].ix[:,1]\n",
      "\n",
      "print mdf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logging.basicConfig(filename='/tmp/qore.dev.log', level=logging.DEBUG)\n",
      "\n",
      "xrels = xrange(len(els))\n",
      "t = list(xrels)\n",
      "for i in xrels:\n",
      "    print ''\n",
      "    #clear_output()\n",
      "        #sys.stdout.write('test' + '\\n')\n",
      "    t[i] = threading.Thread(target=testThr, args=[els, i])\n",
      "    t[i].daemon = False\n",
      "    t[i].start()\n",
      "    \n",
      "    time.sleep(0.25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "li2 = []\n",
      "for i in b.driver.find_elements_by_xpath('//*[@id=\"views\"]/div[2]/div[2]/div/div[2]/span'):\n",
      "    #li2.append(i.text)\n",
      "    print i.text\n",
      "    clear_output()\n",
      "p.DataFrame(li)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}