{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "try: sys.path.index('/ml.dev/bin')\n",
    "except: sys.path.append('/ml.dev/bin')\n",
    "\n",
    "import numpy as n\n",
    "import pandas as p\n",
    "#mport Quandl as q\n",
    "from Quandl import Quandl as q\n",
    "import datetime as dd\n",
    "from qoreliquid import *\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# readable datetime format\n",
    "def qoreGetTime(dt):\n",
    "    \"\"\"\n",
    "    dt = dd.datetime.now()\n",
    "    \"\"\"\n",
    "    if type(dt) != type(dd.datetime(2000,1,1)):\n",
    "        raise(TypeError(\"descriptor 'strftime' requires a 'datetime.date' object but received a '{0}'\".format(type(dt))))\n",
    "    \n",
    "    return dd.datetime.strftime(dt, '%Y-%m-%d %T.%fTGMT-3')\n",
    "print qoreGetTime(dd.datetime.now())\n",
    "#print qoreGetTime('')\n",
    "print time.time()\n",
    "print type(dd.datetime.now())\n",
    "print type(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# scrape stocktwits trending stocks list\n",
    "# fetch historical prices of listed stocks\n",
    "#  - google data via quandl\n",
    "# analyze historical data of listed stocks\n",
    "#  - normalized, sigmoid filters\n",
    "\n",
    "import ujson as j\n",
    "import pandas as p\n",
    "\n",
    "def parseSTJson(j3):\n",
    "    lst = []\n",
    "    #for i in j3['industries']:\n",
    "    for i in j3['stocks']:\n",
    "        #print p.DataFrame(i).transpose()\n",
    "        tdf = p.DataFrame(i)\n",
    "        lst.append(n.array(tdf.ix[['change'],tdf.columns].get_values()[0], dtype=str))\n",
    "        #print p.pivot(p.DataFrame(i).ix[['change'],['symbol', 'values']], index='symbol', columns=['change'], values=['values'])\n",
    "        #print p.pivot(p.DataFrame(i), index='change', columns=['symbol', 'name'], values=['values'])\n",
    "        #break\n",
    "        #print\n",
    "    res2 = p.DataFrame(lst, columns=tdf.columns)\n",
    "    return res2\n",
    "\n",
    "def gettickerSymbol(s):\n",
    "    hque = fetchURL('https://www.google.com/finance?q={0}'.format(s), mode='')\n",
    "    try:\n",
    "        hque = re.match(re.compile(r'.*\\(([\\w]+?:[\\w]+?)\\).*', re.S), hque).groups()[0]\n",
    "        return hque\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def queryGoogleFinanceForTicker(st1):\n",
    "    st1\n",
    "    ty = []\n",
    "    for i in st1:\n",
    "        ty.append(\"{0}\".format(gettickerSymbol(i)))\n",
    "    print ty\n",
    "    tt = \";\".join(ty)\n",
    "    tt = re.sub(re.compile(r':', re.S), '_', tt).split(';')\n",
    "    print tt\n",
    "    ty = []\n",
    "    for i in tt:\n",
    "        ty.append(\"GOOG/{0}\".format(i))\n",
    "    st1 = ty\n",
    "    return st1\n",
    "\n",
    "def fromGoogleFinanceChartGetTickers(url):\n",
    "    \"\"\"\n",
    "    url = 'https://www.google.com/finance?chdnp=1&chdd=1&chds=1&chdv=1&chvs=Linear&chdeh=1&chfdeh=1&chdet=1426072726443&chddm=963&chls=IntervalBasedLine&cmpto=NYSE:BITA;NYSE:PAY;NASDAQ:GERN;NYSEMKT:ROX;NYSE:PNK&cmptdms=0;0;0;0;0&q=NASDAQ:URBN&ntsp=0&ei=ux8AVZGVE8ei8waB2IHIDw'\n",
    "    \"\"\"\n",
    "    t1 = re.match(re.compile(r'.*cmpto=.*?q=(.*?)&.*', re.S), url).groups()[0]\n",
    "    t2 = re.match(re.compile(r'.*cmpto=(.*?)&.*', re.S), url).groups()[0]\n",
    "    tt = \"{0};{1}\".format(t1,t2)\n",
    "    tt = re.sub(re.compile(r':', re.S), '_', tt).split(';')\n",
    "    ty = []\n",
    "    for i in tt:\n",
    "        ty.append(\"GOOG/{0}\".format(i))\n",
    "    return ty\n",
    "\n",
    "def jsonValidator():\n",
    "    #from jsonschema import Draft3Validator\n",
    "    #my_schema = j.loads(r3) #or however else you end up with a dict of the schema\n",
    "    #print my_schema\n",
    "    #Draft3Validator.check_schema(schema)\n",
    "    #print r3\n",
    "    ''\n",
    "\n",
    "#st1 = fromGoogleFinanceChartGetTickers()\n",
    "#print st1\n",
    "\n",
    "#url = 'http://stocktwits.com/signals/stocks/week'\n",
    "url = 'http://stocktwits.com/signals/stocks/day'\n",
    "html = fetchURL(url, mode='')\n",
    "res = re.match(re.compile(r'.*?parseJSON\\(\"(.*})\"\\).*', re.S), html).groups()\n",
    "r3 = res[0].decode('string_escape')\n",
    "# todo: save json to log file\n",
    "j3 = j.loads(r3)\n",
    "\n",
    "res2 = parseSTJson(j3)\n",
    "#print res2.ix[0:10,['symbol', 'values']]\n",
    "print res2.ix[0:10,:]\n",
    "st1 = list(res2.ix[0:10,['symbol']].transpose().get_values()[0])\n",
    "print st1\n",
    "st1 = queryGoogleFinanceForTicker(st1)\n",
    "print st1\n",
    "st1 = \"\\n\".join(st1)\n",
    "st1 = st1.strip().split('\\n')\n",
    "\n",
    "non1 = getDataFromQuandl(st1, plot=False, style='-', columns='Close', tail=100)\n",
    "non = non1\n",
    "non = normalizeme(non)\n",
    "non = sigmoidme(non)\n",
    "#non.ix[:,['Ratio', 'Bullish', 'Bearish']].plot(style='-'); show();\n",
    "non.plot(style='-'); legend(non.columns, 2); show();\n",
    "print non.tail(3).transpose()\n",
    "non.to_csv('stocktwits-signal.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import requests\n",
    "from Quandl import Quandl as q\n",
    "\n",
    "index = ['Dec 12 2296', 'Dec 21 1998', 'Oct 9 2000', 'Oct 19 2001', 'Oct 30 2003', 'Nov 12 2003']\n",
    "data = pandas.DataFrame(numpy.random.randn(6, 3), index=index, columns=['D', 'B', 'C'])\n",
    "q.push(data, code='F32C', name='Test', desc='test', authtoken='WVsyCxwHeYZZyhf5RHs2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import requests\n",
    "q.push(non, code='TESTCODE12321', name='NON', desc='test', authtoken=\"WVsyCxwHeYZZyhf5RHs2\")\n",
    "#Quandl.push(data, code='F32C', name='Test', desc='test', authtoken='xxxxxx')\n",
    "#q.get('ALEXA/PSYCH_CENTRAL', authtoken=\"WVsyCxwHeYZZyhf5RHs2\")\n",
    "#non."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize stocktwits result\n",
    "na1 = n.array(res2.ix[:,'values'].get_values(), dtype=float)\n",
    "na1 = p.DataFrame(na1).ix[0:4,:]\n",
    "\n",
    "# select and calculate indeces based on \n",
    "# available tickers (some brokers may not list all tickers in this list)\n",
    "#availableTickers = [1] #etoro\n",
    "availableTickers = [1,2,12,13,19,21,25,27,28,] #plu500\n",
    "na1 = p.DataFrame(na1).ix[availableTickers,:]\n",
    "\n",
    "print len(na1)\n",
    "#print len(na2)\n",
    "#print p.DataFrame(n.abs(na1))\n",
    "na1 = n.abs(na1)\n",
    "print  n.sum(na1)\n",
    "res2['alloc'] = na1 / n.sum(na1) * 100\n",
    "#res2['alloc'] = 0\n",
    "print n.sum(res2.ix[:,'alloc'])\n",
    "print \" \".join(list(res2.ix[0:50,'symbol'].get_values()))\n",
    "print res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htmlp500 = fetchURL('http://www.plus500.com/AllInstruments/AllInstruments.aspx', mode='')\n",
    "# $x('//*[@id=\"main\"]/div/div[1]/div[2]/div/div/table/tbody/tr/td[1]').forEach(function(e) {console.log(e.innerHTML)});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non = getDataFromQuandl('PSYCH/EURUSD_R', plot=True, style='.')\n",
    "non = normalizeme(non)\n",
    "non = sigmoidme(non)\n",
    "non.ix[:,['Ratio', 'Bullish', 'Bearish']].plot(style='-'); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WORLDBANK/URY_FR_INR_DPST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "searchQuandl('yield')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -lS '/ml.dev/bin/data/oanda/datafeed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import oandapy\n",
    "import pandas as p\n",
    "\n",
    "co = p.read_csv('config.csv', header=None)\n",
    "\n",
    "env2=co.ix[1,1]\n",
    "access_token2=co.ix[1,2]\n",
    "oanda2 = oandapy.API(environment=env2, access_token=access_token2)\n",
    "\n",
    "acc = oanda2.get_accounts()['accounts']\n",
    "accid = acc[0]['accountId']\n",
    "print 'using account: {0}'.format(accid)\n",
    "\n",
    "response = oanda2.get_prices(instruments=\"USD_MXN\")\n",
    "prices = response.get(\"prices\")\n",
    "asking_price = prices[0].get(\"ask\")\n",
    "print asking_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as gos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# view real-time plot\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "# auto sign-in with credentials or use py.sign_in()\n",
    "py.sign_in('cilixian', 'ks48f6mysz')\n",
    "trace1 = Scatter(\n",
    "    x=[], \n",
    "    y=[], \n",
    "    #stream=dict(token='my_stream_id')\n",
    "    stream=dict(token='dlun5nb9sr')\n",
    ")\n",
    "data = Data([trace1])\n",
    "py.plot(data)\n",
    "#s = py.Stream('dlun5nb9sr')\n",
    "#s.open()\n",
    "#s.write(dict(x=1, y=2))\n",
    "#s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = py.Stream('dlun5nb9sr')\n",
    "s.open()\n",
    "s.write(dict(x=1, y=2))\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: http://stackoverflow.com/questions/18722196/how-to-set-utc-offset-for-datetime\n",
    "import datetime as dd\n",
    "import time\n",
    "import dateutil.tz\n",
    "dt = dateutil.parser.parse('2015-03-09T23:08:16.854172Z +0000')\n",
    "print (dt - dd.datetime(1970,1,1, tzinfo=dateutil.tz.tzoffset('UTC', 0))).total_seconds()  / dd.timedelta(seconds=1).total_seconds()\n",
    "print dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair = 'EUR_USD'\n",
    "\n",
    "from tailf import tailf\n",
    "ticks = 0\n",
    "for line in tailf('/ml.dev/bin/data/oanda/datafeed/{0}.csv'.format(pair)):\n",
    "    ticks += 1\n",
    "    i = line.split(',')\n",
    "    #print i[4]\n",
    "    print i\n",
    "    #print \"{0}\".format(dd.datetime.strptime(i[3], '%Y-%m-%dT%H:%M:%S.%fZ'))\n",
    "        \n",
    "    #if ticks >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tailf import tailf\n",
    "s = py.Stream('dlun5nb9sr')\n",
    "s.open()\n",
    "\"\"\"\n",
    "for c in range(100):\n",
    "    #time.sleep(1)\n",
    "    #print c\n",
    "    i = n.random.randn(1,2)[0];\n",
    "    s.write(dict(x=i[0], y=i[1]))\n",
    "\"\"\"\n",
    "for line in tailf('/ml.dev/bin/data/oanda/datafeed/GBP_JPY.csv'):\n",
    "    i = line.split(',')\n",
    "    s.write(dict(x=i[1], y=i[2]))\n",
    "s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "an1 = p.read_csv('/ml.dev/bin/data/oanda/datafeed/USD_MXN.csv', header=None)\n",
    "an2 = p.read_csv('/ml.dev/bin/data/oanda/datafeed/USD_SEK.csv', header=None)\n",
    "\n",
    "an1.plot(legend=None)\n",
    "an2.plot(legend=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rmo():\n",
    "    #\"\"\"\n",
    "    an1 = p.read_csv('/ml.dev/bin/data/oanda/datafeed/USD_MXN.csv', header=None)\n",
    "    \n",
    "    an1[4] = 1\n",
    "    an1[5] = '1'\n",
    "    print an1.ix[0,3]\n",
    "    for i in range(0,len(an1)-1):\n",
    "        #an1.ix[i,5] = dd.datetime.strptime(an1.ix[i,3], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        ''\n",
    "        #break\n",
    "    print an1.ix[0:2,:]\n",
    "    \n",
    "    #an1 = p.pivot_table(an1, values=[1,2], index=[3], columns=[0])\n",
    "    anp = p.pivot_table(an1, values=[4], index=[1], columns=[2], aggfunc=n.sum).fillna(0)\n",
    "    #an2 = p.read_csv('/ml.dev/bin/data/oanda/datafeed/EUR_USD.csv', header=None)\n",
    "    #an = an.set_index(3)\n",
    "    #print an1\n",
    "    #an.ix[:,[1,2]].plot(style='.'); show();\n",
    "    #\"\"\"\n",
    "    #print (p.DataFrame(n.sum(anp.ix[:,anp.columns[0:100]]), index=anp.columns[0:100]).plot(legend=False));\n",
    "    #print list(anp.index)\n",
    "    #show();\n",
    "#%prun rmo()\n",
    "rmo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "an = p.read_csv('/ml.dev/bin/data/oanda/datafeed/EUR_USD.csv', header=None)\n",
    "#an = an.set_index(3)\n",
    "#print an\n",
    "an.ix[:,[1,2]].plot(style='.'); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "\n",
    "data = [float(val) for val in '4 4'.split(' ')]\n",
    "print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, serial\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from collections import deque\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# plot class\n",
    "class AnalogPlot:\n",
    "  # constr\n",
    "  def __init__(self, analogData):\n",
    "    # set plot to animated\n",
    "    self.fig, axplt = plt.subplots() #plt.ion() \n",
    "    self.axline, = axplt.plot(analogData.ax)\n",
    "    self.ayline, = axplt.plot(analogData.ay)\n",
    "    plt.ylim([0, 1023])\n",
    "\n",
    "  # update plot\n",
    "  def update(self, analogData):\n",
    "    self.axline.set_ydata(analogData.ax)\n",
    "    self.ayline.set_ydata(analogData.ay)\n",
    "    self.fig.canvas.draw()\n",
    "    self.fig.canvas.flush_events()\n",
    "    #plt.draw()\n",
    "\n",
    "# class that holds analog data for N samples\n",
    "class AnalogData:\n",
    "  # constr\n",
    "  def __init__(self, maxLen):\n",
    "    self.ax = deque([0.0]*maxLen)\n",
    "    self.ay = deque([0.0]*maxLen)\n",
    "    self.maxLen = maxLen\n",
    "\n",
    "  # ring buffer\n",
    "  def addToBuf(self, buf, val):\n",
    "    if len(buf) < self.maxLen:\n",
    "      buf.append(val)\n",
    "    else:\n",
    "      buf.pop()\n",
    "      buf.appendleft(val)\n",
    "\n",
    "  # add data\n",
    "  def add(self, data):\n",
    "    assert(len(data) == 2)\n",
    "    self.addToBuf(self.ax, data[0])\n",
    "    self.addToBuf(self.ay, data[1])\n",
    "    \n",
    "# plot parameters\n",
    "analogData = AnalogData(100)\n",
    "analogPlot = AnalogPlot(analogData)\n",
    "print('plotting data...')\n",
    "\n",
    "while True:\n",
    "        #try:\n",
    "        #.strip(b'\\x00').decode('ascii') added for IPython3\n",
    "        #line = ser.readline().strip(b'\\x00').decode('ascii')\n",
    "        line = '600 400'\n",
    "        data = [float(val) for val in line.split()]\n",
    "        \n",
    "        if(len(data) == 2):\n",
    "            analogData.add(data)\n",
    "            analogPlot.update(analogData)\n",
    "        #except: #Interrupt the kernal to exit\n",
    "        #    print('Exiting')\n",
    "        #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "for i in range(10):\n",
    "    try:\n",
    "        pl.plot(pl.randn(100))\n",
    "        display.clear_output()\n",
    "        display.display(pl.gcf())\n",
    "        pl.gcf().show();\n",
    "        time.sleep(1.0)\n",
    "    except:\n",
    "        ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "import threading\n",
    "import time\n",
    "import numpy as n\n",
    "import pandas as p\n",
    "from tailf import tailf\n",
    "\n",
    "tiks = \"\"\"/ml.dev/bin/data/oanda/datafeed/AUD_CAD.csv  /ml.dev/bin/data/oanda/datafeed/EUR_PLN.csv  /ml.dev/bin/data/oanda/datafeed/SGD_JPY.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/AUD_CHF.csv  /ml.dev/bin/data/oanda/datafeed/EUR_SEK.csv  /ml.dev/bin/data/oanda/datafeed/TRY_JPY.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/AUD_HKD.csv  /ml.dev/bin/data/oanda/datafeed/EUR_SGD.csv  /ml.dev/bin/data/oanda/datafeed/USD_CAD.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/AUD_JPY.csv  /ml.dev/bin/data/oanda/datafeed/EUR_TRY.csv  /ml.dev/bin/data/oanda/datafeed/USD_CHF.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/AUD_NZD.csv  /ml.dev/bin/data/oanda/datafeed/EUR_USD.csv  /ml.dev/bin/data/oanda/datafeed/USD_CNH.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/AUD_SGD.csv  /ml.dev/bin/data/oanda/datafeed/EUR_ZAR.csv  /ml.dev/bin/data/oanda/datafeed/USD_CNY.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/AUD_USD.csv  /ml.dev/bin/data/oanda/datafeed/GBP_AUD.csv  /ml.dev/bin/data/oanda/datafeed/USD_CZK.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CAD_CHF.csv  /ml.dev/bin/data/oanda/datafeed/GBP_CAD.csv  /ml.dev/bin/data/oanda/datafeed/USD_DKK.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CAD_HKD.csv  /ml.dev/bin/data/oanda/datafeed/GBP_CHF.csv  /ml.dev/bin/data/oanda/datafeed/USD_HKD.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CAD_JPY.csv  /ml.dev/bin/data/oanda/datafeed/GBP_HKD.csv  /ml.dev/bin/data/oanda/datafeed/USD_HUF.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CAD_SGD.csv  /ml.dev/bin/data/oanda/datafeed/GBP_JPY.csv  /ml.dev/bin/data/oanda/datafeed/USD_INR.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CHF_HKD.csv  /ml.dev/bin/data/oanda/datafeed/GBP_NZD.csv  /ml.dev/bin/data/oanda/datafeed/USD_JPY.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CHF_JPY.csv  /ml.dev/bin/data/oanda/datafeed/GBP_PLN.csv  /ml.dev/bin/data/oanda/datafeed/USD_MXN.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/CHF_ZAR.csv  /ml.dev/bin/data/oanda/datafeed/GBP_SGD.csv  /ml.dev/bin/data/oanda/datafeed/USD_NOK.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_AUD.csv  /ml.dev/bin/data/oanda/datafeed/GBP_USD.csv  /ml.dev/bin/data/oanda/datafeed/USD_PLN.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_CAD.csv  /ml.dev/bin/data/oanda/datafeed/GBP_ZAR.csv  /ml.dev/bin/data/oanda/datafeed/USD_SAR.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_CHF.csv  /ml.dev/bin/data/oanda/datafeed/HKD_JPY.csv  /ml.dev/bin/data/oanda/datafeed/USD_SEK.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_CZK.csv  /ml.dev/bin/data/oanda/datafeed/NZD_CAD.csv  /ml.dev/bin/data/oanda/datafeed/USD_SGD.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_DKK.csv  /ml.dev/bin/data/oanda/datafeed/NZD_CHF.csv  /ml.dev/bin/data/oanda/datafeed/USD_THB.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_GBP.csv  /ml.dev/bin/data/oanda/datafeed/NZD_HKD.csv  /ml.dev/bin/data/oanda/datafeed/USD_TRY.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_HKD.csv  /ml.dev/bin/data/oanda/datafeed/NZD_JPY.csv  /ml.dev/bin/data/oanda/datafeed/USD_TWD.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_HUF.csv  /ml.dev/bin/data/oanda/datafeed/NZD_SGD.csv  /ml.dev/bin/data/oanda/datafeed/USD_ZAR.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_JPY.csv  /ml.dev/bin/data/oanda/datafeed/NZD_USD.csv  /ml.dev/bin/data/oanda/datafeed/ZAR_JPY.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_NOK.csv  /ml.dev/bin/data/oanda/datafeed/SGD_CHF.csv\n",
    "/ml.dev/bin/data/oanda/datafeed/EUR_NZD.csv  /ml.dev/bin/data/oanda/datafeed/SGD_HKD.csv\"\"\"\n",
    "tk = tiks.split('  ')\n",
    "\n",
    "\"\"\"\n",
    "t = {}\n",
    "for i in xrange(1):\n",
    "    #time.sleep(5)\n",
    "    #clear_output()\n",
    "        #sys.stdout.write('test' + '\\n')\n",
    "    \n",
    "    t[0] = threading.Thread(target=testThr, args=[tk[i]])\n",
    "    t[0].daemon = False\n",
    "    t[0].start()\n",
    "    \n",
    "    #sys.stdout.flush()\n",
    "\"\"\"\n",
    "\n",
    "def groupby(lns, a, b):\n",
    "    df = p.DataFrame(lns)\n",
    "    df = df.convert_objects(convert_numeric=True)\n",
    "    dfg = df.groupby(a)\n",
    "    #print dfg.describe()\n",
    "    print dfg[b].agg([n.std,n.mean])\n",
    "\n",
    "def testThr(fname):\n",
    "    #for i in xrange(10):\n",
    "        \n",
    "    lns = []\n",
    "    ticks = 0\n",
    "    \n",
    "    #plotly stream\n",
    "    #s = py.Stream('dlun5nb9sr')\n",
    "    #s.open()\n",
    "    \n",
    "    for line in tailf(fname):\n",
    "        ticks += 1\n",
    "        \n",
    "        i = line.split(',')\n",
    "        #print i[4]\n",
    "        #print i\n",
    "        lns.append(i)\n",
    "        \n",
    "        time.sleep(0.3)\n",
    "        clear_output()\n",
    "\n",
    "        groupby(lns, 1,2)\n",
    "\n",
    "        #i = line.split(',')\n",
    "        #s.write(dict(x=i[1], y=i[2]))\n",
    "        \n",
    "        sys.stdout.flush()\n",
    "            \n",
    "        #if ticks >= 10: break\n",
    "        \n",
    "    s.close()\n",
    "        \n",
    "testThr('/ml.dev/bin/data/oanda/datafeed/EUR_USD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as p\n",
    "import numpy as n\n",
    "from pylab import *\n",
    "\n",
    "def prepTks(tks):\n",
    "    tkd = []\n",
    "    for i in filter(None, tks.split(' ')):\n",
    "        i = filter(None, i.split('\\n'))\n",
    "        i[0] = i[0].replace('.csv','')\n",
    "        tkd.append(\" \".join(i))\n",
    "    #print tkd\n",
    "    #print \" \".join(tkd)\n",
    "    return tkd\n",
    "\n",
    "def genGrid(tks):\n",
    "    df = p.DataFrame()\n",
    "    tkd = prepTks(tks)\n",
    "    for i in xrange(len(tkd)):\n",
    "        df = df.combine_first(p.DataFrame(tkd[i].split('_'), index=[0,1], columns=[i]).transpose())\n",
    "    pairs = p.DataFrame(list(df.ix[:,0].drop_duplicates()) + list(df.ix[:,1].drop_duplicates())).transpose()\n",
    "    pairs = list(pairs.get_values()[0])\n",
    "    lp = len(pairs)\n",
    "    grid = p.DataFrame(n.zeros(n.power(lp,2)).reshape(lp,lp), index=pairs, columns=pairs)\n",
    "    return grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq = Qoreliquid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####\n",
    "# Visualization\n",
    "###\n",
    "tks = \"\"\"AUD_CAD.csv  AUD_USD.csv  CHF_JPY.csv  EUR_DKK.csv  EUR_NZD.csv  EUR_ZAR.csv  GBP_NZD.csv  NZD_CAD.csv  SGD_CHF.csv  USD_CNH.csv  USD_INR.csv  USD_SEK.csv  ZAR_JPY.csv  AUD_CHF.csv  CAD_CHF.csv  CHF_ZAR.csv  EUR_GBP.csv  EUR_PLN.csv  GBP_AUD.csv   GBP_PLN.csv  NZD_CHF.csv  SGD_HKD.csv  USD_CNY.csv  USD_JPY.csv  USD_SGD.csv AUD_HKD.csv  CAD_HKD.csv  EUR_AUD.csv  EUR_HKD.csv  EUR_SEK.csv  GBP_CAD.csv   GBP_SGD.csv  NZD_HKD.csv  SGD_JPY.csv  USD_CZK.csv  USD_MXN.csv  USD_THB.csv AUD_JPY.csv  CAD_JPY.csv  EUR_CAD.csv  EUR_HUF.csv  EUR_SGD.csv  GBP_CHF.csv   GBP_USD.csv  NZD_JPY.csv  TRY_JPY.csv  USD_DKK.csv  USD_NOK.csv  USD_TRY.csv AUD_NZD.csv  CAD_SGD.csv  EUR_CHF.csv  EUR_JPY.csv  EUR_TRY.csv  GBP_HKD.csv   GBP_ZAR.csv  NZD_SGD.csv  USD_CAD.csv  USD_HKD.csv  USD_PLN.csv  USD_TWD.csv  AUD_SGD.csv  CHF_HKD.csv  EUR_CZK.csv  EUR_NOK.csv  EUR_USD.csv  GBP_JPY.csv   HKD_JPY.csv  NZD_USD.csv  USD_CHF.csv  USD_HUF.csv  USD_SAR.csv  USD_ZAR.csv\"\"\"\n",
    "\n",
    "#%timeit -n 20 genGrid(tks)\n",
    "gr = genGrid(tks)\n",
    "\n",
    "# source: http://matplotlib.org/examples/pylab_examples/hist2d_demo.html\n",
    "x = randn(len(gr))\n",
    "y = randn(len(gr))\n",
    "\n",
    "#normal distribution center at x=0 and y=5\n",
    "print \n",
    "hist2d(x,y,bins=40)\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readCompanies(fname):\n",
    "    fp = open(fname,'r')\n",
    "    #js = j.loads(fp.read())\n",
    "    df = p.DataFrame()\n",
    "    i = 0\n",
    "    for line in fp.readlines():\n",
    "        js = j.loads(line.split('\\n')[0])\n",
    "        df = df.combine_first(p.DataFrame(js, index=[i]))\n",
    "        i += 1\n",
    "    fp.close()\n",
    "    return df\n",
    "df = readCompanies('/mldev/lib/bloomberg/bloomberg/backups/companies_products.json')\n",
    "#df2 = readCompanies('/mldev/lib/bloomberg/bloomberg/companies_products.json')\n",
    "#df = readCompanies('/mldev/lib/bloomberg/CrawlPubComp/companies.json')http://127.0.0.1:8889/21fad5ec-c1c0-4910-b80b-3b01cd3551e3#\n",
    "\n",
    "\n",
    "print len(df)\n",
    "print len(df2)\n",
    "\n",
    "print df2.set_index('ticker')\n",
    "\n",
    "df = p.DataFrame()\n",
    "for i in xrange(len(js)):\n",
    "    #df = df.combine_first(p.DataFrame(js[i], index=[i]))\n",
    "    print js[i]\n",
    "#print df\n",
    "\n",
    "fp = open('/mldev/lib/stocktwits/tmpscrapy/CrawlPubComp/companies.json', 'r')\n",
    "js = fp.read()\n",
    "js = j.loads(js)\n",
    "len(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "def countLines(fname):\n",
    "    cmd = \"wc -l '{0}'\".format(fname)\n",
    "    print cmd\n",
    "    %timeit -n 1 print int(subprocess.check_output(cmd).split()[0])\n",
    "    \n",
    "    %timeit -n 1 print sum(1 for line in open(fname))\n",
    "print countLines('/data-oanda-datafeed/EUR_USD.csv')\n",
    "print countLines('/data-oanda-datafeed/GBP_USD.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mmap\n",
    "mmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = '/data-oanda-datafeed/EUR_USD.csv'\n",
    "fname = os.path.abspath(fname)\n",
    "print fname\n",
    "fname = os.path.dirname(fname)\n",
    "print fname\n",
    "#fname = os.chdir(fname)\n",
    "#print fname\n",
    "#fname = os.chdir(os.path.dirname(os.path.abspath(fname)))\n",
    "#print fname\n",
    "\n",
    "cmd = \"wc -l '{0}'\".format(fname)\n",
    "#cmd = \"ls\"\n",
    "print cmd\n",
    "#%timeit -n 1 print\n",
    "print int(subprocess.check_output(cmd).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "fname = '/data-oanda-datafeed/EUR_USD.csv'\n",
    "print n.genfromtxt(fname, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print p.read_csv(fname, skiprows=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 34967750.0/539981\n",
    "print int(floor(34967750.0/64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandasdmx import Request\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams['figure.figsize'] = 200, 50\n",
    "\n",
    "class ECB:\n",
    "    \n",
    "    def __init__(self, verbose=False):\n",
    "\n",
    "        self.ecb = Request('ECB')\n",
    "        cat_resp = self.ecb.get(resource_type = 'categoryscheme')\n",
    "        if verbose == True: print type(cat_resp)\n",
    "        #Out[6]: pandasdmx.api.Response\n",
    "        \n",
    "        cat_msg = cat_resp.msg\n",
    "        if verbose == True: print type(cat_msg)\n",
    "        #Out[8]: pandasdmx.model.StructureMessage\n",
    "        \n",
    "        cat_header = cat_msg.header\n",
    "        if verbose == True: print type(cat_header)\n",
    "        #Out[10]: pandasdmx.model.Header\n",
    "        \n",
    "        categorisations = cat_msg.categorisations\n",
    "        if verbose == True: print type(categorisations)\n",
    "        #Out[12]: pandasdmx.model.Categorisations\n",
    "        \n",
    "        # part II\n",
    "        cs = cat_msg.categoryschemes\n",
    "        \n",
    "        type(cs)\n",
    "        #Out[17]: pandasdmx.utils.DictLike\n",
    "        \n",
    "        list(cs.keys())\n",
    "        #Out[18]: ['MOBILE_NAVI']\n",
    "        \n",
    "        # part III\n",
    "        cs0 = cs.aslist()[0]\n",
    "        for i in cs0.keys():\n",
    "            if verbose == True: print cs0[i]\n",
    "        if verbose == True: print \n",
    "        if verbose == True: print cs0['03'].name\n",
    "        #for i in cat_msg.categorisations['03']: print i\n",
    "        if verbose == True: print cat_msg.dataflows.find('interest')\n",
    "                \n",
    "        # part IV\n",
    "        flows = self.ecb.get(resource_type = 'dataflow')\n",
    "        flows.msg.dataflows\n",
    "        #data_resp = self.ecb.get(resource_type = 'data', resource_id = 'MIR', key = '.USD+JPY+GBP...', params = dict(startPeriod = '2014'))\n",
    "        \n",
    "        # part VI\n",
    "        cs0 = cs.aslist()[0]\n",
    "        \n",
    "        if verbose == True: print type(cs0)\n",
    "        #Out[20]: pandasdmx.model.CategoryScheme\n",
    "        \n",
    "        # Print the number of categories\n",
    "        if verbose == True: print len(cs0)\n",
    "        #Out[21]: 11\n",
    "        \n",
    "        # Print ID's of categories\n",
    "        if verbose == True: print list(cs0.keys())\n",
    "        #Out[22]: ['04', '08', '09', '06', '03', '01', '10', '02', '11', '07', '05']\n",
    "        \n",
    "        # English name of category '07'\n",
    "        if verbose == True: print cs0['07'].name.en\n",
    "        #Out[23]: 'Exchange rates'\n",
    "\n",
    "        # part VII\n",
    "        cat07_l = cat_msg.categorisations['07']\n",
    "\n",
    "        if verbose == True: print list(cat_msg.dataflows[i.artefact.id] for i in cat07_l)\n",
    "        #Out[25]: \n",
    "        #[DataflowDefinition : EXR  : Exchange Rates,\n",
    "        # DataflowDefinition : EXR  : Exchange Rates,\n",
    "        # DataflowDefinition : WTS  : Trade weights,\n",
    "        # DataflowDefinition : WTS  : Trade weights]        \n",
    "    \n",
    "        # part VIII\n",
    "        #cat_msg.dataflows.find('rates')\n",
    "        if verbose == True: print cat_msg.dataflows.find('interest')\n",
    "        if verbose == True: print cat_msg.dataflows.find('yield')\n",
    "        #Out[26]: \n",
    "        #{'EXR': DataflowDefinition : EXR  : Exchange Rates,\n",
    "        # 'RIR': DataflowDefinition : RIR  : Retail Interest Rates}\n",
    "    \n",
    "    def getDimensions(self, cat_msg, dsd_id):\n",
    "        exec('dsd_id = cat_msg.dataflows.{0}.structure.id'.format(dsd_id))\n",
    "        #dsd_id = cat_msg.dataflows.'EXR'.structure.id\n",
    "        refs = dict(references = 'all')\n",
    "        refs\n",
    "        dsd_resp = self.ecb.get(resource_type = 'datastructure', resource_id = dsd_id, params = refs)\n",
    "        dsd_resp\n",
    "        dsd = dsd_resp.msg.datastructures[dsd_id]\n",
    "        dsd\n",
    "        \n",
    "        print list(d.id for d in dsd.dimensions.aslist())\n",
    "        #Out[32]: ['FREQ', 'CURRENCY', 'CURRENCY_DENOM', 'EXR_TYPE', 'EXR_SUFFIX', 'TIME_PERIOD']\n",
    "        \n",
    "        return dsd\n",
    "        \n",
    "    def getCodeList(self, dsd3):\n",
    "        for i in dsd3.dimensions.keys():\n",
    "            print\n",
    "            print i    \n",
    "        \n",
    "            cmd = 'ccl = dsd3.dimensions.{0}.local_repr.enum'.format(i)\n",
    "            print cmd\n",
    "            exec(cmd)\n",
    "            print ccl\n",
    "            #print ccl.USD, currency_codelist.JPY\n",
    "            #print dir(ccl)\n",
    "            try:    \n",
    "                print len(ccl)\n",
    "                for j in ccl.aslist():                                                                                                                          \n",
    "                    print j\n",
    "            except: ''\n",
    "            print \n",
    "            print \n",
    "            \n",
    "            #currency_codelist = dsd.dimensions.CURRENCY.local_repr.enum\n",
    "            \n",
    "            #print len(currency_codelist)\n",
    "            #Out[34]: 348\n",
    "            \n",
    "            #print currency_codelist.USD, currency_codelist.JPY\n",
    "            #Out[35]: (Code : USD  : US dollar, Code : JPY  : Japanese yen)\n",
    "            \n",
    "    def getSeries(self):\n",
    "        # part V\n",
    "        data_resp = self.ecb.get(resource_type = 'data', resource_id = 'EXR', key = '.USD+JPY+GBP...', params = dict(startPeriod = '2014'))\n",
    "        data = data_resp.msg.data\n",
    "        for i in data.series:\n",
    "            print i.key\n",
    "        \n",
    "        #daily = (s for s in data.series if s.key.FREQ == 'D')\n",
    "        #cur_df = data_resp.write(daily)\n",
    "        #print cur_df.shape\n",
    "        #print cur_df.tail()\n",
    "        #print cur_df\n",
    "\n",
    "    def gee(self, nnn):\n",
    "        self.pa = getDatasetEUR(returnPairs=False)\n",
    "        self.pa = self.pa.split(' ')\n",
    "        li = []\n",
    "        for i in self.pa[0:nnn]:\n",
    "            li.append(i[3:])\n",
    "        self.pa = '+'.join(li)\n",
    "        print self.pa\n",
    "        \n",
    "        data_resp = self.ecb.get(resource_type = 'data', resource_id = 'EXR', key = '.{0}...'.format(self.pa), params = dict(startPeriod = '2013-01-01'))\n",
    "        data = data_resp.msg.data\n",
    "        daily = (s for s in data.series if s.key.FREQ == 'D')\n",
    "        cur_df = data_resp.write(daily)\n",
    "        #print cur_df.shape\n",
    "        #print cur_df.tail()\n",
    "        #print cur_df\n",
    "        #Out[48]: \n",
    "        #FREQ                 D        \n",
    "        #CURRENCY           JPY     USD\n",
    "        #CURRENCY_DENOM     EUR     EUR\n",
    "        #EXR_TYPE          SP00    SP00\n",
    "        #EXR_SUFFIX           A       A\n",
    "        #2015-05-19      134.36  1.1180\n",
    "        #2015-05-20      134.43  1.1118\n",
    "        #2015-05-21      134.79  1.1133\n",
    "        \n",
    "        df = cur_df\n",
    "        df = df.fillna(0)\n",
    "        df = normalizeme(df)\n",
    "        df = sigmoidme(df)\n",
    "        #print df\n",
    "        #df.plot(legend=False); show();\n",
    "        #savefig('temp-{0}.png'.format(nnn), dpi=fig.dpi)\n",
    "        \n",
    "        ax = df.plot(legend=False);  # s is an instance of Series\n",
    "        fig = ax.get_figure()\n",
    "        mkdir_p('plots')\n",
    "        fig.savefig('plots/EUR_{0}.png'.format(nnn))\n",
    "        \n",
    "        #fig = plt.figure()\n",
    "        #plt.plot(list(cur_df.index), df); show();\n",
    "        #fig.savefig('temp-{0}.png'.format(nnn), dpi=fig.dpi)\n",
    "\n",
    "    def getEUR(self):\n",
    "        \n",
    "        #for i in xrange(1, len(getDatasetEUR(returnPairs=False).split(' '))-1): \n",
    "        #    self.gee(i)\n",
    "        self.gee(167)\n",
    "\n",
    "ee = ECB()\n",
    "#dsd2 = ee.getDimensions(cat_msg, 'EXR')\n",
    "#dsd2 = ee.getDimensions(cat_msg, 'MIR')\n",
    "#ee.getCodeList(dsd2)\n",
    "#ee.getEUR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 200, 50\n",
    "data = p.read_csv('/mldev/bin/data/quandl/BNP.EUR.csv')\n",
    "df = data\n",
    "df = df.set_index(df.columns[0]).fillna(0)\n",
    "#df = df.ix['2013-01-01':,:]\n",
    "print df.shape\n",
    "dfn = df.get_values()\n",
    "dfn = normalizeme(dfn)\n",
    "dfn = sigmoidme(dfn)\n",
    "p.DataFrame(dfn, index=df.index, columns=df.columns).plot(legend=False); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecb = Request('ECB')\n",
    "#data_resp = ecb.get(resource_type = 'data', resource_id = 'MIR', key = '....', params = dict(startPeriod = '2014'))\n",
    "data_resp = ecb.get(resource_type = 'data', resource_id = 'EXR', key = '.USD+GBP+JPY...', params = dict(startPeriod = '2000'))\n",
    "\n",
    "print type(data_resp.msg)\n",
    "#Out[37]: pandasdmx.model.GenericDataMessage\n",
    "\n",
    "data = data_resp.msg.data\n",
    "\n",
    "print type(data)\n",
    "#Out[39]: pandasdmx.model.GenericDataSet\n",
    "\n",
    "daily = (s for s in data.series if s.key.FREQ == 'D')\n",
    "\n",
    "cur_df = data_resp.write(daily)\n",
    "\n",
    "print cur_df.shape\n",
    "#Out[47]: (354, 2)\n",
    "\n",
    "#print cur_df.tail()\n",
    "cur_df = normalizeme2(cur_df)\n",
    "print cur_df.plot()\n",
    "#Out[48]: \n",
    "#FREQ                 D        \n",
    "#CURRENCY           JPY     USD\n",
    "#CURRENCY_DENOM     EUR     EUR\n",
    "#EXR_TYPE          SP00    SP00\n",
    "#EXR_SUFFIX           A       A\n",
    "#2015-05-19      134.36  1.1180\n",
    "#2015-05-20      134.43  1.1118\n",
    "#2015-05-21      134.79  1.1133\n",
    "#2015-05-22      135.01  1.1164\n",
    "#2015-05-25      133.39  1.0978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = p.read_csv('/home/qore2/Desktop/data.csv')\n",
    "df.ix[0:len(df),:].convert_objects(convert_numeric=True).fillna(0) #.get_values() #.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n.sin(li)\n",
    "lss = sin(linspace(0,10, num=10000))\n",
    "lss2 = sin(linspace(0, 100, num=10000))\n",
    "lss3 = cos(linspace(0, 200, num=10000))\n",
    "lss4 = sin(linspace(0, 300, num=10000))\n",
    "plot(lss); show();\n",
    "#plot(lss2); show();\n",
    "#plot(lss3); show();\n",
    "#plot(lss + lss2); show();\n",
    "plot(lss + lss2 + lss3 + lss4); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random as rr\n",
    "import numpy as n\n",
    "import pandas as p\n",
    "\n",
    "def t1():\n",
    "    li = []\n",
    "    for i in xrange(100):\n",
    "        x1 = '%.5f' % float(rr.random()*1)\n",
    "        li.append(float(x1) + 1.5)\n",
    "    print li\n",
    "    print p.DataFrame(li).describe()\n",
    "    plot(li); show();\n",
    "\n",
    "for i in xrange(10):\n",
    "    t1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fakeTicker(ticker=False):\n",
    "    pri = 1.5\n",
    "    li2 = []\n",
    "    \n",
    "    for i in xrange(10000):\n",
    "    #while True:\n",
    "        ri = rr.random()/10000\n",
    "        \n",
    "        if i % 2 == 0:  il = 1\n",
    "        else:           il = -1\n",
    "\n",
    "        pri += ri * il\n",
    "        li2.append(pri)\n",
    "        if ticker == True:\n",
    "            print pri\n",
    "            time.sleep(rr.random())\n",
    "    if ticker == True:\n",
    "        plot(li2)\n",
    "        print p.DataFrame(li2).describe()\n",
    "        return li2\n",
    "    \n",
    "fakeTicker(ticker=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# real-time account summary\n",
    "oq = OandaQ()\n",
    "print oq.oanda2.get_account(oq.aid)['unrealizedPl']\n",
    "\n",
    "fakeTicker(ticker=True)\n",
    "\n",
    "try:\n",
    "    print oq.oanda2.get_positions(oq.aid)['positions'][0]#['units']\n",
    "    print\n",
    "    trades = oq.oanda2.get_trades(oq.aid)['trades']\n",
    "    print p.DataFrame(trades).set_index('id').transpose()#['positions'][0]#['units']\n",
    "except:\n",
    "    ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq.oanda2.get_positions(oq.aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq.oanda2.close_position(oq.aid, 'EUR_USD')\n",
    "oq.oanda2.close_position(oq.aid, 'USD_JPY')\n",
    "oq.oanda2.close_position(oq.aid, 'AUD_JPY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq.trade(5, 30, 'eu', 's')\n",
    "#oq.trade(1, 20, 'au', 'b')\n",
    "#oq.trade(1, 20, 'ej', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#oq.trade(1, 40, 'eu', 's')\n",
    "oq.trade(10, 40, 'au', 's')\n",
    "#oq.trade(3, 400, 'ej', 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def realtimechart(trend):\n",
    "    stop = 86\n",
    "    if trend == 'up':\n",
    "        oq.trade(1, stop, 'uj', 'b')\n",
    "        oq.trade(1, stop, 'eu', 's')\n",
    "    if trend == 'down':\n",
    "        oq.trade(1, stop, 'uj', 's')\n",
    "        oq.trade(1, stop, 'eu', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realtimechart('up')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "realtimechart('down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq.trade(1, 10, 'uj', 's')\n",
    "oq.oanda2.create_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq.sell(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#oq.buy(1, 86) # h1\n",
    "#oq.buy(1, 25) # 30m\n",
    "oq.buy(1, 25) # 1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# source: https://bearcart.readthedocs.org/en/latest/gettingstarted.html\n",
    "import bearcart\n",
    "import pandas as pd\n",
    "\n",
    "html_path = r'index.html'\n",
    "data_path = r'data.json'\n",
    "js_path = r'rickshaw.min.js'\n",
    "css_path = r'rickshaw.min.css'\n",
    "\n",
    "#All of the following import code comes from Wes McKinney's book, Python\n",
    "#for Data Analysis\n",
    "\n",
    "import pandas.io.data as web\n",
    "\n",
    "all_data = {}\n",
    "for ticker in ['AAPL', 'GOOG']:\n",
    "    all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2014', '1/1/2015')\n",
    "\n",
    "price = pd.DataFrame({tic: data['Adj Close']\n",
    "                      for tic, data in all_data.iteritems()})\n",
    "\n",
    "\n",
    "#all_data = {}\n",
    "#for ticker in ['AAPL', 'GOOG', 'XOM', 'MSFT', 'INTC', 'YHOO']:\n",
    "#    all_data[ticker] = web.get_data_yahoo(ticker, '1/1/2014', '1/1/2015')\n",
    "#price = pd.DataFrame({tic: data['Adj Close'] for tic, data in all_data.iteritems()})\n",
    "\n",
    "print price\n",
    "price = price.bfill()\n",
    "price = normalizeme(price)\n",
    "price = sigmoidme(price)\n",
    "#%pylab inline\n",
    "price.plot()\n",
    "\n",
    "#vis = bearcart.Chart(price, plt_type='area')\n",
    "vis = bearcart.Chart(price)\n",
    "vis = bearcart.Chart(price, hover=False, legend=False)\n",
    "\n",
    "#df = pd.concat([price['AAPL'], price['GOOG']], axis=1)[:100]\n",
    "#vis = bearcart.Chart(df, plt_type='scatterplot', colors={'AAPL': '#1d4e69',\n",
    "#                                                         'GOOG': '#3b98ca' })\n",
    "\n",
    "#vis.create_chart(html_path=html_path, data_path=data_path, js_path=js_path, css_path=css_path)\n",
    "\n",
    "# Serving HTTP on 0.0.0.0 port 5556\n",
    "# http://askubuntu.com/questions/377389/how-to-easily-start-a-webserver-in-any-folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dataviz(df):\n",
    "\n",
    "    # source: https://bearcart.readthedocs.org/en/latest/gettingstarted.html\n",
    "    import bearcart\n",
    "    import pandas as pd\n",
    "    import pandas.io.data as web\n",
    "\n",
    "    html_path = r'index.html'\n",
    "    data_path = r'data.json'\n",
    "    js_path = r'rickshaw.min.js'\n",
    "    css_path = r'rickshaw.min.css'\n",
    "\n",
    "    #All of the following import code comes from Wes McKinney's book, Python\n",
    "    #for Data Analysis\n",
    "\n",
    "    %pylab inline\n",
    "    rcParams['figure.figsize'] = 20, 5\n",
    "\n",
    "    df = df.bfill().ffill()\n",
    "    df = normalizeme(df)\n",
    "    df = sigmoidme(df)\n",
    "    df.plot()\n",
    "\n",
    "    #vis = bearcart.Chart(df, plt_type='area')\n",
    "    #vis = bearcart.Chart(df)\n",
    "    vis = bearcart.Chart(df, hover=False, legend=False)\n",
    "\n",
    "    #df = pd.concat([df['AAPL'], df['GOOG']], axis=1)[:100]\n",
    "    #vis = bearcart.Chart(df, plt_type='scatterplot', colors={'AAPL': '#1d4e69',\n",
    "    #                                                         'GOOG': '#3b98ca' })\n",
    "\n",
    "    vis.create_chart(html_path=html_path, data_path=data_path, js_path=js_path, css_path=css_path)\n",
    "    \n",
    "    print 'paste into terminal: cd /ml.dev/bin/datafeeds/; python -m SimpleHTTPServer 5556'\n",
    "    print '         should see: Serving HTTP on 0.0.0.0 port 5556'\n",
    "    # http://askubuntu.com/questions/377389/how-to-easily-start-a-webserver-in-any-folder\n",
    "\n",
    "df = p.read_csv('/mldev/lib/crawlers/finance/dataPipeline.scrapy/investingWorldGovernmentBonds_numbeo.csv')\n",
    "\n",
    "#df.ix[:, 'name\tchg\tcountry\tcurrencyCode\tperiod\thigh\tchgpcnt\tlow\ttime\tprev\tiyield'.split('\t')]\n",
    "#df = df.set_index('name').ix[:, 'chg\thigh\tchgpcnt\tlow\ttime\tprev\tiyield'.split('\t')]\n",
    "df = df.ix[:, 'name\tchg\thigh\tchgpcnt\tlow\ttime\tprev\tiyield'.split('\t')]\n",
    "#df\n",
    "df = df.pivot('time', 'name')['iyield'].bfill().ffill()\n",
    "#dataviz(df)\n",
    "print df.tail(10)\n",
    "df = normalizeme(df)\n",
    "df = sigmoidme(df)\n",
    "#df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "# Connection to Mongo DB\n",
    "try:\n",
    "    conn = pymongo.MongoClient(port=27017)\n",
    "    print \"Connected successfully!!!\"\n",
    "except pymongo.errors.ConnectionFailure, e:\n",
    "    print \"Could not connect to MongoDB: %s\" % e \n",
    "    ''\n",
    "db = conn.numbeo\n",
    "#db.investingWorldGovernmentBondsfind()#.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time, datetime as dd\n",
    "\n",
    "print datetime.datetime.strptime('19/9'+'/2015', '%d/%m/%Y')\n",
    "# '%Y-%m-%dT%H:%M:%S.%fZ'\n",
    "print datetime.datetime.strptime('2015-09-19 '+'08:07:51', '%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[0]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = conn.numbeo\n",
    "#db.numbeo.investingWorldGovernmentBonds.find().length()\n",
    "df = p.DataFrame()\n",
    "for i in db.investingWorldGovernmentBonds2.find()[0:100]:\n",
    "    try:\n",
    "        i['name']\n",
    "        df = df.combine_first(p.DataFrame(i, index=[i['_id']]))\n",
    "    except KeyError as e:\n",
    "        ''\n",
    "#df = df.ix[:,' chg chgpcnt high iyield low prev'.split(' ')]\n",
    "df = df.ix[:,'time'.split(' ')]#.get_values()\n",
    "#df['timei'] = map(lambda x: datetime.datetime.strptime('2015-09-19 '+x, '%Y-%m-%d %H:%M:%S'), df['time'])\n",
    "#df['timei'] = map(lambda x: re.sub(re.compile(r'.*?([\\d]+)\\/([\\d]+).*'), '\\\\1', x), df['time'])\n",
    "df['timei'] = [0]*len(df['time'])\n",
    "print len(df['time'])\n",
    "print len(df['timei'])\n",
    "for i in xrange(len(df['time'])):\n",
    "        #print i\n",
    "        stri = df.ix[i, 'time']\n",
    "        print stri\n",
    "        df.ix[0, 'timei'] = i\n",
    "        print i\n",
    "        #print df.ix[i, 'time']\n",
    "        #try:\n",
    "        res = re.match(re.compile(r'.*?(([\\d]+)\\/([\\d]+)).*'), stri).groups(1)[0]\n",
    "        #print res\n",
    "        df['timei'][0] = res\n",
    "        #except Exception as e:\n",
    "        #    print e\n",
    "        #    ''\n",
    "        #print df.ix[i, 'timei']\n",
    "#df['timei'] = map(lambda x: re.match(re.compile(r'.*?([\\d]+)\\/([\\d]+).*'), x).groups(1), df['time'])\n",
    "print df#.transpose()\n",
    "#db.ticks.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.ix[7,'time'] = None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
