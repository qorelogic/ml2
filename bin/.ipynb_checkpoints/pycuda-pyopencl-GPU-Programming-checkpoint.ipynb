{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!python\n",
      "import pycuda.driver as cuda\n",
      "import pycuda.autoinit\n",
      "from pycuda.compiler import SourceModule\n",
      "import pycuda.gpuarray as gpuarray\n",
      "import numpy as np\n",
      "\n",
      "# Converting the list into numpy array for faster access and putting it into the GPU for processing... \n",
      "start = cuda.Event()\n",
      "end = cuda.Event()\n",
      "\n",
      "N = 222341\n",
      "\n",
      "values = np.random.randn(N)\n",
      "number_of_blocks=N/1024\n",
      "\n",
      "# Calculating the (value-max)/max-min computation and storing it in a numpy array. Pre-calculating the maximum and minimum values.\n",
      "\n",
      "# Space for the Kernel computation..\n",
      "\n",
      "func_mod = SourceModule(\"\"\"\n",
      "// Needed to avoid name mangling so that PyCUDA can\n",
      "// find the kernel function:\n",
      "extern \"C\" {\n",
      "__global__ void func(float *a, int N, float minval, int denom)\n",
      "{\n",
      "int idx = threadIdx.x+threadIdx.y*32+blockIdx.x*blockDim.x;\n",
      "if (idx < N)\n",
      "    a[idx] = (a[idx]-minval)/denom;\n",
      "}\n",
      "}\n",
      "\"\"\", no_extern_c=1)\n",
      "\n",
      "func = func_mod.get_function('func')\n",
      "x = np.asarray(values, np.float32)\n",
      "x_gpu = gpuarray.to_gpu(x)\n",
      "h_minval = np.int32(0)\n",
      "h_denom = np.int32(255)\n",
      "\n",
      "start.record()\n",
      "# a function to the GPU to calculate the computation in the GPU.\n",
      "func(x_gpu.gpudata, np.uint32(N), np.uint32(h_minval), np.uint32(h_denom), block=(1024, 1, 1), grid=(number_of_blocks+1,1,1))\n",
      "end.record() \n",
      "end.synchronize()\n",
      "secs = start.time_till(end)*1e-3\n",
      "\n",
      "print \"SourceModule time\"\n",
      "print \"%fs\" % (secs)\n",
      "print 'x:       ', x[N-1]\n",
      "print 'Func(x): ', x_gpu.get()[N-1],'Actual: ',(values[N-1]-0)/(h_denom)\n",
      "x_colors=x_gpu.get()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "RuntimeError",
       "evalue": "cuInit failed: no device",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-4-03907b697940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSourceModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpuarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgpuarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pycuda/autoinit.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Initialize CUDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_default_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mRuntimeError\u001b[0m: cuInit failed: no device"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# example provided by Eilif Muller\n",
      "\n",
      "from __future__ import division\n",
      "\n",
      "KERNEL_CODE = \"\"\"\n",
      "\n",
      "// Thread block size\n",
      "#define BLOCK_SIZE %(block_size)d\n",
      "\n",
      "// Matrix dimensions\n",
      "// (chosen as multiples of the thread block size for simplicity)\n",
      "#define WA %(w_a)d // Matrix A width\n",
      "#define HA %(h_a)d // Matrix A height\n",
      "#define WB %(w_b)d // Matrix B width\n",
      "#define HB WA  // Matrix B height\n",
      "#define WC WB  // Matrix C width\n",
      "#define HC HA  // Matrix C height\n",
      "\n",
      "\n",
      "/*\n",
      " * Copyright 1993-2009 NVIDIA Corporation.  All rights reserved.\n",
      " *\n",
      " * NVIDIA Corporation and its licensors retain all intellectual property and\n",
      " * proprietary rights in and to this software and related documentation.\n",
      " * Any use, reproduction, disclosure, or distribution of this software\n",
      " * and related documentation without an express license agreement from\n",
      " * NVIDIA Corporation is strictly prohibited.\n",
      " *\n",
      " * Please refer to the applicable NVIDIA end user license agreement (EULA)\n",
      " * associated with this source code for terms and conditions that govern\n",
      " * your use of this NVIDIA software.\n",
      " *\n",
      " */\n",
      "\n",
      "/* Matrix multiplication: C = A * B.\n",
      " * Device code.\n",
      " */\n",
      "\n",
      "#define AS(j, i) As[i + j * BLOCK_SIZE]\n",
      "#define BS(j, i) Bs[i + j * BLOCK_SIZE]\n",
      "\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "//! Matrix multiplication on the device: C = A * B\n",
      "//! WA is A's width and WB is B's width\n",
      "////////////////////////////////////////////////////////////////////////////////\n",
      "__kernel __attribute__((reqd_work_group_size(BLOCK_SIZE,BLOCK_SIZE,1)))\n",
      "void\n",
      "matrixMul( __global float* C, __global float* A, __global float* B)\n",
      "{\n",
      "    __local float As[BLOCK_SIZE*BLOCK_SIZE];\n",
      "    __local float Bs[BLOCK_SIZE*BLOCK_SIZE];\n",
      "\n",
      "    // Block index\n",
      "    int bx = get_group_id(0);\n",
      "    int by = get_group_id(1);\n",
      "\n",
      "    // Thread index\n",
      "    int tx = get_local_id(0);\n",
      "    int ty = get_local_id(1);\n",
      "\n",
      "    // Index of the first sub-matrix of A processed by the block\n",
      "    int aBegin = WA * BLOCK_SIZE * by;\n",
      "\n",
      "    // Index of the last sub-matrix of A processed by the block\n",
      "    int aEnd   = aBegin + WA - 1;\n",
      "\n",
      "    // Step size used to iterate through the sub-matrices of A\n",
      "    int aStep  = BLOCK_SIZE;\n",
      "\n",
      "    // Index of the first sub-matrix of B processed by the block\n",
      "    int bBegin = BLOCK_SIZE * bx;\n",
      "\n",
      "    // Step size used to iterate through the sub-matrices of B\n",
      "    int bStep  = BLOCK_SIZE * WB;\n",
      "\n",
      "    // Csub is used to store the element of the block sub-matrix\n",
      "    // that is computed by the thread\n",
      "    float Csub = 0.0f;\n",
      "\n",
      "    // Loop over all the sub-matrices of A and B\n",
      "    // required to compute the block sub-matrix\n",
      "    for (int a = aBegin, b = bBegin;\n",
      "             a <= aEnd;\n",
      "             a += aStep, b += bStep) {\n",
      "\n",
      "        // Load the matrices from device memory\n",
      "        // to shared memory; each thread loads\n",
      "        // one element of each matrix\n",
      "        AS(ty, tx) = A[a + WA * ty + tx];\n",
      "        BS(ty, tx) = B[b + WB * ty + tx];\n",
      "\n",
      "        // Synchronize to make sure the matrices are loaded\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "\n",
      "        // Multiply the two matrices together;\n",
      "        // each thread computes one element\n",
      "        // of the block sub-matrix\n",
      "        for (int k = 0; k < BLOCK_SIZE; ++k)\n",
      "            Csub += AS(ty, k) * BS(k, tx);\n",
      "\n",
      "        // Synchronize to make sure that the preceding\n",
      "        // computation is done before loading two new\n",
      "        // sub-matrices of A and B in the next iteration\n",
      "        barrier(CLK_LOCAL_MEM_FENCE);\n",
      "    }\n",
      "\n",
      "    // Write the block sub-matrix to device memory;\n",
      "    // each thread writes one element\n",
      "    C[get_global_id(1) * get_global_size(0) + get_global_id(0)] = Csub;\n",
      "\n",
      "}\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import pyopencl as cl\n",
      "from time import time\n",
      "import numpy\n",
      "\n",
      "block_size = 16\n",
      "\n",
      "ctx = cl.create_some_context()\n",
      "\n",
      "for dev in ctx.devices:\n",
      "    assert dev.local_mem_size > 0\n",
      "\n",
      "queue = cl.CommandQueue(ctx,\n",
      "        properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
      "\n",
      "#queue = cl.CommandQueue(ctx)\n",
      "\n",
      "if False:\n",
      "    a_height = 4096\n",
      "    #a_height = 1024\n",
      "    a_width = 2048\n",
      "    #a_width = 256\n",
      "    #b_height == a_width\n",
      "    b_width = a_height\n",
      "\n",
      "elif False:\n",
      "    # like PyCUDA\n",
      "    a_height = 2516\n",
      "    a_width = 1472\n",
      "    b_height = a_width\n",
      "    b_width = 2144\n",
      "\n",
      "else:\n",
      "    # CL SDK\n",
      "    a_width = 50*block_size\n",
      "    a_height = 100*block_size\n",
      "    b_width = 50*block_size\n",
      "    b_height = a_width\n",
      "\n",
      "c_width = b_width\n",
      "c_height = a_height\n",
      "\n",
      "h_a = numpy.random.rand(a_height, a_width).astype(numpy.float32)\n",
      "h_b = numpy.random.rand(b_height, b_width).astype(numpy.float32)\n",
      "h_c = numpy.empty((c_height, c_width)).astype(numpy.float32)\n",
      "\n",
      "\n",
      "kernel_params = {\"block_size\": block_size,\n",
      "        \"w_a\":a_width, \"h_a\":a_height, \"w_b\":b_width}\n",
      "\n",
      "if \"NVIDIA\" in queue.device.vendor:\n",
      "    options = \"-cl-mad-enable -cl-fast-relaxed-math\"\n",
      "else:\n",
      "    options = \"\"\n",
      "prg = cl.Program(ctx, KERNEL_CODE % kernel_params,\n",
      "        ).build(options=options)\n",
      "kernel = prg.matrixMul\n",
      "#print prg.binaries[0]\n",
      "\n",
      "assert a_width % block_size == 0\n",
      "assert a_height % block_size == 0\n",
      "assert b_width % block_size == 0\n",
      "\n",
      "# transfer host -> device -----------------------------------------------------\n",
      "mf = cl.mem_flags\n",
      "\n",
      "t1 = time()\n",
      "\n",
      "d_a_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_a)\n",
      "d_b_buf = cl.Buffer(ctx, mf.READ_ONLY | mf.COPY_HOST_PTR, hostbuf=h_b)\n",
      "d_c_buf = cl.Buffer(ctx, mf.WRITE_ONLY, size=h_c.nbytes)\n",
      "\n",
      "push_time = time()-t1\n",
      "\n",
      "# warmup ----------------------------------------------------------------------\n",
      "for i in range(5):\n",
      "    event = kernel(queue, h_c.shape[::-1], (block_size, block_size),\n",
      "            d_c_buf, d_a_buf, d_b_buf)\n",
      "    event.wait()\n",
      "\n",
      "queue.finish()\n",
      "\n",
      "# actual benchmark ------------------------------------------------------------\n",
      "t1 = time()\n",
      "\n",
      "count = 20\n",
      "for i in range(count):\n",
      "    event = kernel(queue, h_c.shape[::-1], (block_size, block_size),\n",
      "            d_c_buf, d_a_buf, d_b_buf)\n",
      "\n",
      "event.wait()\n",
      "\n",
      "gpu_time = (time()-t1)/count\n",
      "\n",
      "# transfer device -> host -----------------------------------------------------\n",
      "t1 = time()\n",
      "cl.enqueue_copy(queue, h_c, d_c_buf)\n",
      "pull_time = time()-t1\n",
      "\n",
      "# timing output ---------------------------------------------------------------\n",
      "gpu_total_time = gpu_time+push_time+pull_time\n",
      "\n",
      "print \"GPU push+compute+pull total [s]:\", gpu_total_time\n",
      "print \"GPU push [s]:\", push_time\n",
      "print \"GPU pull [s]:\", pull_time\n",
      "print \"GPU compute (host-timed) [s]:\", gpu_time\n",
      "print \"GPU compute (event-timed) [s]: \", (event.profile.end-event.profile.start)*1e-9\n",
      "\n",
      "gflop = h_c.size * (a_width * 2.) / (1000**3.)\n",
      "gflops = gflop / gpu_time\n",
      "\n",
      "print\n",
      "print \"GFlops/s:\", gflops\n",
      "\n",
      "# cpu comparison --------------------------------------------------------------\n",
      "t1 = time()\n",
      "h_c_cpu = numpy.dot(h_a,h_b)\n",
      "cpu_time = time()-t1\n",
      "\n",
      "print\n",
      "print \"GPU==CPU:\",numpy.allclose(h_c, h_c_cpu)\n",
      "print\n",
      "print \"CPU time (s)\", cpu_time\n",
      "print\n",
      "\n",
      "print \"GPU speedup (with transfer): \", cpu_time/gpu_total_time\n",
      "print \"GPU speedup (without transfer): \", cpu_time/gpu_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LogicError",
       "evalue": "clGetPlatformIDs failed: platform not found khr",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-af752ec43234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0mblock_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_some_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/lib/python2.7/dist-packages/pyopencl/__init__.pyc\u001b[0m in \u001b[0;36mcreate_some_context\u001b[0;34m(interactive, answers)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;31m# {{{ pick a platform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m     \u001b[0mplatforms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_platforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mplatforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mLogicError\u001b[0m: clGetPlatformIDs failed: platform not found khr"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyopencl as cl\n",
      "platform = cl.get_platform()\n",
      "my_devices = platform[0].get_devices(device_type = cl.devices_type.ALL)\n",
      "print my_devices\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'module' object has no attribute 'get_platform'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-c7408eed5293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyopencl\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplatform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_platform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmy_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevices_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmy_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'get_platform'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "devices = [ d for d in cl.get_platforms()[0].get_devices(cl.device_type.GPU)]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "LogicError",
       "evalue": "clGetPlatformIDs failed: platform not found khr",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-18-e836c75d38bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_platforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mLogicError\u001b[0m: clGetPlatformIDs failed: platform not found khr"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}