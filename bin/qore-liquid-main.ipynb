{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext memory_profiler\n",
    "%reload_ext line_profiler\n",
    "from qoreliquid import *\n",
    "import pandas as p\n",
    "import numpy as n\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "$x('//div[@id=\"content\"]//div//ul/li[1]/a[@class=\"flexMore\"]/span[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "700-4322-2797\n",
    "print 5207.92 - 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data\n",
    "#te = fetchURL('https://www.quandl.com/api/v2/datasets.json?query=*&source_code=SNB&per_page=300&page=1')\n",
    "\n",
    "for i in te:\n",
    "    print i\n",
    "\n",
    "p.DataFrame(te['docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rtc = RealtimeChart()\n",
    "csvc = \"\"\"EUR_TRY,3.04432,3.04023,2015-06-12T01:45:52.104105Z,1434073552.1\n",
    "EUR_SEK,9.2428,9.23431,2015-06-12T01:45:50.649149Z,1434073550.65\n",
    "EUR_CAD,1.3828,1.38247,2015-06-12T01:45:51.203540Z,1434073551.2\n",
    "EUR_TRY,3.04413,3.03993,2015-06-12T01:45:51.044598Z,1434073551.04\n",
    "EUR_TRY,3.04459,3.03994,2015-06-12T01:45:51.543846Z,1434073551.54\n",
    "EUR_SEK,9.2428,9.23433,2015-06-12T01:45:51.626036Z,1434073551.63\n",
    "EUR_SEK,9.2428,9.23435,2015-06-12T01:45:51.738727Z,1434073551.74\n",
    "EUR_TRY,3.04432,3.04023,2015-06-12T01:45:52.104105Z,1434073552.1\n",
    "EUR_SEK,9.2428,9.23433,2015-06-12T01:45:52.625787Z,1434073552.63\n",
    "EUR_NZD,1.60292,1.6024,2015-06-12T01:45:53.041025Z,1434073553.04\n",
    "EUR_USD,1.12489,1.12472,2015-06-12T01:45:53.252452Z,1434073553.25\n",
    "EUR_TRY,3.04413,3.04043,2015-06-12T01:45:53.404264Z,1434073553.4\"\"\"\n",
    "csvc = csvc.split('\\n')\n",
    "tls  = []\n",
    "for i in csvc:\n",
    "    isi = i.split(',')\n",
    "    #rtc.update(isi)\n",
    "    tls.append(isi)\n",
    "tdf = p.DataFrame(tls)\n",
    "tdf\n",
    "#p.pivot_table(data=tdf, index=[4], columns=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#getDataJPY()\n",
    "qq2.sw.oq.generateRelatedColsFromOandaTickers(self.dfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq2.main(pair='USDJPY', iterations=2000, alpha=0.01, noUpdate=True)\n",
    "tp = qq2.predict()\n",
    "#qq2.tradePrediction(tp)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq2 = QoreQuant()\n",
    "#qq2.updateDatasets('USD', noUpdate=True)\n",
    "qq2.update(pair='USDJPY', granularity='D', noUpdate=False)\n",
    "y = qq2.dfdata.ix[:, qq2.sw.keyCol].fillna(0)\n",
    "print y\n",
    "#list(qq2.sw.higherNextDay(y, qq2.sw.keyCol).get_values()); y.append(0)[y, ymean, ystd] = normalizeme([1,2,3,42,3,421,3], pinv=True)\n",
    "y = sigmoidme(y)\n",
    "y = sigmoidmePinv(y)\n",
    "y = normalizemePinv(y, ymean, ystd)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdir  = '/mldev/bin/datafeeds/models/qorequant'\n",
    "pair = 'EURUSD'\n",
    "granularity = 'D'\n",
    "fname = hdir+'/{0}-{1}.theta.csv'.format(pair, granularity)\n",
    "print fname\n",
    "iter  = 0\n",
    "df0 = p.read_csv(fname, index_col=0)\n",
    "\n",
    "dfT = df0.transpose()\n",
    "df00 = n.sum(dfT.fillna(0), 0)\n",
    "for i in xrange(len(df00)): #.transpose()\n",
    "    sumik = df00.keys()[i]\n",
    "    sumi = list(df00)[i]\n",
    "    dfT = dfT.drop(sumik, axis=1)\n",
    "#print dfT.transpose()\n",
    "df0 = dfT.to_csv(fname)\n",
    "print dfT\n",
    "#getDataJPY()tp['EURUSD'] = tp[0]\n",
    "#tp['EURUSD']def nextBar(dfa, k, barsForward=3):\n",
    "    \n",
    "    dfc = p_DataFrame(dfa, index=dfa.index[0:len(dfa)-barsForward])\n",
    "    #print type(dfc)\n",
    "    a = dfa.ix[0:len(dfa)-barsForward, [k]].get_values()\n",
    "    b = dfa.ix[barsForward:len(dfa),[k]].get_values()\n",
    "    #print len(a)\n",
    "    #print len(b)\n",
    "    dfc['a'] = a\n",
    "    dfc['b'] = b\n",
    "    dfc['c'] = dfc['b']\n",
    "    #print dfc.ix[1:len(dfa),['a','b','c']]\n",
    "    return dfc['c']\n",
    "\n",
    "#qq2.sw.nextBar(qq2.dfdata, qq2.dfdata.columns[1])\n",
    "barsForward=20\n",
    "b = nextBar(qq2.dfdata, qq2.dfdata.columns[1], barsForward=barsForward)\n",
    "dfaa = qq2.dfdata.ix[barsForward:len(qq2.dfdata),[0,1]]\n",
    "print len(b)\n",
    "print len(dfaa)\n",
    "\n",
    "print dfaa\n",
    "print b\n",
    "\n",
    "#qq2.sw.keyCol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nextBar(dfa, k, barsForward=3):\n",
    "    \n",
    "    dfc = p.DataFrame(dfa, index=dfa.index[0:len(dfa)-barsForward])\n",
    "    #print type(dfc)\n",
    "    a = dfa.ix[0:len(dfa)-barsForward, [k]].get_values()\n",
    "    b = dfa.ix[barsForward:len(dfa),[k]].get_values()\n",
    "    #print len(a)\n",
    "    #print len(b)\n",
    "    dfc['a'] = a\n",
    "    dfc['b'] = b\n",
    "    dfc['c'] = dfc['b']\n",
    "    #print dfc.ix[1:len(dfa),['a','b','c']]\n",
    "    return dfc['c']\n",
    "\n",
    "#qq2.sw.nextBar(qq2.dfdata, qq2.dfdata.columns[1])\n",
    "barsForward=20\n",
    "b = nextBar(qq2.dfdata, qq2.dfdata.columns[1], barsForward=barsForward)\n",
    "dfaa = qq2.dfdata.ix[barsForward:len(qq2.dfdata),[0,1]]\n",
    "print len(b)\n",
    "print len(dfaa)\n",
    "\n",
    "print dfaa\n",
    "print b\n",
    "\n",
    "#qq2.sw.keyCol#qq = QoreQuant()\n",
    "mstop = qq.oq.calculateStopLossFromPrice('EUR_USD', 1.113)\n",
    "#qq.forecastCurrency(mode=2, pair='EURUSD', iterations=20000, alpha=0.09, risk=1, stop=mstop)\n",
    "qq.forecastCurrency(mode=4, pair='EURUSD', iterations=20000, alpha=0.09, risk=1, stop=mstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nose.tools import *\n",
    "from qore import *\n",
    "li = [1,2,3,42,3,421,3]\n",
    "[y, ymean, ystd] = normalizeme(li, pinv=True)\n",
    "y = sigmoidme(y)\n",
    "y = sigmoidmePinv(y)\n",
    "y = normalizemePinv(y, ymean, ystd)\n",
    "#assert list(y) == liqq2 = QoreQuant(verbose=False)\n",
    "qq2.main(pair='USDJPY', iterations=2000, alpha=0.01, noUpdate=False)\n",
    "tp = qq2.predict()\n",
    "#qq2.tradePrediction(tp)\n",
    "tp\n",
    "for i in dfa.keys():\n",
    "    print i\n",
    "    print dfa[i].keys()\n",
    "    print \n",
    "    #['EUR_CAD'].keys()qq2 = QoreQuant(verbose=False)\n",
    "qq2.main(pair='USDJPY', iterations=2000, alpha=0.01, noUpdate=False)\n",
    "tp = qq2.predict()\n",
    "#qq2.tradePrediction(tp)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "li = n.array([1,4, 2,1,56,6,7,4,4])\n",
    "li > 3\n",
    "#n.where('>', [1,3,2,4,5], 4, )\n",
    "#n.greater()\n",
    "li[li > 3]tp['EURUSD'] = tp[0]\n",
    "tp['EURUSD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#qq = QoreQuant()\n",
    "mstop = qq.oq.calculateStopLossFromPrice('EUR_USD', 1.113)\n",
    "#qq.forecastCurrency(mode=2, pair='EURUSD', iterations=20000, alpha=0.09, risk=1, stop=mstop)\n",
    "qq.forecastCurrency(mode=4, pair='EURUSD', iterations=20000, alpha=0.09, risk=1, stop=mstop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in dfa.keys():\n",
    "    print i\n",
    "    print dfa[i].keys()\n",
    "    print \n",
    "    #['EUR_CAD'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "li = n.array([1,4, 2,1,56,6,7,4,4])\n",
    "li > 3\n",
    "#n.where('>', [1,3,2,4,5], 4, )\n",
    "#n.greater()\n",
    "li[li > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import pandas as p\n",
    "from qore import mkdir_p\n",
    "\n",
    "hdir = '/mldev/bin/datafeeds/models/qorequant'\n",
    "fname = hdir+'/EURUSD-H4.theta.csv'\n",
    "\n",
    "iterations = 5000\n",
    "try:\n",
    "    df0 = p.read_csv(fname, index_col=0)\n",
    "    iter = max(df0.index[df0.index < iterations])\n",
    "    print iter\n",
    "    print iterations - iter    \n",
    "    initialTheta = df0.ix[iter, :].get_values()\n",
    "    print initialTheta\n",
    "except:\n",
    "    df0 = p.DataFrame()\n",
    "    initialTheta = None\n",
    "initialTheta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from qoreliquid import *\n",
    "df = qq.df\n",
    "df = normalizeme(df)\n",
    "df = n.tanh(df)\n",
    "#df = sigmoidme(df)\n",
    "rcParams['figure.figsize'] = 200, 50\n",
    "df.plot(legend=None); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()\n",
    "#oq.\n",
    "tti = dd.datetime.now()\n",
    "tti = tti+ dd.timedelta(days=30)\n",
    "tti = oq.datetimeToTimestamp(tti)\n",
    "expiry = oq.timestampToDatetimeFormat(tti, fmt='%Y-%m-%dT%H:%M:%S-3:00')\n",
    "# 2014-12-16T13:48:49-05:00\n",
    "print expiry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# signal clients\n",
    "signalClients = {\n",
    "    airmac = ''\n",
    "    tradingview    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.ix[0:len(y)-1, qq.sw.keyCol].get_values()\n",
    "print type(y)\n",
    "print y.ix[0:len(y)-1, :]\n",
    "y.ix[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = qq.df\n",
    "qq.sw.higherNextDay(df, qq.sw.keyCol)\n",
    "\n",
    "y = df.ix[:, [qq.sw.keyCol]].fillna(0)\n",
    "# shift to next bar close\n",
    "y = list(qq.sw.higherNextDay(y, qq.sw.keyCol).get_values()); y.append(0)\n",
    "print y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair='USD_CNY'\n",
    "granularity='H4'\n",
    "#qq.update(pair=pair, granularity=granularity, plot=False)\n",
    "#qq.oq.updateBarsFromOanda(pair=pair, granularities=granularity, plot=True, noUpdate=False)\n",
    "#qq.appendHistoricalPrice(granularity, pair, granularity=granularity, plot=plot)\n",
    "qq.oq.getHistoricalPrice(pair, granularity, plot=True, count=5000)\n",
    "#qq.oq.appendHistoricalPrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs          = ['EUR_USD', 'EUR_NZD', 'NZD_USD', 'USD_JPY', 'USD_CHF', 'AUD_JPY', 'GBP_USD', 'AUD_USD', 'USD_CAD', 'NZD_JPY']#[0]\n",
    "pairs          = ['EUR_USD', 'GBP_USD', 'AUD_USD', 'NZD_USD']\n",
    "granularities  = ['D', 'H4', 'H1', 'M5']#[0]\n",
    "for i in pairs:\n",
    "    print i\n",
    "for i in pairs[0:3]:\n",
    "    for j in granularities[0:4]:\n",
    "        print '{0} {1}'.format(i,j)\n",
    "        qq.update(pair=i, granularity=j, plot=False)\n",
    "#clear_output()\n",
    "qq.predict(wlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq.predict(wlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext memory_profiler\n",
    "%reload_ext line_profiler\n",
    "qq = QoreQuant()\n",
    "%prun qq.update(pair='EUR_USD', granularity='H4', noUpdate=False, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " a = 1092\n",
    "    (-(1092.0/1.10352*1.08278))*1.08278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \n",
    "df['ts4h'] = df['ts'] % float(60*60*4-1)/(24/4)\n",
    "#df['ts4h'] = qq.oq.timestampToDatetime(df['ts'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = qq.oq.getHistoricalPrice('EUR_USD', granularity='H4', count=1000, plot=False)\n",
    "df['ts'] = qq.oq.oandaToTimestamp(df.index)\n",
    "#df\n",
    "#plot(df['ts'], df['closeAsk']); show();\n",
    "\n",
    "#plot(df['ts'], df['closeBid']); show();\n",
    "#scatter(df['ts'], df['closeBid']); show();\n",
    "#scatter(df['closeBid'], df['ts']); show();\n",
    "#plot(df['closeBid'], df['ts']); show();\n",
    "\n",
    "\n",
    "dfd = df.describe()\n",
    "print dfd\n",
    "dfdg = dfd.groupby(by='closeAsk')\n",
    "dfdg = dfdg.aggregate('mean')\n",
    "print dfdg\n",
    "dfdg = dfdg.ix[dfdg['closeBid'] < 2,:]\n",
    "#dfdg['closeBid'].plot()\n",
    "scatter(dfdg['closeBid'], dfdg['ts'])qq.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext memory_profiler\n",
    "%reload_ext line_profiler\n",
    "\n",
    "from qoreliquid import QoreQuant\n",
    "qq = QoreQuant()\n",
    "\n",
    "mode          = 2\n",
    "noUpdate      = 0\n",
    "#pairs         = ['EUR_USD', 'GBP_USD', 'AUD_USD', 'NZD_USD', 'NZD_EUR', 'USD_JPY',  'USD_CHF', 'USD_CAD','GBP_JPY', 'EUR_NZD', 'GBP_NZD', 'AUD_JPY', 'AUD_NZD', 'NZD_JPY']\n",
    "pairs         = ['EUR_USD', 'GBP_USD', 'GBP_JPY', 'EUR_NZD', 'NZD_USD', 'USD_JPY', 'USD_CHF', 'AUD_JPY', 'AUD_USD', 'USD_CAD', 'NZD_JPY']\n",
    "pairs         = ['EUR_USD', 'GBP_USD', 'EUR_JPY', 'GBP_JPY','USD_JPY']\n",
    "pair          = pairs[2]\n",
    "granularities = [ 'H4', 'D','M5', 'H1','M30']\n",
    "granularity   = granularities[1]\n",
    "iterations    = 25000\n",
    "alpha         = 0.125\n",
    "risk          = 2\n",
    "plot          = False\n",
    "stopLossPrice = [1.5648, 1.5566, 0.73488, 1.07978, 1.5617, 1.1024, 1.10965, 1.102, 1.10682, 1.113, 1.10963, 1.10707, 1.0963][0]\n",
    "if mode == 0: noUpdate = 0\n",
    "if mode == 1 or mode == 2: \n",
    "    noUpdate = True\n",
    "#noUpdate = True\n",
    "\n",
    "pair          = pairs[0]\n",
    "granularity   = granularities[0]\n",
    "#%prun qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "#%lprun -f qq.main -f qq.update -f qq.oq.updateBarsFromOanda -f qq.oq.appendHistoricalPrice qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "\n",
    "#qq.oq.getPairsRelatedToOandaTickers(pair.replace('_',''))\n",
    "qq.predict(wlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lis = []\n",
    "lis.append(dd.datetime.now())\n",
    "lis.append(dd.datetime.now())\n",
    "\n",
    "print oq.datetimeToTimestamp(lis)\n",
    "print oq.datetimeToTimestamp(dd.datetime.now())\n",
    "print oq.oandaToTimestamp(tps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()\n",
    "bal = oq.oanda2.get_account(oq.aid)['balance']\n",
    "\n",
    "relatedPairs = qq.oq.getPairsRelatedToOandaTickers('EUR_USD')\n",
    "pairs = list(n.array(p.DataFrame(relatedPairs['lsp']).ix[:,0], dtype=string0))\n",
    "prices = p.DataFrame(oq.oanda2.get_prices(instruments=','.join(pairs))['prices'])\n",
    "cupris = prices.set_index('instrument').ix['EUR_USD',['ask','bid']].transpose().describe()['top']#.ix['EUR_USD',:]\n",
    "\n",
    "trades = p.DataFrame(oq.oanda2.get_trades(oq.aid)['trades'])\n",
    "trades['cprice'] = cupris\n",
    "pl = (trades['price'] - cupris) * trades['units'] * cupris\n",
    "trades['pl'] = pl\n",
    "trades['pips'] = (trades['price'] - cupris) * 10000\n",
    "trades['pcnt'] = pl / bal * 100\n",
    "\n",
    "#print list((trades['instrument'] == 'EUR_USD').index)\n",
    "for i in xrange(len(trades)):\n",
    "    trade = trades.ix[i,:]\n",
    "    pl = trade['pl']\n",
    "    print trade\n",
    "    if pl > 0:\n",
    "        print pl\n",
    "        tid = trade['id']\n",
    "        #oq.oanda2.modify_trade(oq.aid, tid, trailingStop=10)\n",
    "    #break\n",
    "trades.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modifyTrade(instrument, stopLoss=None):\n",
    "    trades = p.DataFrame(oq.oanda2.get_trades(oq.aid)['trades'])\n",
    "    trades['cprice'] = cupris\n",
    "    pl = (trades['price'] - cupris) * trades['units'] * cupris\n",
    "    trades['pl'] = pl\n",
    "    trades['pips'] = (trades['price'] - cupris) * 10000\n",
    "    trades['pcnt'] = pl / bal * 100\n",
    "    \n",
    "    for i in xrange(len(trades)):\n",
    "        trade = trades.ix[i,:]\n",
    "        pl = trade['pl']\n",
    "        #print trade\n",
    "        if pl > 0:\n",
    "            print pl\n",
    "            tid = trade['id']\n",
    "            print trade['instrument']\n",
    "            #oq.oanda2.modify_trade(oq.aid, tid, trailingStop=10)\n",
    "            if trade['instrument'] == instrument:\n",
    "                oq.oanda2.modify_trade(oq.aid, tid, stopLoss=stopLoss)\n",
    "        #break\n",
    "    trades.transpose()\n",
    "modifyTrade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "df = p.read_csv('/home/qore/sec-svn.git/assets/etoro/eToroAccountStatement - manapana - 01-01-2013 - 16-07-2015.csv')\n",
    "#for i in xrange(len(df)-1): df.ix[df.index[i],'Date'] = 'qwe'\n",
    "#df = df.ix[:, 'Realized Equity']\n",
    "print df.columns\n",
    "df = df.ix[:, [1,5,6,7,8]]\n",
    "df = normalizeme(df)\n",
    "#df = sigmoidme(df)\n",
    "df = n.tanh(df)\n",
    "#print df\n",
    "df.ix[600:].plot(logy=False); df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qoreliquid import OandaQ\n",
    "oq = OandaQ()\n",
    "pair = 'EUR_USD'\n",
    "print pair\n",
    "relatedPairs = oq.getPairsRelatedToOandaTickers(pair, mode=1)\n",
    "pairs = list(p.DataFrame(relatedPairs['lsp']).ix[:,0])\n",
    "print len(pairs)\n",
    "#pairs = ','.join(pairs)\n",
    "print pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = [123,456,789]\n",
    "bb = [987,654,321,456]\n",
    "print list(set(aa) & set(bb))\n",
    "print list(set(aa) - set(bb))\n",
    "print list(set(bb) - set(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs          = ['EUR_USD', 'EUR_NZD', 'NZD_USD', 'USD_JPY', 'USD_CHF', 'AUD_JPY', 'GBP_USD', 'AUD_USD', 'USD_CAD', 'NZD_JPY']#[0]\n",
    "pairs          = ['EUR_USD', 'GBP_USD', 'AUD_USD', 'NZD_USD']\n",
    "granularities  = ['D', 'H4', 'H1', 'M5']#[0]\n",
    "for i in pairs:\n",
    "    print i\n",
    "for i in pairs[0:3]:\n",
    "    for j in granularities[0:4]:\n",
    "        print '{0} {1}'.format(i,j)\n",
    "        qq.update(pair=i, granularity=j, plot=False)\n",
    "#clear_output()\n",
    "qq.predict(wlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq.predict(wlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext memory_profiler\n",
    "%reload_ext line_profiler\n",
    "qq = QoreQuant()\n",
    "%prun qq.update(pair='EUR_USD', granularity='H4', noUpdate=False, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " a = 1092\n",
    "    (-(1092.0/1.10352*1.08278))*1.08278"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \n",
    "df['ts4h'] = df['ts'] % float(60*60*4-1)/(24/4)\n",
    "#df['ts4h'] = qq.oq.timestampToDatetime(df['ts'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = qq.oq.getHistoricalPrice('EUR_USD', granularity='H4', count=1000, plot=False)\n",
    "df['ts'] = qq.oq.oandaToTimestamp(df.index)\n",
    "#df\n",
    "#plot(df['ts'], df['closeAsk']); show();\n",
    "\n",
    "#plot(df['ts'], df['closeBid']); show();\n",
    "#scatter(df['ts'], df['closeBid']); show();\n",
    "#scatter(df['closeBid'], df['ts']); show();\n",
    "#plot(df['closeBid'], df['ts']); show();\n",
    "\n",
    "\n",
    "dfd = df.describe()\n",
    "print dfd\n",
    "dfdg = dfd.groupby(by='closeAsk')\n",
    "dfdg = dfdg.aggregate('mean')\n",
    "print dfdg\n",
    "dfdg = dfdg.ix[dfdg['closeBid'] < 2,:]\n",
    "#dfdg['closeBid'].plot()\n",
    "scatter(dfdg['closeBid'], dfdg['ts'])qq.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext memory_profiler\n",
    "%reload_ext line_profiler\n",
    "\n",
    "from qoreliquid import QoreQuant\n",
    "qq = QoreQuant()\n",
    "\n",
    "mode          = 2\n",
    "noUpdate      = 0\n",
    "#pairs         = ['EUR_USD', 'GBP_USD', 'AUD_USD', 'NZD_USD', 'NZD_EUR', 'USD_JPY',  'USD_CHF', 'USD_CAD','GBP_JPY', 'EUR_NZD', 'GBP_NZD', 'AUD_JPY', 'AUD_NZD', 'NZD_JPY']\n",
    "pairs         = ['EUR_USD', 'GBP_USD', 'GBP_JPY', 'EUR_NZD', 'NZD_USD', 'USD_JPY', 'USD_CHF', 'AUD_JPY', 'AUD_USD', 'USD_CAD', 'NZD_JPY']\n",
    "pairs         = ['EUR_USD', 'GBP_USD', 'EUR_JPY', 'GBP_JPY','USD_JPY']\n",
    "pair          = pairs[2]\n",
    "granularities = [ 'H4', 'D','M5', 'H1','M30']\n",
    "granularity   = granularities[1]\n",
    "iterations    = 25000\n",
    "alpha         = 0.125\n",
    "risk          = 2\n",
    "plot          = False\n",
    "stopLossPrice = [1.5648, 1.5566, 0.73488, 1.07978, 1.5617, 1.1024, 1.10965, 1.102, 1.10682, 1.113, 1.10963, 1.10707, 1.0963][0]\n",
    "if mode == 0: noUpdate = 0\n",
    "if mode == 1 or mode == 2: \n",
    "    noUpdate = True\n",
    "#noUpdate = True\n",
    "\n",
    "pair          = pairs[0]\n",
    "granularity   = granularities[0]\n",
    "#%prun qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "#%lprun -f qq.main -f qq.update -f qq.oq.updateBarsFromOanda -f qq.oq.appendHistoricalPrice qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "\n",
    "#qq.oq.getPairsRelatedToOandaTickers(pair.replace('_',''))\n",
    "qq.predict(wlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df = qq.oq.getHistoricalPrice('EUR_USD', granularity='H4', count=1000, plot=False)\n",
    "df['ts'] = qq.oq.oandaToTimestamp(df.index)\n",
    "#df\n",
    "#plot(df['ts'], df['closeAsk']); show();\n",
    "\n",
    "#plot(df['ts'], df['closeBid']); show();\n",
    "#scatter(df['ts'], df['closeBid']); show();\n",
    "#scatter(df['closeBid'], df['ts']); show();\n",
    "#plot(df['closeBid'], df['ts']); show();\n",
    "\n",
    "\n",
    "dfd = df.describe()\n",
    "print dfd\n",
    "dfdg = dfd.groupby(by='closeAsk')\n",
    "dfdg = dfdg.aggregate('mean')\n",
    "print dfdg\n",
    "dfdg = dfdg.ix[dfdg['closeBid'] < 2,:]\n",
    "#dfdg['closeBid'].plot()\n",
    "scatter(dfdg['closeBid'], dfdg['ts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext memory_profiler\n",
    "%reload_ext line_profiler\n",
    "\n",
    "from qoreliquid import QoreQuant\n",
    "qq = QoreQuant()\n",
    "\n",
    "mode          = 2\n",
    "#pairs         = ['EUR_USD', 'GBP_USD', 'AUD_USD', 'NZD_USD', 'NZD_EUR', 'USD_JPY',  'USD_CHF', 'USD_CAD','GBP_JPY', 'EUR_NZD', 'GBP_NZD', 'AUD_JPY', 'AUD_NZD', 'NZD_JPY']\n",
    "pairs         = ['EUR_USD', 'GBP_USD', 'EUR_JPY', 'GBP_JPY','USD_JPY']\n",
    "granularities = [ 'H4', 'D','M5', 'H1','M30']\n",
    "iterations    = 25000\n",
    "alpha         = 0.125\n",
    "risk          = 2\n",
    "plot          = False\n",
    "stopLossPrice = [1.5566, 0.73488, 1.07978, 1.5617, 1.1024, 1.10965, 1.102, 1.10682, 1.113, 1.10963, 1.10707, 1.0963][0]\n",
    "if mode == 0: noUpdate = 0\n",
    "if mode == 1 or mode == 2: \n",
    "    noUpdate = True\n",
    "#noUpdate = True\n",
    "\n",
    "pair          = pairs[0]\n",
    "granularity   = granularities[0]\n",
    "#%prun qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "#%lprun -f qq.main -f qq.update -f qq.oq.updateBarsFromOanda -f qq.oq.appendHistoricalPrice qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "qq.main(mode=mode, pair=pair, granularity=granularity, iterations=iterations, alpha=alpha, risk=risk, stopLossPrice=stopLossPrice, noUpdate=noUpdate, plot=plot)\n",
    "\n",
    "#qq.oq.getPairsRelatedToOandaTickers(pair.replace('_',''))\n",
    "qq.predict(wlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lis = []\n",
    "lis.append(dd.datetime.now())\n",
    "lis.append(dd.datetime.now())\n",
    "\n",
    "print oq.datetimeToTimestamp(lis)\n",
    "print oq.datetimeToTimestamp(dd.datetime.now())\n",
    "print oq.oandaToTimestamp(tps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()\n",
    "bal = oq.oanda2.get_account(oq.aid)['balance']\n",
    "\n",
    "relatedPairs = qq.oq.getPairsRelatedToOandaTickers('EUR_USD')\n",
    "pairs = list(n.array(p.DataFrame(relatedPairs['lsp']).ix[:,0], dtype=string0))\n",
    "prices = p.DataFrame(oq.oanda2.get_prices(instruments=','.join(pairs))['prices'])\n",
    "cupris = prices.set_index('instrument').ix['EUR_USD',['ask','bid']].transpose().describe()['top']#.ix['EUR_USD',:]\n",
    "\n",
    "trades = p.DataFrame(oq.oanda2.get_trades(oq.aid)['trades'])\n",
    "trades['cprice'] = cupris\n",
    "pl = (trades['price'] - cupris) * trades['units'] * cupris\n",
    "trades['pl'] = pl\n",
    "trades['pips'] = (trades['price'] - cupris) * 10000\n",
    "trades['pcnt'] = pl / bal * 100\n",
    "\n",
    "#print list((trades['instrument'] == 'EUR_USD').index)\n",
    "for i in xrange(len(trades)):\n",
    "    trade = trades.ix[i,:]\n",
    "    pl = trade['pl']\n",
    "    #print trade\n",
    "    if pl > 0:\n",
    "        print pl\n",
    "        tid = trade['id']\n",
    "        #oq.oanda2.modify_trade(oq.aid, tid, trailingStop=10)\n",
    "    #break\n",
    "trades.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modifyTrade(instrument, stopLoss=None):\n",
    "    trades = p.DataFrame(oq.oanda2.get_trades(oq.aid)['trades'])\n",
    "    trades['cprice'] = cupris\n",
    "    pl = (trades['price'] - cupris) * trades['units'] * cupris\n",
    "    trades['pl'] = pl\n",
    "    trades['pips'] = (trades['price'] - cupris) * 10000\n",
    "    trades['pcnt'] = pl / bal * 100\n",
    "    \n",
    "    for i in xrange(len(trades)):\n",
    "        trade = trades.ix[i,:]\n",
    "        pl = trade['pl']\n",
    "        #print trade\n",
    "        if pl > 0:\n",
    "            print pl\n",
    "            tid = trade['id']\n",
    "            print trade['instrument']\n",
    "            #oq.oanda2.modify_trade(oq.aid, tid, trailingStop=10)\n",
    "            if trade['instrument'] == instrument:\n",
    "                oq.oanda2.modify_trade(oq.aid, tid, stopLoss=stopLoss)\n",
    "        #break\n",
    "    trades.transpose()\n",
    "modifyTrade()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "df = p.read_csv('/home/qore/sec-svn.git/assets/etoro/eToroAccountStatement - manapana - 01-01-2013 - 16-07-2015.csv')\n",
    "#for i in xrange(len(df)-1): df.ix[df.index[i],'Date'] = 'qwe'\n",
    "#df = df.ix[:, 'Realized Equity']\n",
    "print df.columns\n",
    "df = df.ix[:, [1,5,6,7,8]]\n",
    "df = normalizeme(df)\n",
    "#df = sigmoidme(df)\n",
    "df = n.tanh(df)\n",
    "#print df\n",
    "df.ix[600:].plot(logy=False); df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qoreliquid import OandaQ\n",
    "oq = OandaQ()\n",
    "pair = 'EUR_USD'\n",
    "print pair\n",
    "relatedPairs = oq.getPairsRelatedToOandaTickers(pair, mode=1)\n",
    "pairs = list(p.DataFrame(relatedPairs['lsp']).ix[:,0])\n",
    "print len(pairs)\n",
    "#pairs = ','.join(pairs)\n",
    "print pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = [123,456,789]\n",
    "bb = [987,654,321,456]\n",
    "print list(set(aa) & set(bb))\n",
    "print list(set(aa) - set(bb))\n",
    "print list(set(bb) - set(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sw2 = StatWing()\n",
    "print sw2.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()\n",
    "oth = oq.oandaTransactionHistory(plot=False)\n",
    "othh = oth.ix[1880000000:,'Balance']\n",
    "#for i in xrange(len(othh)-1): othh.ix[othh.index[0],'time'] = 'qwe'\n",
    "#othh = oth.ix[1880000000:,:].set_index('time')\n",
    "othh = oth.ix[:,:]\n",
    "#othh = normalizeme(othh)\n",
    "#othh = sigmoidme(othh)\n",
    "print othh.ix[:,['time', 'Time (UTC)']]\n",
    "print othh.tail(2).transpose()\n",
    "othh.plot(logy=0); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()\n",
    "oth = oq.oandaTransactionHistory(plot=False)\n",
    "#othh = oth.ix[1880000000:,'Balance']\n",
    "for i in xrange(len(othh)-1): othh.ix[othh.index[0],'time'] = 'qwe'\n",
    "#othh = oth.ix[1880000000:,:].set_index('time')\n",
    "othh = oth.ix[:,:]\n",
    "#othh = normalizeme(othh)\n",
    "#othh = sigmoidme(othh)\n",
    "print othh.ix[:,['time', 'Time (UTC)']]\n",
    "print othh.tail(2).transpose()\n",
    "#othh.plot(logy=0); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# oanda equity chart\n",
    "oq = OandaQ()\n",
    "oth = oq.oandaTransactionHistory(plot=False)\n",
    "othh = oth.ix[1480000000:,'Balance']\n",
    "#othh = oth.ix[:,'Balance']\n",
    "#othh = normalizeme(othh)\n",
    "#othh = sigmoidme(othh)\n",
    "othh.plot(logy=0); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2 = p.DataFrame(oth['Balance'].get_values()[len(oth)-10:len(oth)], columns=[2])#.ix[0:10,:]\n",
    "df3 = p.DataFrame(oth['Balance'].get_values()[len(oth)-11:len(oth)], columns=[3])#.ix[0:10,:]\n",
    "dff = df2.combine_first(df3)\n",
    "#dff.ix[:,2] dff.ix[:,2]\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair = 'EURUSD'\n",
    "#pair = 'EURJPY'\n",
    "\n",
    "qq = QoreQuant()\n",
    "#qq.updateDatasets('EUR', noUpdate=False)\n",
    "qq.main(pair=pair, iterations=10000, alpha=0.5, noUpdate=True)\n",
    "\n",
    "#tp['EURUSD'] = tp[0]\n",
    "#tp.ix[:,'EURUSD']\n",
    "\n",
    "tp = qq.predict()\n",
    "#qq.tradePrediction(tp, risk=3)\n",
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq.updateDatasets('EUR', noUpdate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df\n",
    "wlen = 200\n",
    "#sw.predictRegression2(mdf.ix[0:ldf-0, :], quiet=True)\n",
    "ldf = len(data.ix[:, sw.keyCol])\n",
    "\n",
    "\"\"\"\n",
    "try:\n",
    "    nprices = getPricesLatest(data, trueprices=True)\n",
    "    data.ix[p.tslib.Timestamp('2015-06-10').date(), sw.relatedCols] = list(nprices.transpose().ix[0,:])\n",
    "    #print data.ix[p.tslib.Timestamp('2015-06-10'), sw.relatedCols]\n",
    "    #print data\n",
    "    print nprices\n",
    "except:\n",
    "    ''\n",
    "\"\"\"\n",
    "[mdf, dmean, dstd] = normalizeme(data, pinv=True)\n",
    "#tp = sw.predictRegression2(mdf.ix[0:ldf-i, :], quiet=False)\n",
    "tp = p.DataFrame(sw.predictRegression2(mdf.ix[:, :], quiet=True), index=data.index)\n",
    "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
    "plot(tp.ix[ldf-wlen: ldf, :], '.')\n",
    "legend(['price', 'tp'])\n",
    "show();\n",
    "#normalizemePinv(, dmean, dstd)\n",
    "tp.ix[len(tp)-10:len(tp)-0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 5*3\n",
    "fig = plt.figure()\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(sigmoidme(normalizeme(du)),'.')\n",
    "#ax1.title('USD pairs')\n",
    "#legend(d.columns)\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(sigmoidme(normalizeme(de)),'.')\n",
    "#ax2.title('EUR pairs')\n",
    "#ax3 = fig.add_subplot(213)\n",
    "#ax3.plot(sigmoidme(normalizeme(da)))\n",
    "#ax3.title('AUD pairs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test2 normalizeme normalizemePinv\n",
    "data = de.ix[de.index, :].fillna(0)\n",
    "[data, dmean, dstd] = normalizeme(data, pinv=True)\n",
    "#print normalizemePinv(data, dmean, dstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test normalizeme normalizemePinv\n",
    "#print p.read_csv('quandl-BNP-EUR.csv')#.ix[1:1,:]\n",
    "#print de.ix[de.index[0:2], data.columns]\n",
    "#print type(de)\n",
    "#de.ix[de.index[0:2], relatedCols]\n",
    "dfr = de.ix[:,0]\n",
    "dfr2 = p.DataFrame()\n",
    "dfr2[1] = dfr\n",
    "[dfr, dfrmean, dfrstd] = normalizeme(dfr, pinv=True)\n",
    "dfr2[2] = normalizemePinv(dfr, dfrmean, dfrstd)\n",
    "dfr2[3] = dfr2[1] - dfr2[2]\n",
    "#dfr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from qoreliquid import *\n",
    "qq4 = QoreQuant()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as op\n",
    "\n",
    "def Sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z));\n",
    "\n",
    "def Gradient(theta,x,y):\n",
    "    m , n = x.shape\n",
    "    theta = theta.reshape((n,1));\n",
    "    y = y.reshape((m,1))\n",
    "    sigmoid_x_theta = Sigmoid(x.dot(theta));\n",
    "    grad = ((x.T).dot(sigmoid_x_theta-y))/m;\n",
    "    #print grad\n",
    "    #clear_output()\n",
    "    return grad.flatten();\n",
    "\n",
    "def CostFunc(theta,x,y):\n",
    "    m,n = x.shape; \n",
    "    theta = theta.reshape((n,1));\n",
    "    y = y.reshape((m,1));\n",
    "    term1 = np.log(Sigmoid(x.dot(theta)));\n",
    "    term2 = np.log(1-Sigmoid(x.dot(theta)));\n",
    "    term1 = term1.reshape((m,1))\n",
    "    term2 = term2.reshape((m,1))\n",
    "    term = y * term1 + (1 - y) * term2;\n",
    "    J = -((np.sum(term))/m);\n",
    "    print J\n",
    "    clear_output()\n",
    "    return J;\n",
    "\n",
    "# intialize X and y\n",
    "qq4 = QoreQuant()\n",
    "df = qq4.updateDatasets('EUR', noUpdate=True)\n",
    "Xf = df.ix[0:len(df), qq4.sw.relatedCols]\n",
    "X = Xf.get_values()\n",
    "#X = np.array([[1,2,3],[1,3,4]]);\n",
    "#y = np.array([[1],[0]]);\n",
    "\n",
    "\n",
    "mm , nn = X.shape;\n",
    "initial_theta = np.zeros(nn);\n",
    "# source: http://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n",
    "# source: http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_bfgs.html#scipy.optimize.fmin_bfgs\n",
    "#method = 'TNC'\n",
    "method = 'BFGS'\n",
    "Result = op.minimize(fun = CostFunc, x0 = initial_theta, args = (X, y), method = method, jac = Gradient, options={'maxiter':1000});\n",
    "optimal_theta = Result.x;\n",
    "#print Result\n",
    "#print optimal_theta\n",
    "qq4.sw.theta = optimal_theta\n",
    "\n",
    "# save theta\n",
    "pairs = []\n",
    "for i in list(Xf.columns):\n",
    "    pairs.append(re.sub(re.compile(r'.*?-\\ (.*)_x'), '\\\\1', i).replace('/', '_'))\n",
    "dfi = p.DataFrame(sw.theta, index=pairs, columns=['theta'])\n",
    "dfi.to_csv('/mldev/bin/datafeeds/theta.csv')\n",
    "print 'saved theta'\n",
    "print dfi\n",
    "\n",
    "# [ 77.74251037 -25.66308518  -4.0457497 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y.ix[0:5]\n",
    "print X.ix[0:5]\n",
    "print \n",
    "#print X.ix[list(pos.transpose().get_values()[0]), 0]\n",
    "#print X.ix[list(pos.transpose().get_values()[0]), 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2 = p.read_csv('/coursera/ml-007/programming-exercises/mlclass-ex2/ex2data1.txt', header=None)\n",
    "X = data2.ix[:, [0,1]]\n",
    "y = data2.ix[:, [2]]\n",
    "\n",
    "#plot(X, '.')\n",
    "#scatter(X.ix[:,0], X.ix[:,1])\n",
    "\n",
    "pos = p.DataFrame(find(y==1))\n",
    "neg = p.DataFrame(find(y==0))\n",
    "\n",
    "#plot(X.ix[pos, 0], X.ix[pos, 1], 'k+', 'LineWidth', 2, 'MarkerSize', 7);\n",
    "plot(X.ix[list(pos.transpose().get_values()[0]), 0], 'ro')\n",
    "plot(X.ix[list(pos.transpose().get_values()[0]), 1], 'r+')\n",
    "#plot(X.ix[list(pos.transpose()), 0], X.ix[list(pos.transpose()), 1], 'ro')\n",
    "#plot(X.ix[list(neg.transpose()), 0], X.ix[list(neg.transpose()), 1], 'ko')\n",
    "plot(X.ix[list(neg.transpose().get_values()[0]), 0], 'ko')\n",
    "plot(X.ix[list(neg.transpose().get_values()[0]), 1], 'k+')\n",
    "#plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y', 'MarkerSize', 7);\n",
    "\n",
    "# source: http://stackoverflow.com/questions/8486294/how-to-add-an-extra-column-to-an-numpy-array\n",
    "X = n.c_[n.ones(len(X)), X.get_values()]\n",
    "[mm, nn] = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "py.sign_in('cilixian', 'ks48f6mysz')\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "trace0 = Scatter(\n",
    "    x=[1, 2, 3, 4],\n",
    "    y=[10, 15, 13, 17]\n",
    ")\n",
    "trace1 = Scatter(\n",
    "    x=[1, 2, 3, 4],\n",
    "    y=[16, 5, 11, 9]\n",
    ")\n",
    "data = Data([trace0, trace1])\n",
    "\n",
    "unique_url = py.plot(data, filename = 'basic-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[d5, d5mean, d5std] = normalizeme(de, pinv=True)\n",
    "d5 = sigmoidme(d5)\n",
    "d5 = sigmoidmePinv(d5)\n",
    "d5 = normalizemePinv(d5, d5mean, d5std)\n",
    "#d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nprices = getPricesLatest(data, trueprices=True)\n",
    "#print nprices\n",
    "#print n.dot(nprices.ix[:,1].get_values(), nprices.ix[:,0].get_values().reshape(len(nprices), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "#print data.index[len(data)-1]\n",
    "#data.ix[p.tslib.Timestamp('2015-06-10'), sw.\n",
    "relatedCols] = data.ix[p.tslib.Timestamp('2015-06-09'), sw.relatedCols].copy()\n",
    "data.ix[p.tslib.Timestamp('2015-06-10').date(), sw.relatedCols] = list(nprices.transpose().ix[1,:])\n",
    "print data.ix[p.tslib.Timestamp('2015-06-10'), sw.relatedCols]\n",
    "print data.ix[:, sw.relatedCols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = theta\n",
    "#print theta.shape\n",
    "#print X.shape\n",
    "\n",
    "\n",
    "res = p.DataFrame(n.dot(n.c_[n.ones(len(X)), X[:,1:]], theta))\n",
    "res = n.c_[df.ix[0:len(df), sw.relatedCols].ix[:,0], res]\n",
    "print res[len(res)-10:len(res)-1,:]\n",
    "res = normalizeme(res)\n",
    "res = sigmoidme(res)\n",
    "nx = 1000\n",
    "plot(res[len(res)-nx:len(res)-1,0], '-');\n",
    "plot(res[len(res)-nx:len(res)-1:,1], '-'); \n",
    "show();\n",
    "#res = normalizemePinv(theta, dmean.ix[sw.relatedCols].get_values(), dstd.ix[sw.relatedCols].get_values())\n",
    "#p.DataFrame(res, index=dmean.ix[sw.relatedCols].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlen = 2000\n",
    "#sw.predictRegression2(mdf.ix[0:ldf-0, :], quiet=True)\n",
    "ldf = len(data.ix[:, sw.keyCol])\n",
    "[mdf, dmean, dstd] = normalizeme(data, pinv=True)\n",
    "#tp = sw.predictRegression2(mdf.ix[0:ldf-i, :], quiet=False)\n",
    "tp = p.DataFrame(sw.predictRegression2(mdf.ix[:, :], quiet=True), index=data.index)\n",
    "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
    "plot(tp.ix[ldf-wlen: ldf, :]); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wlen = 500\n",
    "data = de.ix[df.index, :]\n",
    "tps = []\n",
    "for i in list(n.array(n.linspace(wlen, 0, wlen), dtype=int)):\n",
    "    ldf = len(data.ix[:, sw.keyCol])\n",
    "    [mdf, dmean, dstd] = normalizeme(data, pinv=True)\n",
    "    tp = sw.predictRegression2(mdf.ix[0:ldf-i, :], quiet=False)\n",
    "    tps.append(tp)\n",
    "    print i\n",
    "    clear_output()\n",
    "tps = n.array(tps)\n",
    "\n",
    "ldf = len(de.ix[:, sw.keyCol])\n",
    "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
    "plot(tps, '.')\n",
    "legend(['price', 'target tp'])\n",
    "#df.ix[:, sw.keyCol];\n",
    "#plot(n.array(tp * n.ones(len(dfp))));\n",
    "show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
    "plot(p.DataFrame(tps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ldf = len(de.ix[:, sw.keyCol])\n",
    "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
    "plot(tps, '-')\n",
    "legend(['price', 'target tp'])\n",
    "#df.ix[:, sw.keyCol];\n",
    "#plot(n.array(tp * n.ones(len(dfp))));\n",
    "show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pair2 = ''+pair[0:3]+'_'+pair[3:6]+''\n",
    "print pair2\n",
    "price = oanda2.get_prices(instruments=[pair2])#['ask']\n",
    "\"\"\"\n",
    "if price > tp:\n",
    "    side = 'sell'\n",
    "else:\n",
    "    side = 'buy'\n",
    "\"\"\"\n",
    "aid = 61519\n",
    "oanda2.get_account(aid)\n",
    "#oanda2.create_order(aid, type='market', instrument=''+pair[0:3]+'_'+pair[3:6]+'', side=side, units=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#predictionss['eurgbp'] = [1,2]\n",
    "#predictionss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data.ix[:, relatedCols]\n",
    "#X.ix[:,1:]#.ix[:,0]\n",
    "#X.ix[:,data.columns[relatedCols].insert(0,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print theta\n",
    "print p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print theta\n",
    "\n",
    "#p1.insert(0, 'bias')\n",
    "print p1\n",
    "for i in xrange(len(p1)):\n",
    "    try:\n",
    "        p1[i] = re.findall(re.compile(r'.+\\.([\\w]+).+'), p1[i])[0]\n",
    "    except:\n",
    "        ''\n",
    "#df2 = p.DataFrame()\n",
    "#df2['theta'] = theta\n",
    "#df2['lables'] = p1\n",
    "#df2\n",
    "\n",
    "sw = StatWing()\n",
    "sw.predictRegression(theta, p1, mode=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictionss = p.read_csv('predictlions.csv', index_col=0)\n",
    "#p.DataFrame(predictionss).to_csv(pdc)\n",
    "predictionss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import oandapy\n",
    "import pandas as p\n",
    "\n",
    "fns = [\n",
    "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurusd-001.csv',\n",
    "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurjpy-002.csv',\n",
    "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurusd-004.csv',\n",
    "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurgbp-005.csv',\n",
    "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurchf-006.csv',\n",
    "]\n",
    "\n",
    "fns2 = [\n",
    "    './datafeeds/models/statwing/card_export-quandl-BNP-USD-csv-export-model-usdjpy-007.csv',\n",
    "]\n",
    "\n",
    "#statwingExportPredict(fns)\n",
    "sw.statwingExportPredict(fns2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# QSTK Imports\n",
    "import QSTK.qstkutil.qsdateutil as du\n",
    "import QSTK.qstkutil.tsutil as tsu\n",
    "import QSTK.qstkutil.DataAccess as da\n",
    "\n",
    "# Third Party Imports\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import shutil as shu\n",
    "\n",
    "from qore_qstk import getFrontier\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {1: p.tslib.Timestamp('2013-01-03 00:00:00', tz=None), 2: p.tslib.Timestamp('2013-01-04 00:00:00', tz=None), 3: p.tslib.Timestamp('2013-01-03 00:00:00', tz=None)}\n",
    "df = p.DataFrame(data, index=[0]).transpose()\n",
    "df[1] = [1,2,3]\n",
    "df = df.set_index(0)\n",
    "print df\n",
    "\n",
    "#print oq.timestampToNumpyTimestamp(df.index)\n",
    "\n",
    "#tss = p.tslib.Timestamp('2013-01-03 00:00:00', tz=None)\n",
    "#tss.to_datetime()\n",
    "#tss = oq.oandaToTimestamp(['2004-07-04T21:00:00.000000Z'])\n",
    "#tss = oq.timestampToNumpyTimestamp(tss)\n",
    "#tss = oq.numpyTimestampToTslibTimestamp(tss)\n",
    "#tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#p.tslib.tz_convert\n",
    "###\n",
    "\n",
    "#Create the data\n",
    "data = {1: p.tslib.Timestamp('2013-01-03 00:00:00', tz=None), 2: p.tslib.Timestamp('2013-01-04 00:00:00', tz=None), 3: p.tslib.Timestamp('2013-01-03 00:00:00', tz=None)}\n",
    "\n",
    "#convert to df\n",
    "print df\n",
    "df = p.DataFrame.from_dict(data, orient = 'index')\n",
    "print df\n",
    "df.columns = ['timestamp']\n",
    "\n",
    "#generate the datetime\n",
    "df['datetime'] = df['timestamp'].apply(lambda x: datetime.date(x.year,x.month,x.day))\n",
    "\n",
    "data\n",
    "\n",
    "#p.tslib.Timestamp(-9223372036854775808)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "oq = OandaQ()\n",
    "def getPair(pair, gran):\n",
    "    \n",
    "    df = p.read_csv('/mldev/bin/data/oanda/ticks/{0}/{0}-{1}.csv'.format(pair, gran)).set_index('time').ix[:,'closeAsk closeBid volume'.split(' ')]\n",
    "    df['timeTslib'] = oq.oandaToTslibTimeStamp(df.index)\n",
    "    df[pair] = df['closeAsk']\n",
    "    df = df.set_index('timeTslib').ix[:,[pair]]\n",
    "    return df\n",
    "\n",
    "def source2():\n",
    "    \n",
    "    df = oq.oanda2.get_instruments(oq.aid)\n",
    "    df = p.DataFrame(df['instruments'])\n",
    "    syms = list(df.ix[:,'instrument'])\n",
    "    #syms = 'AUD_CAD EUR_USD GBP_USD AUD_USD USD_CAD'\n",
    "    #syms = syms.split(' ')\n",
    "    dfs = p.DataFrame()\n",
    "    for i in syms:\n",
    "        try:\n",
    "            dfs = dfs.combine_first(getPair(i, 'D'))\n",
    "        except Exception as e:\n",
    "            print e\n",
    "    #dfs.plot(); show();\n",
    "    dfs = dfs.ffill().bfill()\n",
    "\n",
    "    return {'df_close':dfs, 'df_close_test':dfs}\n",
    "\n",
    "def source():\n",
    "    \n",
    "    # S&P 100\n",
    "    #ls_symbols = ['AAPL', 'ABT', 'ACN', 'AEP', 'ALL', 'AMGN', 'AMZN', 'APC', 'AXP', 'BA', 'BAC', 'BAX', 'BHI', 'BK', 'BMY', 'BRK.B', 'CAT', 'C', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CPB', 'CSCO', 'CVS', 'CVX', 'DD', 'DELL', 'DIS', 'DOW', 'DVN', 'EBAY', 'EMC', 'EXC', 'F', 'FCX', 'FDX', 'GD', 'GE', 'GILD', 'GOOG', 'GS', 'HAL', 'HD', 'HNZ', 'HON', 'HPQ', 'IBM', 'INTC', 'JNJ', 'JPM', 'KFT', 'KO', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDT', 'MET', 'MMM', 'MO', 'MON', 'MRK', 'MS', 'MSFT', 'NKE', 'NOV', 'NSC', 'NWSA', 'NYX', 'ORCL', 'OXY', 'PEP', 'PFE', 'PG', 'PM', 'QCOM', 'RF', 'RTN', 'SBUX', 'SLB', 'HSH', 'SO', 'SPG', 'T', 'TGT', 'TWX', 'TXN', 'UNH', 'UPS', 'USB', 'UTX', 'VZ', 'WAG', 'WFC', 'WMB', 'WMT', 'XOM']\n",
    "    ls_symbols = ['AAPL', 'ABT', 'ACN', 'AEP', 'ALL', 'AMGN', 'AMZN']\n",
    "    \n",
    "    # Creating an object of the dataaccess class with Yahoo as the source.\n",
    "    c_dataobj = da.DataAccess('Yahoo')\n",
    "    \n",
    "    ls_all_syms = c_dataobj.get_all_symbols()\n",
    "    # Bad symbols are symbols present in portfolio but not in all syms\n",
    "    ls_bad_syms = list(set(ls_symbols) - set(ls_all_syms))\n",
    "    for s_sym in ls_bad_syms:\n",
    "        i_index = ls_symbols.index(s_sym)\n",
    "        ls_symbols.pop(i_index)\n",
    "    \n",
    "    # Start and End date of the charts\n",
    "    dt_end = dt.datetime(2010, 1, 1)\n",
    "    dt_start = dt_end - dt.timedelta(days=365)\n",
    "    dt_test = dt_end + dt.timedelta(days=365)\n",
    "    \n",
    "    # We need closing prices so the timestamp should be hours=16.\n",
    "    dt_timeofday = dt.timedelta(hours=16)\n",
    "    \n",
    "    # Get a list of trading days between the start and the end.\n",
    "    ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
    "    ldt_timestamps_test = du.getNYSEdays(dt_end, dt_test, dt_timeofday)\n",
    "    \n",
    "    # Reading just the close prices\n",
    "    df_close = c_dataobj.get_data(ldt_timestamps, ls_symbols, \"close\")\n",
    "    df_close_test = c_dataobj.get_data(ldt_timestamps_test, ls_symbols, \"close\")\n",
    "    \n",
    "    return {'df_close':df_close, 'df_close_test':df_close_test}\n",
    "\n",
    "def main():\n",
    "    \n",
    "    '''Main Function'''\n",
    "    \n",
    "    src = source2()\n",
    "    df_close      = src['df_close']\n",
    "    df_close_test = src['df_close_test']    \n",
    "    \n",
    "    #print type(df_close.index[0])\n",
    "    #return df_close\n",
    "    \n",
    "    # Filling the data for missing NAN values\n",
    "    df_close = df_close.fillna(method='ffill')\n",
    "    df_close = df_close.fillna(method='bfill')\n",
    "    df_close_test = df_close_test.fillna(method='ffill')\n",
    "    df_close_test = df_close_test.fillna(method='bfill')\n",
    "    \n",
    "    # Copying the data values to a numpy array to get returns\n",
    "    na_data = df_close.values.copy()\n",
    "    na_data_test = df_close_test.values.copy()\n",
    "    \n",
    "    # Getting the daily returns\n",
    "    tsu.returnize0(na_data)\n",
    "    tsu.returnize0(na_data_test)\n",
    "    \n",
    "    # Calculating the frontier.\n",
    "    (lf_returns, lf_std, lna_portfolios, na_avgrets, na_std) = getFrontier(na_data)\n",
    "    (lf_returns_test, lf_std_test, unused, unused, unused) = getFrontier(na_data_test)\n",
    "    \n",
    "    # Plotting the efficient frontier\n",
    "    plt.clf()\n",
    "    plt.plot(lf_std, lf_returns, 'b')\n",
    "    plt.plot(lf_std_test, lf_returns_test, 'r')\n",
    "    \n",
    "    # Plot where the efficient frontier would be the following year\n",
    "    lf_ret_port_test = []\n",
    "    lf_std_port_test = []\n",
    "    for na_portfolio in lna_portfolios:\n",
    "        na_port_rets = np.dot(na_data_test, na_portfolio)\n",
    "        lf_std_port_test.append(np.std(na_port_rets))\n",
    "        lf_ret_port_test.append(np.average(na_port_rets))\n",
    "    \n",
    "    plt.plot(lf_std_port_test, lf_ret_port_test, 'k')\n",
    "    \n",
    "    # Plot indivisual stock risk/return as green +\n",
    "    print na_avgrets\n",
    "    for i, f_ret in enumerate(na_avgrets):\n",
    "        print i\n",
    "        print f_ret\n",
    "        plt.plot(na_std[i], f_ret, 'g+')\n",
    "    \n",
    "    # # Plot some arrows showing transistion of efficient frontier\n",
    "    # for i in range(0, 101, 10):\n",
    "    #     plt.arrow(lf_std[i], lf_returns[i], lf_std_port_test[i] - lf_std[i],\n",
    "    #                 lf_ret_port_test[i] - lf_returns[i], color='k')\n",
    "    \n",
    "    # Labels and Axis\n",
    "    plt.legend(['2009 Frontier', '2010 Frontier',\n",
    "        'Performance of \\'09 Frontier in 2010'], loc='lower right')\n",
    "    plt.title('Efficient Frontier For S&P 100 ')\n",
    "    plt.ylabel('Expected Return')\n",
    "    plt.xlabel('StDev')\n",
    "    #plt.savefig('tutorial8.pdf', format='pdf')\n",
    "    plt.show()\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# S&P 100\n",
    "ls_symbols = ['AAPL', 'ABT', 'ACN', 'AEP', 'ALL', 'AMGN', 'AMZN', 'APC', 'AXP', 'BA', 'BAC', 'BAX', 'BHI', 'BK', 'BMY', 'BRK.B', 'CAT', 'C', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CPB', 'CSCO', 'CVS', 'CVX', 'DD', 'DELL', 'DIS', 'DOW', 'DVN', 'EBAY', 'EMC', 'EXC', 'F', 'FCX', 'FDX', 'GD', 'GE', 'GILD', 'GOOG', 'GS', 'HAL', 'HD', 'HNZ', 'HON', 'HPQ', 'IBM', 'INTC', 'JNJ', 'JPM', 'KFT', 'KO', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDT', 'MET', 'MMM', 'MO', 'MON', 'MRK', 'MS', 'MSFT', 'NKE', 'NOV', 'NSC', 'NWSA', 'NYX', 'ORCL', 'OXY', 'PEP', 'PFE', 'PG', 'PM', 'QCOM', 'RF', 'RTN', 'SBUX', 'SLB', 'HSH', 'SO', 'SPG', 'T', 'TGT', 'TWX', 'TXN', 'UNH', 'UPS', 'USB', 'UTX', 'VZ', 'WAG', 'WFC', 'WMB', 'WMT', 'XOM']\n",
    "print len(ls_symbols)\n",
    "\n",
    "# Creating an object of the dataaccess class with Yahoo as the source.\n",
    "c_dataobj = da.DataAccess('Yahoo')\n",
    "\n",
    "ls_all_syms = c_dataobj.get_all_symbols()\n",
    "\n",
    "# Bad symbols are symbols present in portfolio but not in all syms\n",
    "ls_bad_syms = list(set(ls_symbols) - set(ls_all_syms))\n",
    "for s_sym in ls_bad_syms:\n",
    "    i_index = ls_symbols.index(s_sym)\n",
    "    ls_symbols.pop(i_index)\n",
    "\n",
    "# Start and End date of the charts\n",
    "dt_end = dt.datetime(2010, 1, 1)\n",
    "dt_start = dt_end - dt.timedelta(days=365)\n",
    "dt_test = dt_end + dt.timedelta(days=365)\n",
    "\n",
    "# We need closing prices so the timestamp should be hours=16.\n",
    "dt_timeofday = dt.timedelta(hours=16)\n",
    "\n",
    "# Get a list of trading days between the start and the end.\n",
    "ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
    "ldt_timestamps_test = du.getNYSEdays(dt_end, dt_test, dt_timeofday)\n",
    "\n",
    "# Reading just the close prices\n",
    "df_close = c_dataobj.get_data(ldt_timestamps, ls_symbols, \"close\")\n",
    "df_close_test = c_dataobj.get_data(ldt_timestamps_test, ls_symbols, \"close\")\n",
    "\n",
    "# Filling the data for missing NAN values\n",
    "df_close = df_close.fillna(method='ffill')\n",
    "df_close = df_close.fillna(method='bfill')\n",
    "df_close_test = df_close_test.fillna(method='ffill')\n",
    "df_close_test = df_close_test.fillna(method='bfill')\n",
    "\n",
    "# Copying the data values to a numpy array to get returns\n",
    "na_data = df_close.values.copy()\n",
    "na_data_test = df_close_test.values.copy()\n",
    "\n",
    "# Getting the daily returns\n",
    "tsu.returnize0(na_data)\n",
    "tsu.returnize0(na_data_test)\n",
    "\n",
    "print 'end'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the frontier.\n",
    "(lf_returns, lf_std, lna_portfolios, na_avgrets, na_std) = getFrontier(na_data)\n",
    "(lf_returns_test, lf_std_test, unused, unused, unused) = getFrontier(na_data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = pd.DataFrame()\n",
    "d['lf_returns'] = lf_returns\n",
    "d['lf_std'] = lf_std\n",
    "d['lf_std_test'] = lf_std_test\n",
    "plot(d); legend(d,2); show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "d = pd.DataFrame()\n",
    "for i, f in enumerate(na_avgrets):\n",
    "    #print str(i) + ' ' + str(f) + ' ' + str(na_std[i])\n",
    "    #plt.plot(na_std[i], f)\n",
    "    ''\n",
    "#plt.plot(na_std, na_avgrets, '.')\n",
    "#print na_avgrets\n",
    "#plot(na_avgrets)\n",
    "#plot(na_std)\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plotting the efficient frontier\n",
    "plt.clf()\n",
    "plt.plot(lf_std, lf_returns, 'b')\n",
    "#print str(lf_std) + ' ' + str(lf_returns)\n",
    "#print len(lf_std)\n",
    "#print len(lf_returns)\n",
    "#for i in range(0,len(lf_std)):\n",
    "#    print str(lf_std[i]) + ' ' + str(lf_returns[i])\n",
    "plt.plot(lf_std_test, lf_returns_test, 'r')\n",
    "\n",
    "\n",
    "# Plot where the efficient frontier would be the following year\n",
    "lf_ret_port_test = []\n",
    "lf_std_port_test = []\n",
    "for na_portfolio in lna_portfolios:\n",
    "    na_port_rets = np.dot(na_data_test, na_portfolio)\n",
    "    lf_std_port_test.append(np.std(na_port_rets))\n",
    "    lf_ret_port_test.append(np.average(na_port_rets))\n",
    "\n",
    "plt.plot(lf_std_port_test, lf_ret_port_test, 'k')\n",
    "\n",
    "# Plot indivisual stock risk/return as green +\n",
    "#for i, f_ret in enumerate(na_avgrets):\n",
    "#    plt.plot(na_std[i], f_ret, 'g+')\n",
    "for i, f_ret in enumerate(na_avgrets):\n",
    "#    print str(i) + str(na_avgrets[i]) + ' ' + str(f_ret)\n",
    "    plt.plot(na_std[i], f_ret, 'g+')\n",
    "#plt.plot(na_std, na_avgrets, '.')\n",
    "# # Plot some arrows showing transistion of efficient frontier\n",
    "for i in range(0, 101, 10):\n",
    "#for i in range(0, 10, 1):\n",
    "#    print i\n",
    "    #plt.plot(lf_std[i], lf_returns[i], lf_std_port_test[i] - lf_std[i], lf_ret_port_test[i] - lf_returns[i], color='r')\n",
    "    plt.plot(lf_std_port_test[i], lf_ret_port_test[i], 'ok')\n",
    "    plt.plot(lf_std[i], lf_returns[i], 'ok')\n",
    "\n",
    "# Labels and Axis\n",
    "plt.legend(['2014 Frontier', '2015 Frontier', 'Performance of \\'14 Frontier in 2015'], loc='lower right')\n",
    "plt.title('Efficient Frontier For S&P 100 ')\n",
    "plt.ylabel('Expected Return')\n",
    "plt.xlabel('StDev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(lf_std, lf_returns, '.b')\n",
    "for i, f_ret in enumerate(na_avgrets):\n",
    "    plt.plot(na_std[i], f_ret, 'g+')\n",
    "\n",
    "ddistances = []\n",
    "#for i in range(0,len(na_std)):\n",
    "#for i in range(0,10+1):\n",
    "for i in [0,1,2]:\n",
    "    ddistance = []\n",
    "    #for j in range(0,len(na_std)):\n",
    "    for j in range(3,6):\n",
    "        std = [na_std[i], lf_std[j]]\n",
    "        ret = [na_avgrets[i], lf_returns[j]]\n",
    "        dstd = abs(diff(std))\n",
    "        dret = abs(diff(ret))\n",
    "        ddist = list(n.sqrt(n.power(dstd,2)+n.power(dret,2)))[0]\n",
    "        ddistance.append(ddist)\n",
    "        \"\"\"\n",
    "        print 'std:'+str(std)\n",
    "        print 'dstd:'+str(dstd)\n",
    "        print 'ret:'+str(ret)\n",
    "        print 'dret:'+str(dret)\n",
    "        print 'ddistance:'+str(ddistance)\n",
    "        \"\"\"\n",
    "        #print str(i) + ' ' + str(j) + ' dstd:'+str(dstd) + '   ' + 'dret:'+str(dret) + '   ' + 'ddist:'+str(ddist)\n",
    "        plt.plot(std, ret, '-k')\n",
    "    print\n",
    "    ddistances.append(ddistance)\n",
    "#print n.array(ddistances)\n",
    "ddistances = pd.DataFrame(ddistances).transpose()\n",
    "#print ddistances\n",
    "#print n.min(ddistances)\n",
    "#print n.indices(n.min(ddistances))\n",
    "#plt.plot(ddistances)\n",
    "\n",
    "# find the index number of the minimum for each column\n",
    "#dt = n.array([[1,2,3,4,5],[2,2,1,2,3]])\n",
    "#dt = pd.DataFrame(dt).transpose()\n",
    "#print ddistances\n",
    "dt = ddistances\n",
    "dt = pd.DataFrame(dt)\n",
    "#print dt\n",
    "#print n.min(dt)\n",
    "lowDt = pd.DataFrame(n.array(dt == n.min(dt), dtype=int))\n",
    "#print lowDt\n",
    "#print pd.DataFrame(n.min(dt)).transpose()\n",
    "finz = n.nonzero(lowDt.get_values()) # get row indeces of 1's\n",
    "print finz\n",
    "fin = pd.DataFrame([list(finz[0]),list(finz[1])]).transpose()\n",
    "#fin = pd.DataFrame(index=list(finz[0]), columns=list(finz[1]))\n",
    "print 'len:'+str(len(fin.columns))\n",
    "ln = n.array(pd.DataFrame(list(n.min(dt))).ix[finz[1],0])\n",
    "fin[2] = ln\n",
    "print fin.transpose()\n",
    "\n",
    "for i in range(0,len(finz[0])):\n",
    "    #print dt.ix[finz[0][i], finz[1][i]]\n",
    "    std = [na_std[finz[1][i]], lf_std[finz[0][i]-1]]\n",
    "    ret = [na_avgrets[finz[1][i]], lf_returns[finz[0][i]-1]]\n",
    "    plt.plot(std, ret, '-k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,3):\n",
    "    for j in range(0,3):\n",
    "        print dt.sort(columns=[j]).get_values()[i][j]\n",
    "    print\n",
    "#print dt.sort(columns=[0]).ix[0,:]\n",
    "print dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools \n",
    "\n",
    "fig=plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "all_data = [[1,10],[2,10],[3,10],[4,10],[5,10],[3,1],[3,2],[3,3],[3,4],[3,5]]\n",
    "print itertools.combinations(all_data, 2)\n",
    "plt.plot(    *zip(*itertools.chain.from_iterable(itertools.combinations(all_data, 2))),    color = 'brown', marker = 'o')\n",
    "#plt.plot(   all_data,    color = 'brown', marker = 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_data = [[1,10],[2,10],[3,10],[4,10],[5,10],[3,1],[3,2],[3,3],[3,4],[3,5]]\n",
    "for point in all_data:\n",
    "    for point2 in all_data:\n",
    "        #print str(point) + '' + str(point2)\n",
    "        pyplot.plot([point[0], point2[0]], [point[1], point2[1]])\n",
    "    #print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y = diff(lf_returns[0:101])/diff(lf_std[0:101])\n",
    "y = diff(lf_returns[0:101])/diff(lf_std[0:101])\n",
    "#print y\n",
    "plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.plot(lf_std, lf_returns, '.b')\n",
    "#plt.plot(lf_returns, lf_std, 'b')\n",
    "#plt.plot(lf_std, ones(len(lf_std)), 'r')\n",
    "#plt.plot(lf_std)\n",
    "#plt.plot(lf_returns)\n",
    "ylabel('lf_std')\n",
    "xlabel('lf_returns')\n",
    "dy = diff(lf_std)\n",
    "dx = diff(lf_returns)\n",
    "dydx = dy/dx\n",
    "plot(dydx)\n",
    "#plot(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dydx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# numerical derivative\n",
    "# source: http://web.archive.org/web/20110514123948/http://wiki.octave.org/wiki.pl?CategorySymbolic\n",
    "t = linspace(-6,6,100)\n",
    "#y = sin(t)\n",
    "import numpy as n\n",
    "y = t*t\n",
    "dydt = diff(y)/diff(t)\n",
    "plot(y)\n",
    "plot(dydt)\n",
    "legend(['y','dy/dt'])\n",
    "#plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plt.legend(['2009 Frontier', '2010 Frontier', 'Performance of \\'09 Frontier in 2010'], loc='lower right')\n",
    "plt.savefig('tutorial8.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# QoreQuant\n",
    "# compinvesting-001\n",
    "# video 1 - 9 Computing inside a hedge fund .mp4\n",
    "\n",
    "#qstrader.py\n",
    "#qsoptimizer.py\n",
    "#qsforecaster.py\n",
    "\n",
    "#%reset\n",
    "\n",
    "import pandas as p\n",
    "import numpy as n\n",
    "import time\n",
    "from threading import Thread\n",
    "\t\n",
    "# Trading Algorithm\n",
    "class QsTrader(Thread):\n",
    "    def __init__(self):\n",
    "        Thread.__init__(self)\n",
    "        # getters\n",
    "        self.historical      = None\n",
    "        self.targetPortfolio = None\n",
    "        self.livePortfolio   = None\n",
    "        \n",
    "        # setters\n",
    "        self.orders = None\n",
    "        \n",
    "    def run(self):\n",
    "        while 1:\n",
    "            #self.check()\n",
    "            self.gotoMarket()\n",
    "            time.sleep(1e-1)            \n",
    "    \n",
    "    def getHistoricalPriceData(self):\n",
    "        ''\n",
    "        \n",
    "    # portfolio_X.h5\n",
    "    def getTargetPortfolio(self):\n",
    "        optimizer = QsOptimizer()\n",
    "        self.targetPortfolio = optimizer.generateTargetPortfolio()\n",
    "        return self.targetPortfolio\n",
    "        \n",
    "    # portfolio_LIVE.h5\n",
    "    def getLivePortfolio(self):\n",
    "        # live portfolio\n",
    "        # todo: get live portfolio from broker (keep persistent connection)\n",
    "        livePortfolio = p.DataFrame([100,-200,50,-500], index=['AAPL','BAC','BOA','DAL'], columns=['live_amount'])\n",
    "        self.livePortfolio = livePortfolio\n",
    "        return livePortfolio\n",
    "\n",
    "    # orders_V.h5\n",
    "    def generateOrders(self):\n",
    "        fname = 'orders_V.csv'\n",
    "        # orders\n",
    "        indx = []        \n",
    "        orders = p.DataFrame(n.zeros(len(indx)), index=indx, columns=['orders_amount'])\n",
    "        self.orders = orders\n",
    "        return orders\n",
    "\n",
    "    def sendOrders(self):\n",
    "        # send orders only if there are orders to send\n",
    "        # else do nothing        \n",
    "        if n.sum(n.array(self.orders)) != 0:\n",
    "            print 'detected pending orders.'\n",
    "            print self.orders\n",
    "            print 'sending orders to market..'\n",
    "            print\n",
    "    \n",
    "    def gotoMarket(self):\n",
    "        targetPortfolio = self.getTargetPortfolio()\n",
    "        #print 'target portfolio'\n",
    "        #print targetPortfolio\n",
    "        #print\n",
    "        livePortfolio = self.getLivePortfolio()\n",
    "        #print 'live portfolio'\n",
    "        #print livePortfolio\n",
    "        #print\n",
    "        orders = self.generateOrders()\n",
    "        #print 'orders'\n",
    "        #print orders\n",
    "        #print\n",
    "        #self.sendOrders()\n",
    "        \n",
    "        pp = p.DataFrame()\n",
    "        pp = pp.combine_first(targetPortfolio)\n",
    "        pp = pp.combine_first(livePortfolio)\n",
    "        pp = pp.combine_first(orders)\n",
    "        pp['orders_amount'] = n.diff(n.array(pp.ix[:,['live_amount','target_amount']]))\n",
    "        self.orders = pp.ix[:,'orders_amount'].fillna(0)        \n",
    "        self.orders = self.orders.ix[list(n.nonzero(n.array(self.orders != 0, dtype=int))[0])]\n",
    "        #print self.orders        \n",
    "        self.sendOrders()\n",
    "\n",
    "# Portfolio Optimizer\n",
    "class QsOptimizer:\n",
    "    def __init__(self):\n",
    "        # getters\n",
    "        self.livePortfolio   = None\n",
    "        self.nDayForecast    = None\n",
    "        self.riskConstraints = None\n",
    "        \n",
    "        # setters\n",
    "        self.targetPortfolio = None\n",
    "    \n",
    "    def getLivePortfolio(self):\n",
    "        trader = QsTrader()\n",
    "        self.livePortfolio = trader.getLivePortfolio()\n",
    "        \n",
    "    def getNDayForecast(self):\n",
    "        forecaster = QsForecaster()\n",
    "        self.forecaster = forecaster.getNDayForecast()\n",
    "        \n",
    "    def getRiskConstraints(self):\n",
    "        ''\n",
    "        \n",
    "    def generateTargetPortfolio(self):\n",
    "        # target portfolio\n",
    "        targetPortfolio = p.DataFrame([100,0,50,-550], index=['AAPL','BAC','BOA','DAL'], columns=['target_amount'])\n",
    "        self.targetPortfolio = targetPortfolio\n",
    "        return targetPortfolio\n",
    "\n",
    "# Forecasting Algorithm\n",
    "class QsForecaster:\n",
    "        def __init__(self):\n",
    "            # getters\n",
    "            self.informationFeed   = None\n",
    "            self.historical        = None\n",
    "            self.machineLearning   = None\n",
    "            \n",
    "            # setters\n",
    "            self.nDayForecast = Null\n",
    "        \n",
    "        def getInformationFeed(self):\n",
    "            ''\n",
    "        \n",
    "        def getHistorical(self):\n",
    "            trader = QsTrader()\n",
    "            self.historical = trader.getHistoricalPriceData()\n",
    "        \n",
    "        def getMachineLearning(self):\n",
    "            ''\n",
    "        \n",
    "        def generateNDayForecast(self):\n",
    "            ''\n",
    "    \n",
    "trader = QsTrader()\n",
    "\n",
    "def main():\n",
    "    trader.start()\n",
    "\n",
    "def test():\n",
    "    trader.gotoMarket()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #main()\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import uncertainties as unc  \n",
    "import uncertainties.unumpy as unumpy  \n",
    "import numpy  \n",
    "import nemmen  \n",
    "\n",
    "# Defines x and y  \n",
    "x=numpy.linspace(0,10,50)  \n",
    "y=numpy.linspace(15,20,50)  \n",
    "\n",
    "# Defines the error arrays, values follow a normal distribution  \n",
    "# (method random_normal defined in http://astropython.blogspot.com/2012/04/how-to-generate-array-of-random-numbers.html)  \n",
    "errx=nemmen.random_normal(0.1,0.2,50);     errx=numpy.abs(errx)  \n",
    "erry=nemmen.random_normal(0.3,0.2,50);     erry=numpy.abs(erry)  \n",
    "\n",
    "# Defines special arrays holding the values *and* errors  \n",
    "x=unumpy.uarray(( x, errx ))  \n",
    "y=unumpy.uarray(( y, erry ))  \n",
    "\n",
    "\"\"\"  \n",
    "Now any operation that you carry on xerr and yerr will   \n",
    "automatically propagate the associated errors, as long  \n",
    "as you use the methods provided with uncertainties.unumpy  \n",
    "instead of using the numpy methods.  \n",
    "\n",
    "Let's for instance define z as   \n",
    "z = log10(x+y**2)  \n",
    "and estimate errz.  \n",
    "\"\"\"  \n",
    "z=unumpy.log10(x+y**2)  \n",
    "\n",
    "# Print the propagated error errz  \n",
    "errz=unumpy.std_devs(z)  \n",
    "print errz  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oq = OandaQ()\n",
    "pairs = oq.prepPairsForOandaStream('EUR_USD')\n",
    "pairs\n",
    "#print 'streamlen: {0}'.format(len(pairs.split(',')))\n",
    "#print len(pairs.split(',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
