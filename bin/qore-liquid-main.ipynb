{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload\n",
      "%autoreload 2\n",
      "from qoreliquid import *\n",
      "import pandas as p\n",
      "import numpy as n\n",
      "from pylab import rcParams\n",
      "rcParams['figure.figsize'] = 20, 5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "$x('//div[@id=\"content\"]//div//ul/li[1]/a[@class=\"flexMore\"]/span[1]')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "700-4322-2797\n",
      "print 5207.92 - 230"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data\n",
      "#te = fetchURL('https://www.quandl.com/api/v2/datasets.json?query=*&source_code=SNB&per_page=300&page=1')\n",
      "\n",
      "for i in te:\n",
      "    print i\n",
      "\n",
      "p.DataFrame(te['docs'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# source: http://scikit-image.org/\n",
      "from skimage import data, io, filters\n",
      "image = data.coins() # or any NumPy array!\n",
      "edges = filters.sobel(image)\n",
      "io.imshow(edges)\n",
      "io.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#rtc = RealtimeChart()\n",
      "csvc = \"\"\"EUR_TRY,3.04432,3.04023,2015-06-12T01:45:52.104105Z,1434073552.1\n",
      "EUR_SEK,9.2428,9.23431,2015-06-12T01:45:50.649149Z,1434073550.65\n",
      "EUR_CAD,1.3828,1.38247,2015-06-12T01:45:51.203540Z,1434073551.2\n",
      "EUR_TRY,3.04413,3.03993,2015-06-12T01:45:51.044598Z,1434073551.04\n",
      "EUR_TRY,3.04459,3.03994,2015-06-12T01:45:51.543846Z,1434073551.54\n",
      "EUR_SEK,9.2428,9.23433,2015-06-12T01:45:51.626036Z,1434073551.63\n",
      "EUR_SEK,9.2428,9.23435,2015-06-12T01:45:51.738727Z,1434073551.74\n",
      "EUR_TRY,3.04432,3.04023,2015-06-12T01:45:52.104105Z,1434073552.1\n",
      "EUR_SEK,9.2428,9.23433,2015-06-12T01:45:52.625787Z,1434073552.63\n",
      "EUR_NZD,1.60292,1.6024,2015-06-12T01:45:53.041025Z,1434073553.04\n",
      "EUR_USD,1.12489,1.12472,2015-06-12T01:45:53.252452Z,1434073553.25\n",
      "EUR_TRY,3.04413,3.04043,2015-06-12T01:45:53.404264Z,1434073553.4\"\"\"\n",
      "csvc = csvc.split('\\n')\n",
      "tls  = []\n",
      "for i in csvc:\n",
      "    isi = i.split(',')\n",
      "    #rtc.update(isi)\n",
      "    tls.append(isi)\n",
      "tdf = p.DataFrame(tls)\n",
      "tdf\n",
      "#p.pivot_table(data=tdf, index=[4], columns=[1,2])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "qq2 = QoreQuant()\n",
      "#qq2.updateDatasets('USD', noUpdate=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#getDataJPY()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "qq2.main(pair='USDJPY', iterations=2000, alpha=0.01, noUpdate=True)\n",
      "tp = qq2.predict()\n",
      "#qq2.tradePrediction(tp)\n",
      "tp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nose.tools import *\n",
      "from qore import *\n",
      "li = [1,2,3,42,3,421,3]\n",
      "[y, ymean, ystd] = normalizeme(li, pinv=True)\n",
      "y = sigmoidme(y)\n",
      "y = sigmoidmePinv(y)\n",
      "y = normalizemePinv(y, ymean, ystd)\n",
      "assert list(y) == li"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AssertionError",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-22-343a18bd26e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoidmePinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalizemePinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mymean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mystd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mAssertionError\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pair = 'EURUSD'\n",
      "#pair = 'EURJPY'\n",
      "\n",
      "qq3 = QoreQuant()\n",
      "#qq3.updateDatasets('EUR', noUpdate=False)\n",
      "qq3.main(pair=pair, iterations=2000, alpha=0.09, noUpdate=True)\n",
      "\n",
      "#tp['EURUSD'] = tp[0]\n",
      "#tp.ix[:,'EURUSD']\n",
      "\n",
      "tp = qq3.predict()\n",
      "#qq3.tradePrediction(tp, risk=3)\n",
      "tp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "updateBarsFromOanda()\n",
        "global name 'data' is not defined"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "ename": "UnboundLocalError",
       "evalue": "local variable 'mstop' referenced before assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-6-b5bcc0116930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqq3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQoreQuant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#qq3.updateDatasets('EUR', noUpdate=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mqq3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.09\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoUpdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#tp['EURUSD'] = tp[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/media/sda6/opt/nfs/ml.dev/bin/qoreliquid.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, mode, pair, granularity, iterations, alpha, risk, stopLossPrice, noUpdate, plot)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mmmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforecastCurrency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrisk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrisk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgranularity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;31m#print self.oq.granularities[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'mstop' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "."
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "pair = 'EURUSD'\n",
      "#pair = 'EURJPY'\n",
      "\n",
      "qq = QoreQuant()\n",
      "#qq.updateDatasets('EUR', noUpdate=False)\n",
      "qq.main(pair=pair, iterations=10000, alpha=0.5, noUpdate=True)\n",
      "\n",
      "#tp['EURUSD'] = tp[0]\n",
      "#tp.ix[:,'EURUSD']\n",
      "\n",
      "tp = qq.predict()\n",
      "#qq.tradePrediction(tp, risk=3)\n",
      "tp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "updateBarsFromOanda()\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        "global name 'data' is not defined\n",
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . . . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". . . 'H4'\n",
        ". "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". "
       ]
      },
      {
       "ename": "UnboundLocalError",
       "evalue": "local variable 'mstop' referenced before assignment",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-25-097093977a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mqq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQoreQuant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#qq.updateDatasets('EUR', noUpdate=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mqq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoUpdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#tp['EURUSD'] = tp[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/media/sda6/opt/nfs/ml.dev/bin/qoreliquid.pyc\u001b[0m in \u001b[0;36mmain\u001b[0;34m(self, mode, pair, granularity, iterations, alpha, risk, stopLossPrice, noUpdate, plot)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;31m# shift keyCol up ct cells\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;31m#ct = 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;31m#dfb = p.DataFrame(index=self.df.ix[0:len(self.df)-ct, 0].index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'mstop' referenced before assignment"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        ". . 'H4'\n",
        ". ."
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "qq.updateDatasets('EUR', noUpdate=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = df\n",
      "wlen = 200\n",
      "#sw.predictRegression2(mdf.ix[0:ldf-0, :], quiet=True)\n",
      "ldf = len(data.ix[:, sw.keyCol])\n",
      "\n",
      "\"\"\"\n",
      "try:\n",
      "    nprices = getPricesLatest(data, trueprices=True)\n",
      "    data.ix[p.tslib.Timestamp('2015-06-10').date(), sw.relatedCols] = list(nprices.transpose().ix[0,:])\n",
      "    #print data.ix[p.tslib.Timestamp('2015-06-10'), sw.relatedCols]\n",
      "    #print data\n",
      "    print nprices\n",
      "except:\n",
      "    ''\n",
      "\"\"\"\n",
      "[mdf, dmean, dstd] = normalizeme(data, pinv=True)\n",
      "#tp = sw.predictRegression2(mdf.ix[0:ldf-i, :], quiet=False)\n",
      "tp = p.DataFrame(sw.predictRegression2(mdf.ix[:, :], quiet=True), index=data.index)\n",
      "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
      "plot(tp.ix[ldf-wlen: ldf, :], '.')\n",
      "legend(['price', 'tp'])\n",
      "show();\n",
      "#normalizemePinv(, dmean, dstd)\n",
      "tp.ix[len(tp)-10:len(tp)-0, :]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pylab import rcParams\n",
      "rcParams['figure.figsize'] = 20, 5*3\n",
      "fig = plt.figure()\n",
      "\n",
      "ax1 = fig.add_subplot(211)\n",
      "ax1.plot(sigmoidme(normalizeme(du)),'.')\n",
      "#ax1.title('USD pairs')\n",
      "#legend(d.columns)\n",
      "ax2 = fig.add_subplot(212)\n",
      "ax2.plot(sigmoidme(normalizeme(de)),'.')\n",
      "#ax2.title('EUR pairs')\n",
      "#ax3 = fig.add_subplot(213)\n",
      "#ax3.plot(sigmoidme(normalizeme(da)))\n",
      "#ax3.title('AUD pairs')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test2 normalizeme normalizemePinv\n",
      "data = de.ix[de.index, :].fillna(0)\n",
      "[data, dmean, dstd] = normalizeme(data, pinv=True)\n",
      "#print normalizemePinv(data, dmean, dstd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test normalizeme normalizemePinv\n",
      "#print p.read_csv('quandl-BNP-EUR.csv')#.ix[1:1,:]\n",
      "#print de.ix[de.index[0:2], data.columns]\n",
      "#print type(de)\n",
      "#de.ix[de.index[0:2], relatedCols]\n",
      "dfr = de.ix[:,0]\n",
      "dfr2 = p.DataFrame()\n",
      "dfr2[1] = dfr\n",
      "[dfr, dfrmean, dfrstd] = normalizeme(dfr, pinv=True)\n",
      "dfr2[2] = normalizemePinv(dfr, dfrmean, dfrstd)\n",
      "dfr2[3] = dfr2[1] - dfr2[2]\n",
      "#dfr2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%reload_ext autoreload\n",
      "%autoreload 2\n",
      "from qoreliquid import *\n",
      "qq4 = QoreQuant()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy.optimize as op\n",
      "\n",
      "def Sigmoid(z):\n",
      "    return 1/(1 + np.exp(-z));\n",
      "\n",
      "def Gradient(theta,x,y):\n",
      "    m , n = x.shape\n",
      "    theta = theta.reshape((n,1));\n",
      "    y = y.reshape((m,1))\n",
      "    sigmoid_x_theta = Sigmoid(x.dot(theta));\n",
      "    grad = ((x.T).dot(sigmoid_x_theta-y))/m;\n",
      "    #print grad\n",
      "    #clear_output()\n",
      "    return grad.flatten();\n",
      "\n",
      "def CostFunc(theta,x,y):\n",
      "    m,n = x.shape; \n",
      "    theta = theta.reshape((n,1));\n",
      "    y = y.reshape((m,1));\n",
      "    term1 = np.log(Sigmoid(x.dot(theta)));\n",
      "    term2 = np.log(1-Sigmoid(x.dot(theta)));\n",
      "    term1 = term1.reshape((m,1))\n",
      "    term2 = term2.reshape((m,1))\n",
      "    term = y * term1 + (1 - y) * term2;\n",
      "    J = -((np.sum(term))/m);\n",
      "    print J\n",
      "    clear_output()\n",
      "    return J;\n",
      "\n",
      "# intialize X and y\n",
      "qq4 = QoreQuant()\n",
      "df = qq4.updateDatasets('EUR', noUpdate=True)\n",
      "Xf = df.ix[0:len(df), qq4.sw.relatedCols]\n",
      "X = Xf.get_values()\n",
      "#X = np.array([[1,2,3],[1,3,4]]);\n",
      "#y = np.array([[1],[0]]);\n",
      "\n",
      "\n",
      "mm , nn = X.shape;\n",
      "initial_theta = np.zeros(nn);\n",
      "# source: http://stackoverflow.com/questions/18801002/fminunc-alternate-in-numpy\n",
      "# source: http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_bfgs.html#scipy.optimize.fmin_bfgs\n",
      "#method = 'TNC'\n",
      "method = 'BFGS'\n",
      "Result = op.minimize(fun = CostFunc, x0 = initial_theta, args = (X, y), method = method, jac = Gradient, options={'maxiter':1000});\n",
      "optimal_theta = Result.x;\n",
      "#print Result\n",
      "#print optimal_theta\n",
      "qq4.sw.theta = optimal_theta\n",
      "\n",
      "# save theta\n",
      "pairs = []\n",
      "for i in list(Xf.columns):\n",
      "    pairs.append(re.sub(re.compile(r'.*?-\\ (.*)_x'), '\\\\1', i).replace('/', '_'))\n",
      "dfi = p.DataFrame(sw.theta, index=pairs, columns=['theta'])\n",
      "dfi.to_csv('/mldev/bin/datafeeds/theta.csv')\n",
      "print 'saved theta'\n",
      "print dfi\n",
      "\n",
      "# [ 77.74251037 -25.66308518  -4.0457497 ]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print y.ix[0:5]\n",
      "print X.ix[0:5]\n",
      "print \n",
      "#print X.ix[list(pos.transpose().get_values()[0]), 0]\n",
      "#print X.ix[list(pos.transpose().get_values()[0]), 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "data2 = p.read_csv('/coursera/ml-007/programming-exercises/mlclass-ex2/ex2data1.txt', header=None)\n",
      "X = data2.ix[:, [0,1]]\n",
      "y = data2.ix[:, [2]]\n",
      "\n",
      "#plot(X, '.')\n",
      "#scatter(X.ix[:,0], X.ix[:,1])\n",
      "\n",
      "pos = p.DataFrame(find(y==1))\n",
      "neg = p.DataFrame(find(y==0))\n",
      "\n",
      "#plot(X.ix[pos, 0], X.ix[pos, 1], 'k+', 'LineWidth', 2, 'MarkerSize', 7);\n",
      "plot(X.ix[list(pos.transpose().get_values()[0]), 0], 'ro')\n",
      "plot(X.ix[list(pos.transpose().get_values()[0]), 1], 'r+')\n",
      "#plot(X.ix[list(pos.transpose()), 0], X.ix[list(pos.transpose()), 1], 'ro')\n",
      "#plot(X.ix[list(neg.transpose()), 0], X.ix[list(neg.transpose()), 1], 'ko')\n",
      "plot(X.ix[list(neg.transpose().get_values()[0]), 0], 'ko')\n",
      "plot(X.ix[list(neg.transpose().get_values()[0]), 1], 'k+')\n",
      "#plot(X(neg, 1), X(neg, 2), 'ko', 'MarkerFaceColor', 'y', 'MarkerSize', 7);\n",
      "\n",
      "# source: http://stackoverflow.com/questions/8486294/how-to-add-an-extra-column-to-an-numpy-array\n",
      "X = n.c_[n.ones(len(X)), X.get_values()]\n",
      "[mm, nn] = X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import plotly.plotly as py\n",
      "py.sign_in('cilixian', 'ks48f6mysz')\n",
      "from plotly.graph_objs import *\n",
      "\n",
      "trace0 = Scatter(\n",
      "    x=[1, 2, 3, 4],\n",
      "    y=[10, 15, 13, 17]\n",
      ")\n",
      "trace1 = Scatter(\n",
      "    x=[1, 2, 3, 4],\n",
      "    y=[16, 5, 11, 9]\n",
      ")\n",
      "data = Data([trace0, trace1])\n",
      "\n",
      "unique_url = py.plot(data, filename = 'basic-line')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "[d5, d5mean, d5std] = normalizeme(de, pinv=True)\n",
      "d5 = sigmoidme(d5)\n",
      "d5 = sigmoidmePinv(d5)\n",
      "d5 = normalizemePinv(d5, d5mean, d5std)\n",
      "#d5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#nprices = getPricesLatest(data, trueprices=True)\n",
      "#print nprices\n",
      "#print n.dot(nprices.ix[:,1].get_values(), nprices.ix[:,0].get_values().reshape(len(nprices), 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = df.copy()\n",
      "#print data.index[len(data)-1]\n",
      "#data.ix[p.tslib.Timestamp('2015-06-10'), sw.\n",
      "relatedCols] = data.ix[p.tslib.Timestamp('2015-06-09'), sw.relatedCols].copy()\n",
      "data.ix[p.tslib.Timestamp('2015-06-10').date(), sw.relatedCols] = list(nprices.transpose().ix[1,:])\n",
      "print data.ix[p.tslib.Timestamp('2015-06-10'), sw.relatedCols]\n",
      "print data.ix[:, sw.relatedCols]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "res = theta\n",
      "#print theta.shape\n",
      "#print X.shape\n",
      "\n",
      "\n",
      "res = p.DataFrame(n.dot(n.c_[n.ones(len(X)), X[:,1:]], theta))\n",
      "res = n.c_[df.ix[0:len(df), sw.relatedCols].ix[:,0], res]\n",
      "print res[len(res)-10:len(res)-1,:]\n",
      "res = normalizeme(res)\n",
      "res = sigmoidme(res)\n",
      "nx = 1000\n",
      "plot(res[len(res)-nx:len(res)-1,0], '-');\n",
      "plot(res[len(res)-nx:len(res)-1:,1], '-'); \n",
      "show();\n",
      "#res = normalizemePinv(theta, dmean.ix[sw.relatedCols].get_values(), dstd.ix[sw.relatedCols].get_values())\n",
      "#p.DataFrame(res, index=dmean.ix[sw.relatedCols].index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wlen = 2000\n",
      "#sw.predictRegression2(mdf.ix[0:ldf-0, :], quiet=True)\n",
      "ldf = len(data.ix[:, sw.keyCol])\n",
      "[mdf, dmean, dstd] = normalizeme(data, pinv=True)\n",
      "#tp = sw.predictRegression2(mdf.ix[0:ldf-i, :], quiet=False)\n",
      "tp = p.DataFrame(sw.predictRegression2(mdf.ix[:, :], quiet=True), index=data.index)\n",
      "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
      "plot(tp.ix[ldf-wlen: ldf, :]); show();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "wlen = 500\n",
      "data = de.ix[df.index, :]\n",
      "tps = []\n",
      "for i in list(n.array(n.linspace(wlen, 0, wlen), dtype=int)):\n",
      "    ldf = len(data.ix[:, sw.keyCol])\n",
      "    [mdf, dmean, dstd] = normalizeme(data, pinv=True)\n",
      "    tp = sw.predictRegression2(mdf.ix[0:ldf-i, :], quiet=False)\n",
      "    tps.append(tp)\n",
      "    print i\n",
      "    clear_output()\n",
      "tps = n.array(tps)\n",
      "\n",
      "ldf = len(de.ix[:, sw.keyCol])\n",
      "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
      "plot(tps, '.')\n",
      "legend(['price', 'target tp'])\n",
      "#df.ix[:, sw.keyCol];\n",
      "#plot(n.array(tp * n.ones(len(dfp))));\n",
      "show();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
      "plot(p.DataFrame(tps))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ldf = len(de.ix[:, sw.keyCol])\n",
      "plot(de.ix[ldf-wlen: ldf, sw.keyCol])\n",
      "plot(tps, '-')\n",
      "legend(['price', 'target tp'])\n",
      "#df.ix[:, sw.keyCol];\n",
      "#plot(n.array(tp * n.ones(len(dfp))));\n",
      "show();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pair2 = ''+pair[0:3]+'_'+pair[3:6]+''\n",
      "print pair2\n",
      "price = oanda2.get_prices(instruments=[pair2])#['ask']\n",
      "\"\"\"\n",
      "if price > tp:\n",
      "    side = 'sell'\n",
      "else:\n",
      "    side = 'buy'\n",
      "\"\"\"\n",
      "aid = 61519\n",
      "oanda2.get_account(aid)\n",
      "#oanda2.create_order(aid, type='market', instrument=''+pair[0:3]+'_'+pair[3:6]+'', side=side, units=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#predictionss['eurgbp'] = [1,2]\n",
      "#predictionss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#data.ix[:, relatedCols]\n",
      "#X.ix[:,1:]#.ix[:,0]\n",
      "#X.ix[:,data.columns[relatedCols].insert(0,0)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print theta\n",
      "print p1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print theta\n",
      "\n",
      "#p1.insert(0, 'bias')\n",
      "print p1\n",
      "for i in xrange(len(p1)):\n",
      "    try:\n",
      "        p1[i] = re.findall(re.compile(r'.+\\.([\\w]+).+'), p1[i])[0]\n",
      "    except:\n",
      "        ''\n",
      "#df2 = p.DataFrame()\n",
      "#df2['theta'] = theta\n",
      "#df2['lables'] = p1\n",
      "#df2\n",
      "\n",
      "sw = StatWing()\n",
      "sw.predictRegression(theta, p1, mode=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test\n",
      "theta"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictionss = p.read_csv('predictlions.csv', index_col=0)\n",
      "#p.DataFrame(predictionss).to_csv(pdc)\n",
      "predictionss"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "import oandapy\n",
      "import pandas as p\n",
      "\n",
      "fns = [\n",
      "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurusd-001.csv',\n",
      "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurjpy-002.csv',\n",
      "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurusd-004.csv',\n",
      "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurgbp-005.csv',\n",
      "    './datafeeds/models/statwing/card_export-quandl-BNP-EUR-csv-export-model-eurchf-006.csv',\n",
      "]\n",
      "\n",
      "fns2 = [\n",
      "    './datafeeds/models/statwing/card_export-quandl-BNP-USD-csv-export-model-usdjpy-007.csv',\n",
      "]\n",
      "\n",
      "#statwingExportPredict(fns)\n",
      "sw.statwingExportPredict(fns2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictions.pop()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    '''Main Function'''\n",
      "    \n",
      "    # S&P 100\n",
      "    ls_symbols = ['AAPL', 'ABT', 'ACN', 'AEP', 'ALL', 'AMGN', 'AMZN', 'APC', 'AXP', 'BA', 'BAC', 'BAX', 'BHI', 'BK', 'BMY', 'BRK.B', 'CAT', 'C', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CPB', 'CSCO', 'CVS', 'CVX', 'DD', 'DELL', 'DIS', 'DOW', 'DVN', 'EBAY', 'EMC', 'EXC', 'F', 'FCX', 'FDX', 'GD', 'GE', 'GILD', 'GOOG', 'GS', 'HAL', 'HD', 'HNZ', 'HON', 'HPQ', 'IBM', 'INTC', 'JNJ', 'JPM', 'KFT', 'KO', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDT', 'MET', 'MMM', 'MO', 'MON', 'MRK', 'MS', 'MSFT', 'NKE', 'NOV', 'NSC', 'NWSA', 'NYX', 'ORCL', 'OXY', 'PEP', 'PFE', 'PG', 'PM', 'QCOM', 'RF', 'RTN', 'SBUX', 'SLB', 'HSH', 'SO', 'SPG', 'T', 'TGT', 'TWX', 'TXN', 'UNH', 'UPS', 'USB', 'UTX', 'VZ', 'WAG', 'WFC', 'WMB', 'WMT', 'XOM']\n",
      "    \n",
      "    # Creating an object of the dataaccess class with Yahoo as the source.\n",
      "    c_dataobj = da.DataAccess('Yahoo')\n",
      "    \n",
      "    ls_all_syms = c_dataobj.get_all_symbols()\n",
      "    # Bad symbols are symbols present in portfolio but not in all syms\n",
      "    ls_bad_syms = list(set(ls_symbols) - set(ls_all_syms))\n",
      "    for s_sym in ls_bad_syms:\n",
      "        i_index = ls_symbols.index(s_sym)\n",
      "        ls_symbols.pop(i_index)\n",
      "    \n",
      "    # Start and End date of the charts\n",
      "    dt_end = dt.datetime(2010, 1, 1)\n",
      "    dt_start = dt_end - dt.timedelta(days=365)\n",
      "    dt_test = dt_end + dt.timedelta(days=365)\n",
      "    \n",
      "    # We need closing prices so the timestamp should be hours=16.\n",
      "    dt_timeofday = dt.timedelta(hours=16)\n",
      "    \n",
      "    # Get a list of trading days between the start and the end.\n",
      "    ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
      "    ldt_timestamps_test = du.getNYSEdays(dt_end, dt_test, dt_timeofday)\n",
      "    \n",
      "    # Reading just the close prices\n",
      "    df_close = c_dataobj.get_data(ldt_timestamps, ls_symbols, \"close\")\n",
      "    df_close_test = c_dataobj.get_data(ldt_timestamps_test, ls_symbols, \"close\")\n",
      "    \n",
      "    # Filling the data for missing NAN values\n",
      "    df_close = df_close.fillna(method='ffill')\n",
      "    df_close = df_close.fillna(method='bfill')\n",
      "    df_close_test = df_close_test.fillna(method='ffill')\n",
      "    df_close_test = df_close_test.fillna(method='bfill')\n",
      "    \n",
      "    # Copying the data values to a numpy array to get returns\n",
      "    na_data = df_close.values.copy()\n",
      "    na_data_test = df_close_test.values.copy()\n",
      "    \n",
      "    # Getting the daily returns\n",
      "    tsu.returnize0(na_data)\n",
      "    tsu.returnize0(na_data_test)\n",
      "    \n",
      "    # Calculating the frontier.\n",
      "    (lf_returns, lf_std, lna_portfolios, na_avgrets, na_std) = getFrontier(na_data)\n",
      "    (lf_returns_test, lf_std_test, unused, unused, unused) = getFrontier(na_data_test)\n",
      "    \n",
      "    # Plotting the efficient frontier\n",
      "    plt.clf()\n",
      "    plt.plot(lf_std, lf_returns, 'b')\n",
      "    plt.plot(lf_std_test, lf_returns_test, 'r')\n",
      "    \n",
      "    # Plot where the efficient frontier would be the following year\n",
      "    lf_ret_port_test = []\n",
      "    lf_std_port_test = []\n",
      "    for na_portfolio in lna_portfolios:\n",
      "        na_port_rets = np.dot(na_data_test, na_portfolio)\n",
      "        lf_std_port_test.append(np.std(na_port_rets))\n",
      "        lf_ret_port_test.append(np.average(na_port_rets))\n",
      "    \n",
      "    plt.plot(lf_std_port_test, lf_ret_port_test, 'k')\n",
      "    \n",
      "    # Plot indivisual stock risk/return as green +\n",
      "    for i, f_ret in enumerate(na_avgrets):\n",
      "        plt.plot(na_std[i], f_ret, 'g+')\n",
      "    \n",
      "    # # Plot some arrows showing transistion of efficient frontier\n",
      "    # for i in range(0, 101, 10):\n",
      "    #     plt.arrow(lf_std[i], lf_returns[i], lf_std_port_test[i] - lf_std[i],\n",
      "    #                 lf_ret_port_test[i] - lf_returns[i], color='k')\n",
      "    \n",
      "    # Labels and Axis\n",
      "    plt.legend(['2009 Frontier', '2010 Frontier',\n",
      "        'Performance of \\'09 Frontier in 2010'], loc='lower right')\n",
      "    plt.title('Efficient Frontier For S&P 100 ')\n",
      "    plt.ylabel('Expected Return')\n",
      "    plt.xlabel('StDev')\n",
      "    plt.savefig('tutorial8.pdf', format='pdf')\n",
      "\n",
      "#if __name__ == '__main__':\n",
      "main()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# S&P 100\n",
      "ls_symbols = ['AAPL', 'ABT', 'ACN', 'AEP', 'ALL', 'AMGN', 'AMZN', 'APC', 'AXP', 'BA', 'BAC', 'BAX', 'BHI', 'BK', 'BMY', 'BRK.B', 'CAT', 'C', 'CL', 'CMCSA', 'COF', 'COP', 'COST', 'CPB', 'CSCO', 'CVS', 'CVX', 'DD', 'DELL', 'DIS', 'DOW', 'DVN', 'EBAY', 'EMC', 'EXC', 'F', 'FCX', 'FDX', 'GD', 'GE', 'GILD', 'GOOG', 'GS', 'HAL', 'HD', 'HNZ', 'HON', 'HPQ', 'IBM', 'INTC', 'JNJ', 'JPM', 'KFT', 'KO', 'LLY', 'LMT', 'LOW', 'MA', 'MCD', 'MDT', 'MET', 'MMM', 'MO', 'MON', 'MRK', 'MS', 'MSFT', 'NKE', 'NOV', 'NSC', 'NWSA', 'NYX', 'ORCL', 'OXY', 'PEP', 'PFE', 'PG', 'PM', 'QCOM', 'RF', 'RTN', 'SBUX', 'SLB', 'HSH', 'SO', 'SPG', 'T', 'TGT', 'TWX', 'TXN', 'UNH', 'UPS', 'USB', 'UTX', 'VZ', 'WAG', 'WFC', 'WMB', 'WMT', 'XOM']\n",
      "print len(ls_symbols)\n",
      "\n",
      "# Creating an object of the dataaccess class with Yahoo as the source.\n",
      "c_dataobj = da.DataAccess('Yahoo')\n",
      "\n",
      "ls_all_syms = c_dataobj.get_all_symbols()\n",
      "# Bad symbols are symbols present in portfolio but not in all syms\n",
      "ls_bad_syms = list(set(ls_symbols) - set(ls_all_syms))\n",
      "for s_sym in ls_bad_syms:\n",
      "    i_index = ls_symbols.index(s_sym)\n",
      "    ls_symbols.pop(i_index)\n",
      "\n",
      "# Start and End date of the charts\n",
      "dt_end = dt.datetime(2010, 1, 1)\n",
      "dt_start = dt_end - dt.timedelta(days=365)\n",
      "dt_test = dt_end + dt.timedelta(days=365)\n",
      "\n",
      "# We need closing prices so the timestamp should be hours=16.\n",
      "dt_timeofday = dt.timedelta(hours=16)\n",
      "\n",
      "# Get a list of trading days between the start and the end.\n",
      "ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
      "ldt_timestamps_test = du.getNYSEdays(dt_end, dt_test, dt_timeofday)\n",
      "\n",
      "# Reading just the close prices\n",
      "df_close = c_dataobj.get_data(ldt_timestamps, ls_symbols, \"close\")\n",
      "df_close_test = c_dataobj.get_data(ldt_timestamps_test, ls_symbols, \"close\")\n",
      "\n",
      "# Filling the data for missing NAN values\n",
      "df_close = df_close.fillna(method='ffill')\n",
      "df_close = df_close.fillna(method='bfill')\n",
      "df_close_test = df_close_test.fillna(method='ffill')\n",
      "df_close_test = df_close_test.fillna(method='bfill')\n",
      "\n",
      "# Copying the data values to a numpy array to get returns\n",
      "na_data = df_close.values.copy()\n",
      "na_data_test = df_close_test.values.copy()\n",
      "\n",
      "# Getting the daily returns\n",
      "tsu.returnize0(na_data)\n",
      "tsu.returnize0(na_data_test)\n",
      "\n",
      "print 'end'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Calculating the frontier.\n",
      "(lf_returns, lf_std, lna_portfolios, na_avgrets, na_std) = getFrontier(na_data)\n",
      "(lf_returns_test, lf_std_test, unused, unused, unused) = getFrontier(na_data_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = pd.DataFrame()\n",
      "d['lf_returns'] = lf_returns\n",
      "d['lf_std'] = lf_std\n",
      "d['lf_std_test'] = lf_std_test\n",
      "plot(d); legend(d,2); show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.clf()\n",
      "d = pd.DataFrame()\n",
      "for i, f in enumerate(na_avgrets):\n",
      "    #print str(i) + ' ' + str(f) + ' ' + str(na_std[i])\n",
      "    #plt.plot(na_std[i], f)\n",
      "    ''\n",
      "#plt.plot(na_std, na_avgrets, '.')\n",
      "#print na_avgrets\n",
      "#plot(na_avgrets)\n",
      "#plot(na_std)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Plotting the efficient frontier\n",
      "plt.clf()\n",
      "plt.plot(lf_std, lf_returns, 'b')\n",
      "#print str(lf_std) + ' ' + str(lf_returns)\n",
      "#print len(lf_std)\n",
      "#print len(lf_returns)\n",
      "#for i in range(0,len(lf_std)):\n",
      "#    print str(lf_std[i]) + ' ' + str(lf_returns[i])\n",
      "plt.plot(lf_std_test, lf_returns_test, 'r')\n",
      "\n",
      "\n",
      "# Plot where the efficient frontier would be the following year\n",
      "lf_ret_port_test = []\n",
      "lf_std_port_test = []\n",
      "for na_portfolio in lna_portfolios:\n",
      "    na_port_rets = np.dot(na_data_test, na_portfolio)\n",
      "    lf_std_port_test.append(np.std(na_port_rets))\n",
      "    lf_ret_port_test.append(np.average(na_port_rets))\n",
      "\n",
      "plt.plot(lf_std_port_test, lf_ret_port_test, 'k')\n",
      "\n",
      "# Plot indivisual stock risk/return as green +\n",
      "#for i, f_ret in enumerate(na_avgrets):\n",
      "#    plt.plot(na_std[i], f_ret, 'g+')\n",
      "for i, f_ret in enumerate(na_avgrets):\n",
      "#    print str(i) + str(na_avgrets[i]) + ' ' + str(f_ret)\n",
      "    plt.plot(na_std[i], f_ret, 'g+')\n",
      "#plt.plot(na_std, na_avgrets, '.')\n",
      "# # Plot some arrows showing transistion of efficient frontier\n",
      "for i in range(0, 101, 10):\n",
      "#for i in range(0, 10, 1):\n",
      "#    print i\n",
      "    #plt.plot(lf_std[i], lf_returns[i], lf_std_port_test[i] - lf_std[i], lf_ret_port_test[i] - lf_returns[i], color='r')\n",
      "    plt.plot(lf_std_port_test[i], lf_ret_port_test[i], 'ok')\n",
      "    plt.plot(lf_std[i], lf_returns[i], 'ok')\n",
      "\n",
      "# Labels and Axis\n",
      "plt.legend(['2014 Frontier', '2015 Frontier', 'Performance of \\'14 Frontier in 2015'], loc='lower right')\n",
      "plt.title('Efficient Frontier For S&P 100 ')\n",
      "plt.ylabel('Expected Return')\n",
      "plt.xlabel('StDev')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(lf_std, lf_returns, '.b')\n",
      "for i, f_ret in enumerate(na_avgrets):\n",
      "    plt.plot(na_std[i], f_ret, 'g+')\n",
      "\n",
      "ddistances = []\n",
      "#for i in range(0,len(na_std)):\n",
      "#for i in range(0,10+1):\n",
      "for i in [0,1,2]:\n",
      "    ddistance = []\n",
      "    #for j in range(0,len(na_std)):\n",
      "    for j in range(3,6):\n",
      "        std = [na_std[i], lf_std[j]]\n",
      "        ret = [na_avgrets[i], lf_returns[j]]\n",
      "        dstd = abs(diff(std))\n",
      "        dret = abs(diff(ret))\n",
      "        ddist = list(n.sqrt(n.power(dstd,2)+n.power(dret,2)))[0]\n",
      "        ddistance.append(ddist)\n",
      "        \"\"\"\n",
      "        print 'std:'+str(std)\n",
      "        print 'dstd:'+str(dstd)\n",
      "        print 'ret:'+str(ret)\n",
      "        print 'dret:'+str(dret)\n",
      "        print 'ddistance:'+str(ddistance)\n",
      "        \"\"\"\n",
      "        #print str(i) + ' ' + str(j) + ' dstd:'+str(dstd) + '   ' + 'dret:'+str(dret) + '   ' + 'ddist:'+str(ddist)\n",
      "        plt.plot(std, ret, '-k')\n",
      "    print\n",
      "    ddistances.append(ddistance)\n",
      "#print n.array(ddistances)\n",
      "ddistances = pd.DataFrame(ddistances).transpose()\n",
      "#print ddistances\n",
      "#print n.min(ddistances)\n",
      "#print n.indices(n.min(ddistances))\n",
      "#plt.plot(ddistances)\n",
      "\n",
      "# find the index number of the minimum for each column\n",
      "#dt = n.array([[1,2,3,4,5],[2,2,1,2,3]])\n",
      "#dt = pd.DataFrame(dt).transpose()\n",
      "#print ddistances\n",
      "dt = ddistances\n",
      "dt = pd.DataFrame(dt)\n",
      "#print dt\n",
      "#print n.min(dt)\n",
      "lowDt = pd.DataFrame(n.array(dt == n.min(dt), dtype=int))\n",
      "#print lowDt\n",
      "#print pd.DataFrame(n.min(dt)).transpose()\n",
      "finz = n.nonzero(lowDt.get_values()) # get row indeces of 1's\n",
      "print finz\n",
      "fin = pd.DataFrame([list(finz[0]),list(finz[1])]).transpose()\n",
      "#fin = pd.DataFrame(index=list(finz[0]), columns=list(finz[1]))\n",
      "print 'len:'+str(len(fin.columns))\n",
      "ln = n.array(pd.DataFrame(list(n.min(dt))).ix[finz[1],0])\n",
      "fin[2] = ln\n",
      "print fin.transpose()\n",
      "\n",
      "for i in range(0,len(finz[0])):\n",
      "    #print dt.ix[finz[0][i], finz[1][i]]\n",
      "    std = [na_std[finz[1][i]], lf_std[finz[0][i]-1]]\n",
      "    ret = [na_avgrets[finz[1][i]], lf_returns[finz[0][i]-1]]\n",
      "    plt.plot(std, ret, '-k')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0,3):\n",
      "    for j in range(0,3):\n",
      "        print dt.sort(columns=[j]).get_values()[i][j]\n",
      "    print\n",
      "#print dt.sort(columns=[0]).ix[0,:]\n",
      "print dt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt\n",
      "import itertools \n",
      "\n",
      "fig=plt.figure()\n",
      "ax=fig.add_subplot(111)\n",
      "all_data = [[1,10],[2,10],[3,10],[4,10],[5,10],[3,1],[3,2],[3,3],[3,4],[3,5]]\n",
      "print itertools.combinations(all_data, 2)\n",
      "plt.plot(    *zip(*itertools.chain.from_iterable(itertools.combinations(all_data, 2))),    color = 'brown', marker = 'o')\n",
      "#plt.plot(   all_data,    color = 'brown', marker = 'o')\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_data = [[1,10],[2,10],[3,10],[4,10],[5,10],[3,1],[3,2],[3,3],[3,4],[3,5]]\n",
      "for point in all_data:\n",
      "    for point2 in all_data:\n",
      "        #print str(point) + '' + str(point2)\n",
      "        pyplot.plot([point[0], point2[0]], [point[1], point2[1]])\n",
      "    #print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#y = diff(lf_returns[0:101])/diff(lf_std[0:101])\n",
      "y = diff(lf_returns[0:101])/diff(lf_std[0:101])\n",
      "#print y\n",
      "plot(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.plot(lf_std, lf_returns, '.b')\n",
      "#plt.plot(lf_returns, lf_std, 'b')\n",
      "#plt.plot(lf_std, ones(len(lf_std)), 'r')\n",
      "#plt.plot(lf_std)\n",
      "#plt.plot(lf_returns)\n",
      "ylabel('lf_std')\n",
      "xlabel('lf_returns')\n",
      "dy = diff(lf_std)\n",
      "dx = diff(lf_returns)\n",
      "dydx = dy/dx\n",
      "plot(dydx)\n",
      "#plot(y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dydx"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# numerical derivative\n",
      "# source: http://web.archive.org/web/20110514123948/http://wiki.octave.org/wiki.pl?CategorySymbolic\n",
      "t = linspace(-6,6,100)\n",
      "#y = sin(t)\n",
      "import numpy as n\n",
      "y = t*t\n",
      "dydt = diff(y)/diff(t)\n",
      "plot(y)\n",
      "plot(dydt)\n",
      "legend(['y','dy/dt'])\n",
      "#plot(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#plt.legend(['2009 Frontier', '2010 Frontier', 'Performance of \\'09 Frontier in 2010'], loc='lower right')\n",
      "plt.savefig('tutorial8.pdf', format='pdf')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# QoreQuant\n",
      "# compinvesting-001\n",
      "# video 1 - 9 Computing inside a hedge fund .mp4\n",
      "\n",
      "#qstrader.py\n",
      "#qsoptimizer.py\n",
      "#qsforecaster.py\n",
      "\n",
      "#%reset\n",
      "\n",
      "import pandas as p\n",
      "import numpy as n\n",
      "import time\n",
      "from threading import Thread\n",
      "\t\n",
      "# Trading Algorithm\n",
      "class QsTrader(Thread):\n",
      "    def __init__(self):\n",
      "        Thread.__init__(self)\n",
      "        # getters\n",
      "        self.historical      = None\n",
      "        self.targetPortfolio = None\n",
      "        self.livePortfolio   = None\n",
      "        \n",
      "        # setters\n",
      "        self.orders = None\n",
      "        \n",
      "    def run(self):\n",
      "        while 1:\n",
      "            #self.check()\n",
      "            self.gotoMarket()\n",
      "            time.sleep(1e-1)            \n",
      "    \n",
      "    def getHistoricalPriceData(self):\n",
      "        ''\n",
      "        \n",
      "    # portfolio_X.h5\n",
      "    def getTargetPortfolio(self):\n",
      "        optimizer = QsOptimizer()\n",
      "        self.targetPortfolio = optimizer.generateTargetPortfolio()\n",
      "        return self.targetPortfolio\n",
      "        \n",
      "    # portfolio_LIVE.h5\n",
      "    def getLivePortfolio(self):\n",
      "        # live portfolio\n",
      "        # todo: get live portfolio from broker (keep persistent connection)\n",
      "        livePortfolio = p.DataFrame([100,-200,50,-500], index=['AAPL','BAC','BOA','DAL'], columns=['live_amount'])\n",
      "        self.livePortfolio = livePortfolio\n",
      "        return livePortfolio\n",
      "\n",
      "    # orders_V.h5\n",
      "    def generateOrders(self):\n",
      "        fname = 'orders_V.csv'\n",
      "        # orders\n",
      "        indx = []        \n",
      "        orders = p.DataFrame(n.zeros(len(indx)), index=indx, columns=['orders_amount'])\n",
      "        self.orders = orders\n",
      "        return orders\n",
      "\n",
      "    def sendOrders(self):\n",
      "        # send orders only if there are orders to send\n",
      "        # else do nothing        \n",
      "        if n.sum(n.array(self.orders)) != 0:\n",
      "            print 'detected pending orders.'\n",
      "            print self.orders\n",
      "            print 'sending orders to market..'\n",
      "            print\n",
      "    \n",
      "    def gotoMarket(self):\n",
      "        targetPortfolio = self.getTargetPortfolio()\n",
      "        #print 'target portfolio'\n",
      "        #print targetPortfolio\n",
      "        #print\n",
      "        livePortfolio = self.getLivePortfolio()\n",
      "        #print 'live portfolio'\n",
      "        #print livePortfolio\n",
      "        #print\n",
      "        orders = self.generateOrders()\n",
      "        #print 'orders'\n",
      "        #print orders\n",
      "        #print\n",
      "        #self.sendOrders()\n",
      "        \n",
      "        pp = p.DataFrame()\n",
      "        pp = pp.combine_first(targetPortfolio)\n",
      "        pp = pp.combine_first(livePortfolio)\n",
      "        pp = pp.combine_first(orders)\n",
      "        pp['orders_amount'] = n.diff(n.array(pp.ix[:,['live_amount','target_amount']]))\n",
      "        self.orders = pp.ix[:,'orders_amount'].fillna(0)        \n",
      "        self.orders = self.orders.ix[list(n.nonzero(n.array(self.orders != 0, dtype=int))[0])]\n",
      "        #print self.orders        \n",
      "        self.sendOrders()\n",
      "\n",
      "# Portfolio Optimizer\n",
      "class QsOptimizer:\n",
      "    def __init__(self):\n",
      "        # getters\n",
      "        self.livePortfolio   = None\n",
      "        self.nDayForecast    = None\n",
      "        self.riskConstraints = None\n",
      "        \n",
      "        # setters\n",
      "        self.targetPortfolio = None\n",
      "    \n",
      "    def getLivePortfolio(self):\n",
      "        trader = QsTrader()\n",
      "        self.livePortfolio = trader.getLivePortfolio()\n",
      "        \n",
      "    def getNDayForecast(self):\n",
      "        forecaster = QsForecaster()\n",
      "        self.forecaster = forecaster.getNDayForecast()\n",
      "        \n",
      "    def getRiskConstraints(self):\n",
      "        ''\n",
      "        \n",
      "    def generateTargetPortfolio(self):\n",
      "        # target portfolio\n",
      "        targetPortfolio = p.DataFrame([100,0,50,-550], index=['AAPL','BAC','BOA','DAL'], columns=['target_amount'])\n",
      "        self.targetPortfolio = targetPortfolio\n",
      "        return targetPortfolio\n",
      "\n",
      "# Forecasting Algorithm\n",
      "class QsForecaster:\n",
      "        def __init__(self):\n",
      "            # getters\n",
      "            self.informationFeed   = None\n",
      "            self.historical        = None\n",
      "            self.machineLearning   = None\n",
      "            \n",
      "            # setters\n",
      "            self.nDayForecast = Null\n",
      "        \n",
      "        def getInformationFeed(self):\n",
      "            ''\n",
      "        \n",
      "        def getHistorical(self):\n",
      "            trader = QsTrader()\n",
      "            self.historical = trader.getHistoricalPriceData()\n",
      "        \n",
      "        def getMachineLearning(self):\n",
      "            ''\n",
      "        \n",
      "        def generateNDayForecast(self):\n",
      "            ''\n",
      "    \n",
      "trader = QsTrader()\n",
      "\n",
      "def main():\n",
      "    trader.start()\n",
      "\n",
      "def test():\n",
      "    trader.gotoMarket()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    #main()\n",
      "    test()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import uncertainties as unc  \n",
      "import uncertainties.unumpy as unumpy  \n",
      "import numpy  \n",
      "import nemmen  \n",
      "\n",
      "# Defines x and y  \n",
      "x=numpy.linspace(0,10,50)  \n",
      "y=numpy.linspace(15,20,50)  \n",
      "\n",
      "# Defines the error arrays, values follow a normal distribution  \n",
      "# (method random_normal defined in http://astropython.blogspot.com/2012/04/how-to-generate-array-of-random-numbers.html)  \n",
      "errx=nemmen.random_normal(0.1,0.2,50);     errx=numpy.abs(errx)  \n",
      "erry=nemmen.random_normal(0.3,0.2,50);     erry=numpy.abs(erry)  \n",
      "\n",
      "# Defines special arrays holding the values *and* errors  \n",
      "x=unumpy.uarray(( x, errx ))  \n",
      "y=unumpy.uarray(( y, erry ))  \n",
      "\n",
      "\"\"\"  \n",
      "Now any operation that you carry on xerr and yerr will   \n",
      "automatically propagate the associated errors, as long  \n",
      "as you use the methods provided with uncertainties.unumpy  \n",
      "instead of using the numpy methods.  \n",
      "\n",
      "Let's for instance define z as   \n",
      "z = log10(x+y**2)  \n",
      "and estimate errz.  \n",
      "\"\"\"  \n",
      "z=unumpy.log10(x+y**2)  \n",
      "\n",
      "# Print the propagated error errz  \n",
      "errz=unumpy.std_devs(z)  \n",
      "print errz  "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "No module named nemmen",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-d83c942eaee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muncertainties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0munumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnemmen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Defines x and y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: No module named nemmen"
       ]
      }
     ],
     "prompt_number": 3
    }
   ],
   "metadata": {}
  }
 ]
}