{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb; pdb.set_trace()\n",
    "#%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "from qoreliquid import *\n",
    "from qore_qstk import *\n",
    "from pylab import rcParams\n",
    "import pandas as p\n",
    "rcParams['figure.figsize'] = 20, 13\n",
    "\n",
    "out = getEfficientFrontierCharts(dt.datetime(2014,9,11), calculateHowMany=None, printHowMany=None, days=365*1, annotate=True)\n",
    "#calculateEfficientFrontier(5, dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext memory_profiler\n",
    "%load_ext line_profiler\n",
    "from qoreliquid import *\n",
    "from qore_qstk import *\n",
    "from pylab import rcParams\n",
    "import pandas as p\n",
    "rcParams['figure.figsize'] = 20, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print searchQuandl('SP500', returndataset=True)\n",
    "\n",
    "#print getDataFromQuandl('YAHOO/SP500_5010TR', dataset='')\n",
    "#print getDataFromQuandl('YAHOO/INDEX_GSPC', dataset='')\n",
    "\n",
    "zxc = getDataFromQuandl('YAHOO/INDEX_GSPC', dataset='')\n",
    "#zxc = getDataFromQuandl('YAHOO/SP500_5010TR', dataset='')\n",
    "zxc['Close'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "symb1 = 'GOOG'\n",
    "%mprun getDatasetSymbol(symb1).plot(); show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%lprun -f generateQstkSymbolsTxt generateQstkSymbolsTxt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "out = getEfficientFrontierCharts(dt.datetime(2014,9,11), calculateHowMany=None, printHowMany=None, days=365*1, annotate=True)\n",
    "#calculateEfficientFrontier(5, dt.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trollPlots()\n",
    "#searchQuandl('renewable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dt_end=dt.datetime(2012,1,1)\n",
    "dt_end=dt.datetime.now()\n",
    "portfolioBacktester(dt_end=dt_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qu = ['EIA/SEDS_REPRB_WA_A']\n",
    "#qu = 'EIA/SEDS_REPRB_WA_A'\n",
    "#getDataFromQuandl(qu)\n",
    "plot1 = getDataFromQuandl(qu, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Portfolio Backtester\n",
    "# Tips for accessing historical data via DataAccess + a quick and dirty portfolio back test\n",
    "# source: http://wiki.quantsoftware.org/index.php?title=QSTK_Tutorial_3\n",
    "\n",
    "import QSTK.qstkutil.qsdateutil as du\n",
    "import QSTK.qstkutil.tsutil as tsu\n",
    "import QSTK.qstkutil.DataAccess as da\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv = \"\"\"symbol, allocation\n",
    "SPY,0.3\n",
    "GABBABOOM,0.2\n",
    "GLD,0.3\n",
    "7ABBA, 0.2\n",
    "\"\"\"\n",
    "fname = 'tutorial3portfolio.csv'\n",
    "fp = open(fname, 'w')\n",
    "fp.write(csv)\n",
    "fp.close()\n",
    "\n",
    "#Reading in the portfolio description\n",
    "\n",
    "#NumPy provides a nice utility, loadtxt() for reading in CSV formatted data files. Here's the code for reading in the portfolio:\n",
    "na_portfolio = np.loadtxt(fname, dtype='S5,f4',\n",
    "                        delimiter=',', comments=\"#\", skiprows=1)\n",
    "os.remove(fname)\n",
    "print p.DataFrame(na_portfolio)\n",
    "\n",
    "#The second line (dtype=) defines the format for each column. I think the other arguments are self explanatory. Now let's take a look at what we get back from this read:\n",
    "#[('SPY', 0.30000001192092896) ('GABBA', 0.20000000298023224),('GLD', 0.30000001192092896) ('7ABBA', 0.20000000298023224)]\n",
    "#Later on it will be helpful if our data is sorted by symbol name, so we'll do that next:\n",
    "na_portfolio = sorted(na_portfolio, key=lambda x: x[0])\n",
    "print p.DataFrame(na_portfolio)\n",
    "#Which prints out:\n",
    "#[('7ABBA', 0.20000000298023224), ('GABBA', 0.20000000298023224), ('GLD', 0.30000001192092896), ('SPY', 0.30000001192092896)]\n",
    "#Now we build two lists, one that contains the symbols and one that contains the allocations:\n",
    "ls_port_syms = []\n",
    "lf_port_alloc = []\n",
    "for port in na_portfolio:\n",
    "    ls_port_syms.append(port[0])\n",
    "    lf_port_alloc.append(port[1])\n",
    "#Checking for spurious symbols and removing them\n",
    "#\n",
    "#Now we're going to benefit from the horsepower of our DataAccess class and Python's set operations. First step is to see which symbols are available, then intersect that list with the symbols in our portfolio:\n",
    "c_dataobj = da.DataAccess('Yahoo')\n",
    "ls_all_syms = c_dataobj.get_all_symbols()\n",
    "ls_bad_syms = list(set(ls_port_syms) - set(ls_all_syms))\n",
    "#The second line above returns a list of all symbols available to us in the \"Yahoo\" data store. On the third line above we convert the list of all symbols, and the list of symbols in our portfolio into sets, then remove the symbols not present in the ls_all_syms but present in the ls_port_syms. These are the bad symbols.\n",
    "\n",
    "if len(ls_bad_syms) != 0:\n",
    "        print \"Portfolio contains bad symbols : \", ls_bad_syms\n",
    "#The above code results in the following print out:\n",
    "#Portfolio contains bad symbols : ['7ABBA', 'GABBA']\n",
    "#Now we'll remove those bad symbols from our portfolio:\n",
    "for s_sym in ls_bad_syms:\n",
    "    i_index = ls_port_syms.index(s_sym)\n",
    "    ls_port_syms.pop(i_index)\n",
    "    lf_port_alloc.pop(i_index)\n",
    "#Configuring times and reading the data\n",
    "#\n",
    "#The list portsyms now contains the proper list of valid symbols, so we can ask DataAccess to return them for us with out blowing up. First we must set up the time boundaries as below:\n",
    "dt_end = dt.datetime(2011, 1, 1)\n",
    "dt_start = dt_end - dt.timedelta(days=1095)  # Three years\n",
    "dt_timeofday = dt.timedelta(hours=16)\n",
    "\n",
    "ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
    "\n",
    "ls_keys = ['open', 'high', 'low', 'close', 'volume', 'actual_close']\n",
    "\n",
    "ldf_data = c_dataobj.get_data(ldt_timestamps, ls_port_syms, ls_keys)\n",
    "d_data = dict(zip(ls_keys, ldf_data))\n",
    "#The code above reads in the data for the symbols in our portfolio between the dates of Jan 1, 2011, back to 1095 days before that (3 years).\n",
    "#Now, a quick and dirty back test\n",
    "#\n",
    "#Note: this example computes portfolio returns assuming daily rebalancing. For coursera homework 1, you should not assume daily rebalancing.\n",
    "#The first step is to prep the data. We make a copy of our closing prices in to \"rets\", fill the data forward, then convert it into daily returns:\n",
    "df_rets = d_data['close'].copy()\n",
    "df_rets = df_rets.fillna(method='ffill')\n",
    "df_rets = df_rets.fillna(method='bfill')\n",
    "\n",
    "na_rets = df_rets.values\n",
    "tsu.returnize0(na_rets)\n",
    "#Note that we extracted an ndarray from \"close\" (a pandas DataFrame), so we're now no longer benefitting from DataFrame features. You should consult other locations on this site for details on fill forward and converting into daily returns. For our combined portfolio we'll assume the combined return for each day is a sum of the returns for each equity weighted by the allocation. We can quickly compute the daily returns and the cumulative returns as follows:\n",
    "na_portrets = np.sum(na_rets * lf_port_alloc, axis=1)\n",
    "#print 'na_portrets'; print na_portrets\n",
    "na_port_total = np.cumprod(na_portrets + 1)\n",
    "#print 'na_port_total'; print na_port_total\n",
    "#In a similar manner we can compute the returns of the individual components as follows:\n",
    "na_component_total = np.cumprod(na_rets + 1, axis=0)\n",
    "#That's it for the \"back test.\" porttot contains the total returns for our combined portfolio.\n",
    "#Plotting the results\n",
    "\n",
    "#Our combined portfolio (and component equities).\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(111)\n",
    "plt.plot(ldt_timestamps, na_component_total, alpha=0.4)\n",
    "plt.plot(ldt_timestamps, na_port_total)\n",
    "ls_names = ls_port_syms\n",
    "ls_names.append('Portfolio')\n",
    "plt.title('Portfolio Allocations incl. assets');\n",
    "plt.legend(ls_names,2)\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.xlabel('Date'); plt.show();\n",
    "fig.autofmt_xdate(rotation=45);\n",
    "plt.plot(ldt_timestamps, na_port_total); \n",
    "plt.title('Portfolio Allocations ex. assets');\n",
    "plt.legend('Portfolio',2); plt.show();\n",
    "#plt.savefig('tutorial3.pdf', format='pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The Allocation DataFrame\n",
    "# source: http://wiki.quantsoftware.org/index.php?title=QSTK_Tutorial_4\n",
    "\n",
    "#An allocation DataFrame is created using the pandas data structure DataFrame. \n",
    "#This structure consists of a series of python datetime objects as indexes, \n",
    "#and stock symbols for column headings. The last column in the DataFrame is the symbol _CASH, \n",
    "#which represents what percentage of a portfolio is held in cash. \n",
    "#Each row has the distribution of the portfolio recorded via values in each column \n",
    "#that represent how much of the portfolio is in that stock at that date and time. \n",
    "#Normally these values are normalized so that they add to one.\n",
    "\n",
    "#Creating an Allocation\n",
    "\n",
    "#In order to setup an allocation table, we must first create the DataFrame. \n",
    "#A pandas DataFrame object consists of indices, column headings, and data. \n",
    "#Datetime objects are used for the indices. We can create a list of timestamps over the time \n",
    "#period we are interested in looking in a similar fashion to how we produce timestamps \n",
    "#for the DataAccess utility. We create a list of timestamps like so:\n",
    "dt_start = dt.datetime(2004, 1, 1)\n",
    "dt_end = dt.datetime(2009, 12, 31)\n",
    "\n",
    "# We need closing prices so the timestamp should be hours=16.\n",
    "dt_timeofday = dt.timedelta(hours=16)\n",
    "\n",
    "# Get a list of trading days between the start and the end.\n",
    "ldt_timestamps = du.getNYSEdays(dt_start, dt_end, dt_timeofday)\n",
    "\n",
    "# Creating an object of the dataaccess class with Yahoo as the source.\n",
    "c_dataobj = da.DataAccess('Yahoo')\n",
    "#These timestamps will help us look at the dates between 2004 through the end of 2009.\n",
    "#Symbols\n",
    "\n",
    "#The allocation DataFrame describes the distribution of a portfolio across several stocks. \n",
    "#It also details how much of the portfolio should be in cash at a point in time. \n",
    "#In this particular example, we wish to look at the first 20 stocks of the S&P500. \n",
    "#The way we set up column headers to reflect this stock symbol information is like so:\n",
    "ls_symbols = c_dataobj.get_symbols_from_list('sp5002012')\n",
    "ls_symbols = ls_symbols[:20]\n",
    "ls_symbols.append('_CASH')\n",
    "\n",
    "\n",
    "#Allocations\n",
    "\n",
    "#Now that we have the symbols and time period for our allocation, we must determine how much of the portfolio\n",
    "#will be in each equity at each date. Normally this will be the most involved part in creating an allocation. \n",
    "#In this particular example we will be creating a new random distribution for our portfolio \n",
    "#at the start of each month. We create random values for the first row in our allocation table like so:\n",
    "na_vals = np.random.randint(0, 1000, len(ls_symbols))\n",
    "# Normalize the row - Typecasting as everything is int.\n",
    "na_vals = na_vals / float(sum(na_vals))\n",
    "# Reshape to a 2D matrix to append into dataframe.\n",
    "na_vals = na_vals.reshape(1, -1)\n",
    "#We then make a one row DataFrame for the first date using the constructor like so:\n",
    "df_alloc = pd.DataFrame(na_vals, index=[ldt_timestamps[0]], columns=ls_symbols)\n",
    "#Since we only desire to reallocate our portfolio once a month, we only add a new row to the DataFrame \n",
    "#for each new month. We must then repeat the process of creating and normalizing random values for the allocation. \n",
    "#Then we create another DataFrame row and append it to what we have already. \n",
    "#Thus we build up an allocation table across all of the months in our list of timestamps.\n",
    "dt_last_date = ldt_timestamps[0]\n",
    "# Looping through all dates and creating monthly allocations\n",
    "for dt_date in ldt_timestamps[1:]:\n",
    "#    if dt_last_date.month != dt_date.month:\n",
    "    # Create allocation\n",
    "    na_vals = np.random.randint(0, 1000, len(ls_symbols))\n",
    "    na_vals = na_vals / float(sum(na_vals))\n",
    "    na_vals = na_vals.reshape(1, -1)\n",
    "    # Append to the dataframe\n",
    "    df_new_row = pd.DataFrame(na_vals, index=[dt_date], columns=ls_symbols)\n",
    "    df_alloc = df_alloc.append(df_new_row)\n",
    "        \n",
    "    dt_last_date = dt_date\n",
    "    \n",
    "#print n.sum(df_alloc, axis=1)\n",
    "print df_alloc.ix[0,:]\n",
    "#df_alloc.plot(style='.'); show()\n",
    "#print output\n",
    "\n",
    "#Using an Allocation\n",
    "\n",
    "#QSTK uses allocation tables for a variety of tasks, most notably in backtesting strategies. \n",
    "#In order to use an allocation table, you can either pass it to the function you wish to use it with, \n",
    "#or store it in a pickle file for later usage. To do the latter, you must import the cPickle package and \n",
    "#dump the object like so:\n",
    "#output=open(\"allocations.pkl\",\"wb\")\n",
    "#cPickle.dump(alloc,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_alloc0 = p.DataFrame(df_alloc.ix[0,:].get_values(), index=df_alloc.ix[0,:].index)\n",
    "#print df_alloc0\n",
    "#print 1 - df_alloc.ix[:,0].get_values()\n",
    "#df_alloc0[1] = df_alloc.ix[:,0].get_values() - n.sum(df_alloc0, axis=0)[0]\n",
    "#print df_alloc.ix[0,:].to_csv(fname)\n",
    "#print na_portfolio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
